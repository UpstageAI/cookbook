from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_upstage import UpstageEmbeddings
from pathlib import Path
import tiktoken
import math
from uuid import uuid4
import os
import re

load_dotenv()


class Related_Note:
    """
    Obsidian vault ì•ˆì˜ md íŒŒì¼ë“¤ì„ ì„ë² ë”©í•˜ê³ ,
    íŠ¹ì • ë…¸íŠ¸ì— ëŒ€í•œ ì—°ê´€ ë…¸íŠ¸ 3ê°œë¥¼ ì°¾ì•„ [[ë§í¬]]ë¡œ ì¶”ê°€í•˜ëŠ” í´ë˜ìŠ¤.

    - UpstageEmbeddings + Chroma DB ì‚¬ìš©
    - embedded_markers.txt ë¡œ "ì´ë¯¸ ì„ë² ë”©ëœ íŒŒì¼"ì„ ì¶”ì 
    """

    def __init__(self, vault_path: str) -> None:
        """
        - vault_path / vector_store ê²½ë¡œ / embedded marker ê²½ë¡œ ì„¤ì •
        - Upstage ì„ë² ë”© ê°ì²´ ìƒì„±
        - Chroma ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
        - embedded_markers.txt íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ íŒŒì¼ ìƒì„±
        * embedded_markersëŠ” ì´ë¯¸ ì„ë² ë”©ëœ ë…¸íŠ¸ë“¤ ê¸°ë¡í•´ë‘ ìœ¼ë¡œì„œ ì¶”í›„ ì¤‘ë³µ ì„ë² ë”© ë° ì €ì¥ í”¼í•˜ëŠ” ìš©ë„

        Args:
            vault_path (str): Obsidian Vault ë””ë ‰í† ë¦¬ì˜ ì ˆëŒ€ ê²½ë¡œ
        """
        self.vault_path = Path(vault_path).resolve()
        base_path = Path(__file__).resolve()
        self.embedding_path = base_path.parent
        self.store_dir = self.embedding_path / "vector_store"
        self.marker_root = self.embedding_path / "embedded_markers.txt"

        # ì„ë² ë”© / í† í¬ë‚˜ì´ì € ì„¤ì •
        self.embeddings = UpstageEmbeddings(model="embedding-query")
        # ì—…ìŠ¤í…Œì´ì§€ ì„ë² ë”© ìµœëŒ€ ê°€ëŠ¥ ì¸í’‹ì¸ 4000í† í° ì¸¡ì •
        self.enc = tiktoken.encoding_for_model("text-embedding-3-small")

        # Chroma ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self.vector_store = self._init_vector_store()

        # ë§ˆì»¤ íŒŒì¼ ë³´ì¥
        self._ensure_marker_file()

    def _init_vector_store(self) -> Chroma:
        """
        Chroma ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Returns:
            Chroma: persist_directoryë¥¼ ê°€ì§€ëŠ” Chroma ì¸ìŠ¤í„´ìŠ¤.
        """
        if self.store_dir.exists():
            return Chroma(
                persist_directory=str(self.store_dir),
                embedding_function=self.embeddings,
            )
        else:
            # Chroma.from_texts ë¥¼ ì“°ê¸° ìœ„í•´ dummy ë°ì´í„° í•œ ë²ˆ ë„£ì—ˆë‹¤ê°€ ë°”ë¡œ ì‚­ì œ
            random_id = str(uuid4())
            vs = Chroma.from_texts(
                texts=["dummy_data"],
                ids=[random_id],
                embedding=self.embeddings,
                persist_directory=str(self.store_dir),
            )
            vs.delete(ids=[random_id])
            return vs

    def _ensure_marker_file(self) -> None:
        """
        embedded_markers.txt íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        Args:
            None
        Returns:
            None
        """
        if not self.marker_root.exists():
            self.marker_root.write_text("", encoding="utf-8")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë§ˆì»¤(ì´ë¯¸ ì„ë² ë”©ëœ ë…¸íŠ¸) ê´€ë ¨
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def load_embedded_notes(self) -> set[str]:
        """
        ì´ë¯¸ ì„ë² ë”©ëœ ë…¸íŠ¸ë“¤ì˜ ìƒëŒ€ ê²½ë¡œ ì§‘í•©ì„ ì½ì–´ì˜µë‹ˆë‹¤.
        Args:
            None
        Returns:
            set[str]: vault ê¸°ì¤€ ê²½ë¡œ ì§‘í•©.
        """
        if not self.marker_root.exists():
            return set()

        lines = self.marker_root.read_text(encoding="utf-8").splitlines()
        return {line.strip() for line in lines if line.strip()}

    def save_embedded_notes(self, new_notes: list[str]) -> None:
        """
        ìƒˆë¡œ ì„ë² ë”©ëœ ë…¸íŠ¸ë“¤ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ ë§ˆì»¤ íŒŒì¼ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        Args:
            new_notes (list[str]): vault ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸.
        Returns:
            None
        """
        with self.marker_root.open("a", encoding="utf-8") as f:
            for rel in new_notes:
                f.write(rel + "\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì„ë² ë”© ëŒ€ìƒ ì„ íƒ / ì²­í‚¹ / ì „ì²˜ë¦¬
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def get_unembedded_notes(self) -> list[str]:
        """
        ì•„ì§ ì„ë² ë”©ë˜ì§€ ì•Šì€ md íŒŒì¼ ê²½ë¡œë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        - embedded_markers.txtì— ì—†ëŠ” íŒŒì¼ë§Œ ëŒ€ìƒ
        - 'upthink' ë””ë ‰í† ë¦¬ í•˜ìœ„ëŠ” ì œì™¸
        - ê²½ë¡œëŠ” vault ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œë¡œ ë°˜í™˜

        Args:
            None
        Returns:
            list[str]: ì•„ì§ ì„ë² ë”©ë˜ì§€ ì•Šì€ md íŒŒì¼ë“¤ì˜ ìƒëŒ€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸.

        * frontendì˜ ê²½ìš°, to_embed ë¦¬ìŠ¤íŠ¸ ë‚´ íŒŒì¼ì„ ì„ë² ë”©í•˜ê² ë‹¤ëŠ” ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì£¼ë©´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.
        """
        embedded = self.load_embedded_notes()
        to_embed: list[str] = []

        for md_file in self.vault_path.rglob("*.md"):
            rel = md_file.relative_to(self.vault_path).as_posix()
            if ".venv" in rel.split("/"):
                continue
            if rel not in embedded:
                to_embed.append(rel)

        return to_embed

    def chunk_text(self, text: str) -> list[str]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€ ì•½ 4000 í† í° ë‹¨ìœ„ë¡œ ì²­í‚¹í•©ë‹ˆë‹¤.
        Args:
            text (str): ì›ë³¸ í…ìŠ¤íŠ¸.
        Returns:
            list[str]: ì²­í¬ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸. (4000 í† í° ì´í•˜ì´ë©´ ê¸¸ì´ 1 ë¦¬ìŠ¤íŠ¸)
        """
        token_list = self.enc.encode(text)
        total_tokens = len(token_list)
        chunks: list[str] = []

        if total_tokens > 4000:
            n_chunks = math.ceil(total_tokens / 4000)
            chunk_size = math.ceil(total_tokens / n_chunks)
            for i in range(0, total_tokens, chunk_size):
                chunk_tokens = token_list[i : i + chunk_size]
                chunk_text = self.enc.decode(chunk_tokens)
                chunks.append(chunk_text)
        else:
            chunks.append(text)

        return chunks

    def clean_text(self, text: str) -> str:
        """
        md íŒŒì¼ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        - Windows/Unix ì¤„ë°”ê¿ˆ ì •ê·œí™” (Windows í˜¸í™˜ì„±)
        - íŠ¹ìˆ˜ ê³µë°± ë¬¸ì ì œê±° (non-breaking space ë“±)
        - êµµê²Œ(**) ë§ˆí¬ë‹¤ìš´ ì œê±°
        - ì—°ì† ê°œí–‰ì„ í•˜ë‚˜ë¡œ ì¶•ì†Œ
        - ì•ë’¤ ê³µë°± ì œê±°

        Args:
            text (str): ì›ë³¸ í…ìŠ¤íŠ¸.
        Returns:
            str: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸.
        """
        # Windows ì¤„ë°”ê¿ˆ(\r\n)ì„ Unix ìŠ¤íƒ€ì¼(\n)ë¡œ ì •ê·œí™”
        x = text.replace("\r\n", "\n").replace("\r", "\n")
        x = re.sub(r"[\xa0\u200b]", "", x)
        x = re.sub(r"\*\*", "", x)
        x = re.sub(r"\n+", "\n", x)
        x = x.strip()
        return x

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì„ë² ë”© ì‹¤í–‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def index_unembedded_notes(self) -> None:
        """
        ì•„ì§ ì„ë² ë”©ë˜ì§€ ì•Šì€ md íŒŒì¼ë“¤ì„ ì°¾ì•„ ëª¨ë‘ ì„ë² ë”©í•©ë‹ˆë‹¤.
        - get_unembedded_notes()ë¡œ ëŒ€ìƒ íƒìƒ‰
        - clean_text() + chunk_text()ë¡œ ì „ì²˜ë¦¬/ì²­í‚¹
        - Chroma.add_texts()ë¡œ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
        - embedded_markers.txtì— ê¸°ë¡

        Args:
            None
        Returns:
            None
        """
        to_embed = self.get_unembedded_notes()

        if not to_embed:
            return

        for note_rel in to_embed:
            note_path = self.vault_path / note_rel
            raw_text = note_path.read_text(encoding="utf-8")
            cleaned = self.clean_text(raw_text)

            # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ì„ë² ë”© ê±´ë„ˆë›°ê¸° (Windows í˜¸í™˜ì„±)
            if not cleaned or not cleaned.strip():
                # ë¹ˆ íŒŒì¼ë„ ë§ˆì»¤ì— ê¸°ë¡í•˜ì—¬ ë‹¤ìŒì— ë‹¤ì‹œ ì‹œë„í•˜ì§€ ì•ŠìŒ
                self.save_embedded_notes([note_rel])
                continue

            chunks = self.chunk_text(cleaned)

            if len(chunks) > 1:
                for i, chunk in enumerate(chunks, start=1):
                    # ë¹ˆ ì²­í¬ëŠ” ê±´ë„ˆë›°ê¸°
                    if not chunk or not chunk.strip():
                        continue
                    self.vector_store.add_texts(
                        ids=[str(uuid4())],
                        metadatas=[
                            {
                                "title": f"{Path(note_rel).stem}_{i}",
                                "path": note_rel,
                            }
                        ],
                        texts=[chunk],
                    )
            else:
                self.vector_store.add_texts(
                    ids=[str(uuid4())],
                    metadatas=[
                        {
                            "title": Path(note_rel).stem,
                            "path": note_rel,
                        }
                    ],
                    texts=[cleaned],
                )

            self.save_embedded_notes([note_rel])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì—°ê´€ ë…¸íŠ¸ ì°¾ê¸° & ë§í¬ ì‚½ì…
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def find_related_notes(self, MY_VAULT_PATH: str, k: int = 3) -> list[str]:
        """
        ì£¼ì–´ì§„ ë…¸íŠ¸ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ md íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        Args:
            MY_VAULT_PATH (str):
                vault ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ, ì‚¬ìš©ìê°€ inputìœ¼ë¡œ ë„£ì„ ê²½ë¡œ
                ì˜ˆ) "upthink/data/HCI 2025 í•™íšŒ ê°•ì˜ì„¸ì…˜ë“¤.md"
            k (int, optional):
                ìµœëŒ€ ëª‡ ê°œì˜ ì—°ê´€ ë…¸íŠ¸ë¥¼ ë°˜í™˜í• ì§€. ê¸°ë³¸ê°’ 3.
        Returns:
            list[str]:
                ì—°ê´€ ë…¸íŠ¸ë“¤ì˜ vault ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸.
                (ìê¸° ìì‹ ì€ í¬í•¨í•˜ì§€ ì•Šìœ¼ë©°, ì¤‘ë³µ ì œê±°ë¨)
                * frontendì— í•´ë‹¹ ë…¸íŠ¸ë“¤ì´ ì¶”ì²œë˜ì—ˆë‹¤ëŠ” ë¬¸êµ¬ê°€ ê°„ë‹¨í•˜ê²Œ ë³´ì—¬ì¡Œìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.
        """

        norm_query = Path(MY_VAULT_PATH).as_posix()
        query_note_path = self.vault_path / norm_query

        raw_text = query_note_path.read_text(encoding="utf-8")
        cleaned = self.clean_text(raw_text)
        query_chunks = self.chunk_text(cleaned)

        # ì²« ë²ˆì§¸ ì²­í¬ ê¸°ì¤€ìœ¼ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰
        hits = self.vector_store.similarity_search(query_chunks[0], k=k + 4)
        related: list[str] = []
        for d in hits:
            raw_path = d.metadata.get("path", "")
            if not raw_path:
                continue
            norm_path = Path(raw_path).as_posix()

            # ìê¸° ìì‹ ì€ ì œì™¸
            if norm_path == norm_query:
                continue

            # ì¤‘ë³µ ì œì™¸
            if norm_path in related:
                continue

            related.append(norm_path)

            if len(related) >= k:
                break
        return related

    def append_related_links(self, MY_VAULT_PATH: str, k: int = 3):
        """
        ì£¼ì–´ì§„ ë…¸íŠ¸ íŒŒì¼ì˜ ëì— "Related Notes" ì„¹ì…˜ì„ ì¶”ê°€í•˜ê³ 
        [[ì—°ê´€ë…¸íŠ¸]] ë§í¬ë¥¼ ìµœëŒ€ kê°œê¹Œì§€ ì‚½ì…í•©ë‹ˆë‹¤.
        Args:
            MY_VAULT_PATH (str):
                vault ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ.
                ì˜ˆ) r"upthink\\data\\HCI 2025 í•™íšŒ ê°•ì˜ì„¸ì…˜ë“¤.md"
            k (int, optional):
                ì‚½ì…í•  ë§í¬ ê°œìˆ˜ (ìµœëŒ€). ê¸°ë³¸ê°’ 3.
        Returns:
            None
        """
        print(MY_VAULT_PATH)
        related = self.find_related_notes(MY_VAULT_PATH, k=k)
        if not related:
            return

        norm_query = Path(MY_VAULT_PATH).as_posix()
        target_path = self.vault_path / norm_query

        with target_path.open("a", encoding="utf-8") as f:
            list_ = []
            f.write("\n\n## ğŸ”— Related Notes\n")
            for path_rel in related[:k]:
                # Obsidian ë§í¬ì—ì„œëŠ” í™•ì¥ì(.md)ë¥¼ ë–¼ê¸° ìœ„í•´ [:-3]
                f.write(f"[[{path_rel[:-3]}]]\n")
                list_.append(path_rel[:-3])
            return list_


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‹¨ë… ì‹¤í–‰ìš© ì˜ˆì‹œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    # Vault ê²½ë¡œë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤
    MY_VAULT_PATH = "YOUR_VAULT_PATH_HERE"  # ì˜ˆ: "/Users/username/Documents/MyVault"

    engine = Related_Note(vault_path=MY_VAULT_PATH)

    # 1) ì•„ì§ ì„ë² ë”© ì•ˆ ëœ ë…¸íŠ¸ë“¤ ì„ë² ë”©
    engine.index_unembedded_notes()

    # 2) íŠ¹ì • ë…¸íŠ¸ì— ëŒ€í•´ ì—°ê´€ ë…¸íŠ¸ 3ê°œ ë§í¬ ì‚½ì…
    engine.append_related_links(r"upthink\data\HCI 2025 í•™íšŒ ê°•ì˜ì„¸ì…˜ë“¤.md", k=3)
