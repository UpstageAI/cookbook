{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3293405d-c8eb-4399-b73b-f5d465efbc08",
   "metadata": {},
   "source": [
    "# Fuction Calling\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/function_calling.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "A function calling occurs when you interact with the Chat API to communicate with a Language Learning Model (LLM). Within the tool array, you have the flexibility to define custom functions. This capability enables the model to dynamically generate and provide function signatures in JSON format, facilitating seamless integration with external tools and applications.\n",
    "\n",
    "With function calling, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call one or many functions. The model does not call the function, but it generates JSON that you can use to call the function in your code.\n",
    "\n",
    "1. Make assistant use external api.\n",
    "2. Call api with natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91916202-67af-4e51-b103-3cd437b09171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install requirements\n",
    "!pip install -qU openai\n",
    "!pip install -qU python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf9016cd-25d6-4bb7-96b4-9dfeb18dd5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title set API key\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "upstage_api_key_env_name = 'UPSTAGE_API_KEY'\n",
    "def load_env():\n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        # Running in Google Colab\n",
    "        from google.colab import userdata\n",
    "        upstage_api_key = userdata.get(upstage_api_key_env_name)\n",
    "        return os.environ.setdefault('UPSTAGE_API_KEY', upstage_api_key)\n",
    "    else:\n",
    "        # Running in local Jupyter Notebook\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        return os.environ.get(upstage_api_key_env_name)\n",
    "\n",
    "UPSTAGE_API_KEY = load_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276775d-9259-4dba-8fb8-67a8d200e451",
   "metadata": {},
   "source": [
    "In this example, we'll use function calling in the following order.\n",
    "\n",
    "1. Make an API call with tools parameter, which has function signature and description.\n",
    "2. API response contains tool calls\n",
    "3. Use it to call our function\n",
    "4. Make another API call with the response from our function appended to our original message list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed25955-abcd-45d2-a4c7-973b18c4fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define API\n",
    "#@markdown In this notebook, We'll define a dummy function that replaces the actual external API.\n",
    "\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"seoul\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Seoul\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05821b81-3605-4ae3-a95a-4db2fe07c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response message:\n",
      " [ChatCompletionMessageToolCall(id='e3f3546e-523d-4e94-900b-3bee355ed0fb', function=Function(arguments='{\"location\":\"San Francisco\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='15fc9fb5-a969-45f6-af76-966813ceee4f', function=Function(arguments='{\"location\":\"Seoul\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='7e055ec9-3a02-4c95-8604-b0d2fa7c8b78', function=Function(arguments='{\"location\":\"Paris\"}', name='get_current_weather'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "#@title Request conversation and available functions to the model\n",
    "\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=UPSTAGE_API_KEY, base_url=\"https://api.upstage.ai/v1/solar\")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in San Francisco, Seoul, and Paris?\",\n",
    "    }\n",
    "]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Request conversation\n",
    "response = client.chat.completions.create(\n",
    "    model=\"solar-1-mini-chat\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "print(\"Response message:\\n\", response_message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48c31ca5-f09a-4e04-a075-7d35cd2c8033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages:\n",
      " [{'role': 'user', 'content': \"What's the weather like in San Francisco, Seoul, and Paris?\"}, ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='119a29d5-ac04-4985-963e-4944060242e9', function=Function(arguments='{\"location\":\"San Francisco\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='3e319c52-1cec-42c0-9fb0-997b10780eaa', function=Function(arguments='{\"location\":\"Seoul\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='d6ea1dbc-467b-4704-a0b2-c9f952c4fb5f', function=Function(arguments='{\"location\":\"Paris\"}', name='get_current_weather'), type='function')]), {'tool_call_id': '119a29d5-ac04-4985-963e-4944060242e9', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": null}'}, {'tool_call_id': '3e319c52-1cec-42c0-9fb0-997b10780eaa', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Seoul\", \"temperature\": \"10\", \"unit\": null}'}, {'tool_call_id': 'd6ea1dbc-467b-4704-a0b2-c9f952c4fb5f', 'role': 'tool', 'name': 'get_current_weather', 'content': '{\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": null}'}] \n",
      "\n",
      "The current weather in San Francisco is 72 degrees Fahrenheit, in Seoul is 10 degrees Celsius, and in Paris is 22 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "#@title Check if the model wanted to call a function and call the function\n",
    "if tool_calls:\n",
    "    available_function = {\n",
    "        \"get_current_weather\": get_current_weather\n",
    "    }\n",
    "    messages.append(response_message)\n",
    "\n",
    "    # Send the info for each function call and function response to the model\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_function[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(location=function_args.get(\"location\"), unit=function_args.get(\"unit\"))\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response\n",
    "            }\n",
    "        )\n",
    "    print(\"messages:\\n\", messages, \"\\n\")\n",
    "    \n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"solar-1-mini-chat\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(\"second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47341c90-87a7-4208-b4fa-5dd9d37e36e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
