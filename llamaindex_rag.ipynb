{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c480233-ad9b-4511-b47d-a2d6815d37cb",
   "metadata": {},
   "source": [
    "# RAG with llamaindex-upstage\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/llamaindex_rag.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "In this notebook, you will use the lamindex-upstage package to create a RAG engine that uses pdf files.\n",
    "\n",
    "First, install the relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a5c292-a598-45c1-b4a2-9793d6a93d11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# @title Install requirements\n",
    "# @markdown First, create your upstage api key from upstage console. and set UPSTAGE_API_KEY environ variable.\n",
    "\n",
    "!pip install -qU llama-index-llms-upstage llama-index-llms-openai llama-index-embeddings-upstage llama-index-readers-file\n",
    "!pip install -qU llama-index-core\n",
    "!pip install -qU python-dotenv pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bc510-2704-42c1-8e12-8f73f3157856",
   "metadata": {},
   "source": [
    "# Set API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78bd008b-a22d-49d3-90f9-2b82d860ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title set API key\n",
    "import os\n",
    "import getpass\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Running in Google Colab. Please set the UPSTAGE_API_KEY in the Colab Secrets\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
    "else:\n",
    "    # Running locally. Please set the UPSTAGE_API_KEY in the .env file\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "if \"UPSTAGE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = getpass.getpass(\"Enter your Upstage API key: \")\n"
]

  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ca570f-6549-497a-ab4e-efd015d0a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Setting Upstage llm and embedding\n",
    "# @markdown You can check available models [here](https://developers.upstage.ai/docs/getting-started/models)\n",
    "\n",
    "from llama_index.llms.upstage import Upstage\n",
    "from llama_index.embeddings.upstage import UpstageEmbedding\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "llm = Upstage()\n",
    "embed_model = UpstageEmbedding(model=\"solar-embedding-1-large\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f50eb2-6575-426c-b837-fb8f2a35c57f",
   "metadata": {},
   "source": [
    "# Load document, Build the index\n",
    "\n",
    "In this notebook, we read a document and split it into nodes.\n",
    "\n",
    "To split the document into nodes, we use the [SentenceWindowNodeParser](https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/MetadataReplacementDemo/). `SentenceWindowNodeParser` parses documents into single sentences per node. Each node also contains a \"window\" with the sentences on either side of the node sentence. And the \"window\" will be used in the `MetadataReplacementNodePostProcessor` in the retreiver step.\n",
    "\n",
    "For more information, see the [Metadata Replacement + Node Sentence Window](https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/MetadataReplacementDemo/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344ae075-2d91-48c3-9c83-c4503e25d98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes:  595 \n",
      "\n",
      "Content:\n",
      " SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective\n",
      "Depth Up-Scaling\n",
      "Dahyun Kim∗, Chanjun Park∗†, Sanghoon Kim∗†, Wonsung Lee∗†, Wonho Song∗\n",
      "Yunsu Kim∗, Hyeonwoo Kim∗, Yungi Kim, Hyeonju Lee, Jihoo Kim\n",
      "Changbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim\n",
      "Mikyoung Cha, Hwalsuk Lee†, Sunghun Kim†\n",
      "Upstage AI, South Korea\n",
      "{kdahyun, chanjun.park, limerobot, wonsung.lee, hwalsuk.lee, hunkim}@upstage.ai\n",
      "Abstract\n",
      "We introduce SOLAR 10.7B, a large language\n",
      "model (LLM) with 10.7 billion parameters,\n",
      "demonstrating superior performance in various\n",
      "natural language processing (NLP) tasks.  \n",
      "\n",
      "Metadata:\n",
      " {'window': 'SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective\\nDepth Up-Scaling\\nDahyun Kim∗, Chanjun Park∗†, Sanghoon Kim∗†, Wonsung Lee∗†, Wonho Song∗\\nYunsu Kim∗, Hyeonwoo Kim∗, Yungi Kim, Hyeonju Lee, Jihoo Kim\\nChangbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim\\nMikyoung Cha, Hwalsuk Lee†, Sunghun Kim†\\nUpstage AI, South Korea\\n{kdahyun, chanjun.park, limerobot, wonsung.lee, hwalsuk.lee, hunkim}@upstage.ai\\nAbstract\\nWe introduce SOLAR 10.7B, a large language\\nmodel (LLM) with 10.7 billion parameters,\\ndemonstrating superior performance in various\\nnatural language processing (NLP) tasks.  In-\\nspired by recent efforts to efficiently up-scale\\nLLMs, we present a method for scaling LLMs\\ncalled depth up-scaling (DUS), which encom-\\npasses depthwise scaling and continued pre-\\ntraining.  In contrast to other LLM up-scaling\\nmethods that use mixture-of-experts, DUS does\\nnot require complex changes to train and infer-\\nence efficiently.  We show experimentally that\\nDUS is simple yet effective in scaling up high-\\nperformance LLMs from small ones. ', 'original_text': 'SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective\\nDepth Up-Scaling\\nDahyun Kim∗, Chanjun Park∗†, Sanghoon Kim∗†, Wonsung Lee∗†, Wonho Song∗\\nYunsu Kim∗, Hyeonwoo Kim∗, Yungi Kim, Hyeonju Lee, Jihoo Kim\\nChangbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim\\nMikyoung Cha, Hwalsuk Lee†, Sunghun Kim†\\nUpstage AI, South Korea\\n{kdahyun, chanjun.park, limerobot, wonsung.lee, hwalsuk.lee, hunkim}@upstage.ai\\nAbstract\\nWe introduce SOLAR 10.7B, a large language\\nmodel (LLM) with 10.7 billion parameters,\\ndemonstrating superior performance in various\\nnatural language processing (NLP) tasks. ', 'page_label': '1', 'file_name': 'solar_paper.pdf', 'file_path': 'data/solar_paper.pdf', 'file_type': 'application/pdf', 'file_size': 418872, 'creation_date': '2024-05-29', 'last_modified_date': '2024-05-29'}\n"
     ]
    }
   ],
   "source": [
    "# @title Load document, Build the index\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "\n",
    "# load pdf document\n",
    "documents = SimpleDirectoryReader(input_files=[\"./data/solar_paper.pdf\"]).load_data()\n",
    "\n",
    "# split nodes\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "print(\"Total nodes: \", len(nodes), \"\\n\")\n",
    "print(\"Content:\\n\", nodes[0].get_content(), \"\\n\")\n",
    "print(\"Metadata:\\n\", nodes[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8000090e-ed9e-4a8f-a0c3-310301ab7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Build index\n",
    "index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559afba9-4dec-4da3-a851-a7619ab62290",
   "metadata": {},
   "source": [
    "# Querying with MetadataReplacementPostProcessor\n",
    "\n",
    "Here, we use `MetadataReplacementPostProcessor` to replace the sentence in each node with it`s surrounding sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "026ecd1e-b78d-4a61-8964-be65f8b80ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors of the paper are Sanghoon Kim, Dahyun Kim, Chanjun Park, Wonsung Lee, Wonho Song, Yunsu Kim, Hyeonwoo Kim, Yungi Kim, Jihoo Kim, Changbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim, Hyeonju Lee, and Mikyoung Cha.\n"
     ]
    }
   ],
   "source": [
    "# @title Querying with MetadataReplacementPostProcessor\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "window_response = query_engine.query(\"Who are authors of paper?\")\n",
    "print(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8efb58c1-7306-4cb3-8c87-61133122d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window:\n",
      " 2023.  Llama 2: Open founda-\n",
      "tion and fine-tuned chat models.  arXiv preprint\n",
      "arXiv:2307.09288 .\n",
      " Lewis Tunstall, Edward Beeching, Nathan Lambert,\n",
      "Nazneen Rajani, Kashif Rasul, Younes Belkada,\n",
      "Shengyi Huang, Leandro von Werra, Clémentine\n",
      "Fourrier, Nathan Habib, et al.  2023.  Zephyr: Di-\n",
      "rect distillation of lm alignment.  arXiv preprint\n",
      "arXiv:2310.16944 .\n",
      "\n",
      "Original Sentence:\n",
      " Lewis Tunstall, Edward Beeching, Nathan Lambert,\n",
      "Nazneen Rajani, Kashif Rasul, Younes Belkada,\n",
      "Shengyi Huang, Leandro von Werra, Clémentine\n",
      "Fourrier, Nathan Habib, et al. \n"
     ]
    }
   ],
   "source": [
    "# @title Check source node`s metadata window and origineal text\n",
    "print(\"Window:\\n\", window_response.source_nodes[0].node.metadata[\"window\"])\n",
    "print()\n",
    "print(\n",
    "    \"Original Sentence:\\n\",\n",
    "    window_response.source_nodes[0].node.metadata[\"original_text\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
