{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/Solar-Full-Stack LLM-101/05_3_OracleDB.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-3. LLMChain_OracleDB\n",
    "## Overview  \n",
    "In this exercise, we will explore how to leverage OracleDB to embed documents and create a vectorspace. You will learn how to develop a Retriever object and perform document searches efficiently. Furthermore, this tutorial will guide you through creating an LLM Chain integrated with a Retriever object, enhancing the capabilities of your search and retrieval processes.\n",
    " \n",
    "## Purpose of the Exercise\n",
    "The purpose of this exercise is to demonstrate how to integrate OracleDB with Python, utilize the Solar Embedding API to generate embeddings and create a vectorspace, and create a Retriever object to conduct searches within the vectorspace. By the end of this tutorial, users will also understand how to create an LLM Chain combined with a Retriever object, thereby improving the efficiency and accuracy of document retrieval using OracleDB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OracleVectorDB\n",
    "- benefits?\n",
    "- where to get KEYs and how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -qU python-dotenv PyPDF2 langchain langchain-community langchain-core langchain-text-splitters langchain_upstage oracledb python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title set API key\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "upstage_api_key_env_name = \"UPSTAGE_API_KEY\"\n",
    "oracle_db_user_env_name = \"ORACLE_DB_USER\"\n",
    "oracle_db_password_env_name = \"ORACLE_DB_PASSWORD\"\n",
    "oracle_dsn_env_name = \"ORACLE_DSN\"\n",
    "\n",
    "\n",
    "def load_env():\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        # Running in Google Colab\n",
    "        from google.colab import userdata\n",
    "\n",
    "        upstage_api_key = userdata.get(upstage_api_key_env_name)\n",
    "        oracle_db_user = userdata.get(oracle_db_user_env_name)\n",
    "        oracle_db_password = userdata.get(oracle_db_password_env_name)\n",
    "        oracle_dsn = userdata.get(oracle_dsn_env_name)\n",
    "        return (\n",
    "            os.environ.setdefault(upstage_api_key_env_name, upstage_api_key),\n",
    "            os.environ.setdefault(oracle_db_user_env_name, oracle_db_user),\n",
    "            os.environ.setdefault(oracle_db_password_env_name, oracle_db_password),\n",
    "            os.environ.setdefault(oracle_dsn_env_name, oracle_dsn),\n",
    "        )\n",
    "    else:\n",
    "        # Running in local Jupyter Notebook\n",
    "        from dotenv import load_dotenv\n",
    "\n",
    "        load_dotenv()\n",
    "        return (\n",
    "            os.environ.get(upstage_api_key_env_name),\n",
    "            os.environ.get(oracle_db_user_env_name),\n",
    "            os.environ.get(oracle_db_password_env_name),\n",
    "            os.environ.get(oracle_dsn_env_name),\n",
    "        )\n",
    "\n",
    "\n",
    "UPSTAGE_API_KEY, ORACLE_DB_USER, ORACLE_DB_PASSWORD, ORACLE_DSN = load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import array\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import oracledb\n",
    "from langchain_community.vectorstores import oraclevs\n",
    "from langchain_community.vectorstores.oraclevs import OracleVS\n",
    "\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_core.documents import BaseDocumentTransformer, Document\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful! 23.4.1.24.6\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn23c = oracledb.connect(\n",
    "        user=os.environ[\"ORACLE_DB_USER\"],\n",
    "        password=os.environ[\"ORACLE_DB_PASSWORD\"],\n",
    "        dsn=os.environ[\"ORACLE_DSN\"],\n",
    "    )\n",
    "    print(\"Connection successful!\", conn23c.version)\n",
    "except Exception as e:\n",
    "    print(\"Connection failed!\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
    "\n",
    "\n",
    "layzer = UpstageLayoutAnalysisLoader(\"pdfs/kim-tse-2008.pdf\", output_type=\"html\")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "docs = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 132\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "\n",
    "# 2. Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    chunk_size=1000, chunk_overlap=100, language=Language.HTML\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(\"Splits:\", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "upstage_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "knowledge_base = OracleVS.from_documents(\n",
    "    splits,\n",
    "    upstage_embeddings,\n",
    "    client=conn23c,\n",
    "    table_name=\"text_embeddings2\",\n",
    "    distance_strategy=DistanceStrategy.DOT_PRODUCT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = OracleVS(\n",
    "    client=conn23c,\n",
    "    embedding_function=upstage_embeddings,\n",
    "    table_name=\"text_embeddings2\",\n",
    "    distance_strategy=DistanceStrategy.DOT_PRODUCT,\n",
    ")\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 4\n",
      "<p id='56' data-category='paragraph' style='font-size:16px'>Change classification differs from previ\n"
     ]
    }
   ],
   "source": [
    "# Query the retriever\n",
    "result_docs = retriever.invoke(\"What is change classficiation?\")\n",
    "print(\"Results:\", len(result_docs))\n",
    "print(result_docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Please provide most correct answer from the following context. \n",
    "    If the answer is not present in the context, please write \"The information is not present in the context.\"\n",
    "    ---\n",
    "    Question: {question}\n",
    "    ---\n",
    "    Context: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Change classification is a process that differs from previous bug prediction work. It classifies changes and focuses on predicting whether there is a bug in any of the lines that were changed in one file in one SCM commit transaction. Unlike bug prediction work, change classification uses features from the source code, such as every variable, method call, operator, constant, comment text, and more, to train change classification models. It is also independent of the programming language and uses bug-introducing changes to label changes as buggy or clean with information about the source code at the moment a bug was introduced.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is change classficiation?\", \"context\": result_docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Change classification is a process that differs from previous bug prediction work in that it classifies changes, predicts whether there is a bug in any of the lines that were changed in one file in one SCM commit transaction, and uses every term in the source code as features to train change classification models. It is also independent of the programming language and uses bug-introducing changes.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put themm all together\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "rag_chain = setup_and_retrieval | prompt_template | llm | StrOutputParser()\n",
    "\n",
    "rag_chain.invoke(\"What is change classification?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
