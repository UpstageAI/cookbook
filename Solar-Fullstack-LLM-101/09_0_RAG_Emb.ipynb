{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/Solar-Fullstack-LLM-101/08_RAG.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09. RAG with Embeddings\n",
    "\n",
    "## Overview  \n",
    "In this exercise, we will explore Retrieval-Augmented Generation (RAG) using embeddings within the Solar framework. RAG combines retrieval-based techniques with generative models to improve the relevance and accuracy of generated responses. By incorporating embeddings, we can enhance the retrieval process, leading to more contextually appropriate information being used to augment the model's knowledge. This notebook will guide you through implementing RAG with embeddings and demonstrate its benefits in enhancing model outputs.\n",
    " \n",
    "## Purpose of the Exercise\n",
    "The purpose of this exercise is to integrate Retrieval-Augmented Generation using embeddings into the Solar framework. By the end of this tutorial, users will understand how to use RAG with embeddings to more effectively access and utilize external information. This approach will enable the generation of more informed and contextually accurate responses, thereby improving the performance and reliability of the language model beyond simple keyword-based retrieval methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with Embeddings: Enhanced Retrieval Augmented Generation\n",
    "- Large language models (LLMs) have a limited context size\n",
    "- Embeddings allow for semantic understanding of queries and documents\n",
    "- Not all context is relevant to a given question\n",
    "- Query → Embed → Retrieve (Semantic Search) → Results → (LLM) → Answer\n",
    "- RAG with embeddings combines LLMs with semantic retrieval for more accurate and relevant information augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install -qU  markdownify  langchain-upstage python-dotenv tokenizers chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title set API key\n",
    "import os\n",
    "import getpass\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Running in Google Colab. Please set the UPSTAGE_API_KEY in the Colab Secrets\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
    "else:\n",
    "    # Running locally. Please set the UPSTAGE_API_KEY in the .env file\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "if \"UPSTAGE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = getpass.getpass(\"Enter your Upstage API key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
    "\n",
    "\n",
    "layzer = UpstageLayoutAnalysisLoader(\n",
    "    \"pdfs/kim-tse-2008.pdf\", use_ocr=False, output_type=\"html\"\n",
    ")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "docs = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br><h1 id='2' style='font-size:22px'>Classifying Software Changes:<br>Clean or Buggy?</h1><br><p id='3' data-category='paragraph' style='font-size:18px'>Sunghun Kim, E. James Whitehead Jr., Member, IEEE, and Yi Zhang, Member, IEEE</p><p id='4' data-category='paragraph' style='font-size:16px'>Abstract—This paper introduces a new technique for predicting latent software bugs, called change classification. Change<br>classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or<br>clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using<br>features (in the machine learning sense) extracted from the revision history of a software project stored in its software configuration<br>management repository. The trained classifier can classify changes as buggy or clean, with a 78 percent accuracy and a 60 percent<br>buggy change recall on average. "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(docs[0].page_content[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "solar_tokenizer = AutoTokenizer.from_pretrained(\"upstage/solar-pro-preview-instruct\")\n",
    "\n",
    "token_splitter = TokenTextSplitter.from_huggingface_tokenizer(\n",
    "    solar_tokenizer, chunk_size=250, chunk_overlap=100\n",
    ")\n",
    "\n",
    "splits = token_splitter.split_documents(docs)\n",
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/04zh2c956c91b8hmrg1npwjc0000gn/T/ipykernel_64164/4133877751.py:8: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Initialize Upstage embeddings\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# Create Chroma vector store with Upstage embeddings\n",
    "db = Chroma(embedding_function=embeddings)\n",
    "\n",
    "# Add documents to the vector store\n",
    "db.add_documents(splits)\n",
    "\n",
    "# Define a retriever\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Please provide most correct answer from the following context. \n",
    "    If the answer is not present in the context, please write \"The information is not present in the context.\"\n",
    "    ---\n",
    "    Question: {question}\n",
    "    ---\n",
    "    Context: {Context}\n",
    "    \"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bug classification in<br>that features (terms) are also extracted from the source code<br>and are then fed into classification or clustering algorithms.<br>These projects have goals other than predicting bugs,<br>including classifying software into broad functional cate-<br>gories [19], clustering related software project documents<br>[20], [28], and associating the source code with other<br>artifacts such as design documents [29].</p><br><p id='47' data-category='paragraph' style='font-size:16px'>Krovetz et al. use terms in the source code (as features)<br>and SVM to classify software projects into broad functional<br>categories such as communications, databases, games, and<br>math [19]. Their insight is that software projects in the same<br>category will share terms in their source code, thereby<br>permitting classification.</p><br><p id='48' data-category='paragraph' style='font-size:16px'>Research that categorizes or associates source code with<br>other documents (traceability recovery) is similar to ours in\n"
     ]
    }
   ],
   "source": [
    "query = \"What is bug classficiation?\"\n",
    "context_docs = retriever.invoke(query)\n",
    "print(context_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bug classification is a technique used in software engineering to predict the existence of bugs in software changes. It uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or clean changes. The classifier is trained using features (in the machine learning sense) extracted from the revision history of a software project stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean, with a certain accuracy and recall on average. Change classification has several desirable qualities, including the ability to predict the existence of bugs in software changes.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": query, \"Context\": context_docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise \n",
    "How evalute the performance of RAG with embeddings?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
