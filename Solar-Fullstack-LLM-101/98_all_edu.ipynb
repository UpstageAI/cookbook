{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/Solar-Fullstack-LLM-101/98_all_edu.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upstage Solar Full Stack LLM 101\n",
    "## Code to Understand!\n",
    "![Overview](./figures/overview.png)\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "* <b> Session 1. Hello Solar </b> : Obtain an Upstage API Key and use the upstage chat model. <br>\n",
    "    - 1-1 Interacting with the Solar-1-mini-chat Model\n",
    "    - 1-2 Using Few-Shot Examples in Chat Completions\n",
    "\n",
    "\n",
    "- <b> Session 2. Building LLM Applications with LangChain</b> :  Learn how to easily implement LLM chains using LangChain and understand the features of LLMs.<br>\n",
    "    - 2-1 Prompt Engineering\n",
    "    - 2-2 Hallucinations\n",
    "    - 2-3 Groundedness Check with LangChain and Upstage\n",
    "\n",
    "\n",
    "- <b> Session 3. What is RAG? </b>:  Understand the concept of RAG, load documents, and implement a RAG system.<br>\n",
    "    - 3-1 Layout Analysis\n",
    "    - 3-2 Retrieval Augmented Generation (RAG) for Question Answering\n",
    "    - 3-3 RAG Limitations <br>\n",
    "\n",
    "\n",
    "- <b> Session 4. Efficient Text Splitting and Indexing with LangChain </b>:  Efficiently build a RAG system by loading external documents, splitting them into smaller chunks, using embedding APIs to store them in a vectorspace, and retrieving them.<br>\n",
    "\n",
    "- <b> Session 5. Gradio </b>: Use Gradio and RAG techniques to process PDF documents and generate real-time, interactive responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: typer 0.12.5 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install -qU guardrails-ai openai langchain_community langchain_experimental langchain-upstage sentence-transformers langchainhub langchain-chroma langchain matplotlib python-dotenv tavily-python ragas faiss-cpu tokenizers getpass4\n",
    "! pip3 install -q \"arize-phoenix[evals]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 1] HELLO SOLAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "<b> Introduction to Solar Framework </b>: Learn the basics of setting up the Solar LLM framework and running a simple \"Hello, World!\" example to understand its core functionality.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPSTAGE_API_KEY\n",
    "To obtain your Upstage API key, follow these steps:\n",
    "\n",
    "1. Visit the Upstage AI console at <https://console.upstage.ai>.\n",
    "2. Sign up for an account if you don't already have one.\n",
    "3. Log in to your account.\n",
    "4. Navigate to the API key section.\n",
    "5. Generate your API key.\n",
    "6. Copy the key and save it securely.\n",
    "\n",
    "![Console](./figures/console.upstage.ai.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# UPSTAGE_API_KEY from https://console.upstage.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title set API key\n",
    "import os\n",
    "import getpass\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Running in Google Colab. Please set the UPSTAGE_API_KEY in the Colab Secrets\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
    "else:\n",
    "    # Running locally. Please set the UPSTAGE_API_KEY in the .env file\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "if \"UPSTAGE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = getpass.getpass(\"Enter your Upstage API key: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1-1 Interacting with the Solar-1-mini-chat Model\n",
    "\n",
    "This Python code demonstrates how to use the OpenAI API to interact with the Solar-1-mini-chat model provided by Upstage AI.\n",
    "\n",
    "##### Steps\n",
    "\n",
    "1. Import necessary libraries: `os`, `openai`, and `pprint`.\n",
    "2. Set up the OpenAI client with the API key and base URL.\n",
    "3. Create a chat completion request using `client.chat.completions.create()`.\n",
    "   - Specify the model: \"solar-1-mini-chat\".\n",
    "   - Provide a list of messages, including the system message and user message.\n",
    "4. Handle the model's response:\n",
    "   - Print the entire response using `pprint()`.\n",
    "   - Print the content of the assistant's message using `response.choices[0].message.content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='7c74778a-bf9f-43ff-bec1-93558e43eff0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Ah, Korea. A fascinating place with a rich history and vibrant culture. I've always wanted to visit Seoul, explore the ancient palaces, and try the delicious street food. The fusion of traditional and modern elements in Korean society is truly intriguing. Plus, I've heard their public transportation system is top-notch, which would make it easy for me to get around and immerse myself in the local life.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1724632190, model='solar-1-mini-chat-240612', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=91, prompt_tokens=26, total_tokens=117))\n",
      "Message only:\n",
      "(\"Ah, Korea. A fascinating place with a rich history and vibrant culture. I've \"\n",
      " 'always wanted to visit Seoul, explore the ancient palaces, and try the '\n",
      " 'delicious street food. The fusion of traditional and modern elements in '\n",
      " \"Korean society is truly intriguing. Plus, I've heard their public \"\n",
      " 'transportation system is top-notch, which would make it easy for me to get '\n",
      " 'around and immerse myself in the local life.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"UPSTAGE_API_KEY\"], base_url=\"https://api.upstage.ai/v1/solar\"\n",
    ")\n",
    "chat_result = client.chat.completions.create(\n",
    "    model=\"solar-1-mini-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What about Korea?\"},\n",
    "    ],\n",
    ")\n",
    "pprint(chat_result)\n",
    "print(\"Message only:\")\n",
    "pprint(chat_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2 Using Few-Shot Examples in Chat Completions\n",
    "\n",
    "This Python code demonstrates how to use few-shot examples in the OpenAI Chat Completions API to provide context and guide the model's responses.\n",
    "\n",
    "##### Steps\n",
    "\n",
    "1. Set up the OpenAI client with the API key and base URL.\n",
    "2. Create a chat completion request using `client.chat.completions.create()`.\n",
    "   - Specify the model: \"solar-1-mini-chat\".\n",
    "   - Provide a list of messages, including:\n",
    "     - System message: Defines the assistant's role.\n",
    "     - Few-shot examples: Provide context and desired behavior.\n",
    "     - User input: The actual user query.\n",
    "3. Handle the model's response:\n",
    "   - Print the entire response using `pprint()`.\n",
    "   - Print the content of the assistant's message using `response.choices[0].message.content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='be7d1d1d-58ad-4ae5-a804-5eb1cccdc270', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, Korea! There's North Korea and South Korea. The capital of North Korea is Pyongyang, and the capital of South Korea is Seoul.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1724632210, model='solar-1-mini-chat-240612', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=35, prompt_tokens=55, total_tokens=90))\n",
      "Message only:\n",
      "(\"Oh, Korea! There's North Korea and South Korea. The capital of North Korea \"\n",
      " 'is Pyongyang, and the capital of South Korea is Seoul.')\n"
     ]
    }
   ],
   "source": [
    "# few shots: examples or history\n",
    "chat_result = client.chat.completions.create(\n",
    "    model=\"solar-1-mini-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        # examples\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"I know of it. It's Paris!!\",\n",
    "        },\n",
    "        # user input\n",
    "        {\"role\": \"user\", \"content\": \"What about Korea?\"},\n",
    "    ],\n",
    ")\n",
    "pprint(chat_result)\n",
    "print(\"Message only:\")\n",
    "pprint(chat_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 2] Building LLM Applications with LangChain\n",
    "\n",
    "This Python code demonstrates how to use the LangChain library to build applications with Large Language Models (LLMs). It covers the basic steps of defining an LLM, creating a chat prompt, defining a chain, and invoking the chain.\n",
    "\n",
    "#### Steps\n",
    "\n",
    "1. Define your favorite LLM:\n",
    "   - Import the `ChatUpstage` class from `langchain_upstage`.\n",
    "   - Create an instance of `ChatUpstage` and assign it to the variable `llm`.\n",
    "\n",
    "2. Define a chat prompt:\n",
    "   - Import the `ChatPromptTemplate` class from `langchain_core.prompts`.\n",
    "   - Create a `ChatPromptTemplate` instance using the `from_messages()` method.\n",
    "   - Provide a list of messages, including system messages, example conversations, and user input.\n",
    "\n",
    "3. Define a chain:\n",
    "   - Import the `StrOutputParser` class from `langchain_core.output_parsers`.\n",
    "   - Create a chain by combining the `rag_with_history_prompt`, `llm`, and `StrOutputParser()` using the pipe (`|`) operator.\n",
    "\n",
    "4. Invoke the chain:\n",
    "   - Call the `invoke()` method on the `chain` object, passing an empty dictionary (`{}`) as the input.\n",
    "   - Print the response obtained from the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a computer program, so I don't have feelings or emotions. I'm here to assist you with any questions or tasks you may have. Is there anything specific I can help you with today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 16, 'total_tokens': 64}, 'model_name': 'solar-1-mini-chat-240612', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-064e5d40-ead8-4fa9-a387-dcabf79b6c0c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 48, 'total_tokens': 64})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick hello world\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "llm = ChatUpstage()\n",
    "llm.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, Korea! It's a bit more complicated than France. There are two Koreas: North Korea and South Korea. The capital of South Korea is Seoul, while the capital of North Korea is Pyongyang.\n"
     ]
    }
   ],
   "source": [
    "# langchain, 1. llm define, 2. prompt define, 3. chain, 4. chain.invoke\n",
    "\n",
    "# 1. define your favorate llm, solar\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "# 2. define chat prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"What is the capital of France?\"),\n",
    "        (\"ai\", \"I know of it. It's Paris!!\"),\n",
    "        (\"human\", \"What about Korea?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 3. define chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. invoke the chain\n",
    "c_result = chain.invoke({})\n",
    "print(c_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameterized Prompt Templates in LangChain\n",
    "\n",
    "##### Overview\n",
    "\n",
    "- Prompt templates allow for reusable and modular prompts\n",
    "- They improve maintainability compared to using raw prompt strings\n",
    "- {country} value can be set from outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, I remember now! It's Seoul!!\n",
      "---\n",
      "I know, I know! Tokyo, that's right!\n"
     ]
    }
   ],
   "source": [
    "# parameterized prompt template\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"What is the capital of France?\"),\n",
    "        (\"ai\", \"I know of it. It's Paris!!\"),\n",
    "        (\"human\", \"What about {country}?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. invoke chain with param\n",
    "print(chain.invoke({\"country\": \"Korea\"}))\n",
    "print(\"---\")\n",
    "print(chain.invoke({\"country\": \"Japan\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leveraging Message History in LangChain Prompts\n",
    "\n",
    "- LangChain provides powerful tools for managing conversation history\n",
    "- `MessagesPlaceholder` allows for dynamic inclusion of message history\n",
    "- `HumanMessage` and `AIMessage` classes represent individual messages\n",
    "- Combining message history with user input enables context-aware responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of South Korea is Seoul, while the capital of North Korea is Pyongyang.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# More general chat\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "history = [\n",
    "    HumanMessage(\"What is the capital of France?\"),\n",
    "    AIMessage(\"It's Paris!!\"),\n",
    "]\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "chain_result = chain.invoke({\"history\": history, \"input\": \"What about Korea?\"})\n",
    "print(chain_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain of Thought Prompting\n",
    "\n",
    "![CoT](figures/cot.webp)\n",
    "\n",
    "from https://arxiv.org/abs/2201.11903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cafeteria started with 23 apples. They used 20 for lunch, so they had:\\n\\n23 - 20 = 3 apples left.\\n\\nThen they bought 6 more apples, so they had:\\n\\n3 + 6 = 9 apples.\\n\\nTherefore, the cafeteria has 9 apples.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Q: The cafeteria had 23 apples. \n",
    "If they used 20 to make lunch and bought 6 more, \n",
    "how many apples do they have?\n",
    "\n",
    "A: the answer is\n",
    "\"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cafeteria started with 23 apples. They used 20, so they had 23 - 20 = 3 apples left. Then they bought 6 more apples, so they had 3 + 6 = 9 apples. The answer is 9.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls\n",
    "each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
    "\n",
    "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learn more advanced techniques by reading blog posts on Prompt Engineering!\n",
    "\n",
    "\n",
    "1. [[Prompt Engineering - Part 1] Maximizing the Use of LLM with Prompt Design](https://www.upstage.ai/feed/insight/prompt-engineering-guide-maximizing-the-use-of-llm-with-prompt-design)\n",
    "2. [[Prompt Engineering - Part 2] The Essence of Prompt Engineering: A Comprehensive Guide to Maximizing LLM Usage](https://www.upstage.ai/feed/insight/prompt-engineering-guide-to-maximizing-llm-usage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Hallucinations\n",
    "\n",
    "<b> Understanding Model Hallucinations </b> : Discover how to identify, understand, and mitigate hallucinations to ensure accurate and reliable model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hallucination](./figures/hallucination.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Upstage DUS technique is a method used in the film and television industry to create the illusion of depth and movement on a flat screen. It involves the use of a camera that is mounted on a special rig that allows it to move in a way that simulates the perspective of a human eye. This creates a more natural and immersive experience for the viewer, as it mimics the way we perceive depth and movement in the real world. The technique was developed by filmmaker and inventor, David E. Williams, and has been used in a number of high-profile productions, including the popular TV series \"Game of Thrones.\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 135, 'prompt_tokens': 18, 'total_tokens': 153}, 'model_name': 'solar-1-mini-chat-240612', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1e342939-5da4-4377-be1a-54b10ff855bf-0', usage_metadata={'input_tokens': 18, 'output_tokens': 135, 'total_tokens': 153})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cannot say \"I don't know\" :-)\n",
    "# Because it is trained to complete the sentence and try to answer the question\n",
    "llm.invoke(\"What is Upstage DUS technique?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Token Prediction\n",
    "They are designed to generate the next words. It's also very difficult to know what we don't know.\n",
    "\n",
    "![image](https://jalammar.github.io/images/xlnet/gpt-2-autoregression-2.gif)\n",
    "\n",
    "Image from https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Can We Mitigate Hallucinations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 Groundedness Check with LangChain and Upstage\n",
    "![Groundedness](./figures/gc.png)\n",
    "\n",
    "[Groundedness Check](https://developers.upstage.ai/docs/apis/groundedness-check)\n",
    "\n",
    "#### High-Level Overview\n",
    "\n",
    "The provided code demonstrates how to perform a groundedness check using the LangChain library and the Upstage model. The groundedness check is a process of verifying whether the generated response is grounded in the given context. This is an important step in ensuring the quality and relevance of the generated output.\n",
    "\n",
    "The code uses the `UpstageGroundednessCheck` class from the `langchain_upstage` module to perform the groundedness check. It takes the context (a string of unique documents) and the generated response as input, and returns a verdict indicating whether the response is grounded or not.\n",
    "\n",
    "#### Detailed Explanation\n",
    "\n",
    "1. The code starts by importing the necessary module:\n",
    "   - `UpstageGroundednessCheck` from `langchain_upstage`: This class is used to perform the groundedness check.\n",
    "   \n",
    "\n",
    "2. An instance of the `UpstageGroundednessCheck` class is created and assigned to the variable `groundedness_check`.\n",
    "\n",
    "3. The input for the groundedness check is prepared by creating a dictionary called `request_input`:\n",
    "   - The `\"context\"` key is assigned the value of `str(unique_docs)`, which represents the unique documents as a string.\n",
    "   - The `\"answer\"` key is assigned the value of `response`, which represents the generated response.\n",
    "   \n",
    "\n",
    "4. The `invoke` method of the `groundedness_check` instance is called with the `request_input` as an argument. This method performs the groundedness check and returns the verdict.\n",
    "\n",
    "5. The verdict is stored in the `gc_result` variable and printed to the console using `print(gc_result)`.\n",
    "\n",
    "6. The code then checks if the `gc_result` starts with the word \"grounded\" (case-insensitive):\n",
    "   - If the response starts with \"grounded\", it means the groundedness check has passed, and the message \"✅ Groundedness check passed\" is printed.\n",
    "   - If the response does not start with \"grounded\", it means the groundedness check has failed, and the message \"❌ Groundedness check failed\" is printed.\n",
    "\n",
    "\n",
    "The provided code demonstrates a simple yet effective way to perform a groundedness check using LangChain and Upstage. By verifying whether the generated response is grounded in the given context, it helps ensure the quality and relevance of the output.\n",
    "\n",
    "Groundedness checks are an important step in building reliable and trustworthy language models and conversational agents. They help prevent the generation of irrelevant, inconsistent, or factually incorrect responses.\n",
    "\n",
    "By using the `UpstageGroundednessCheck` class from LangChain, developers can easily integrate groundedness checks into their language model pipelines and improve the overall performance of their systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grounded\n",
      "✅ Groundedness check passed\n"
     ]
    }
   ],
   "source": [
    "# GC\n",
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "groundedness_check = UpstageGroundednessCheck()\n",
    "\n",
    "context = \"DUS is a new approach developed by Upstage to improve the search quality.\"\n",
    "answer = \"DUS is developed by Upstage.\"\n",
    "\n",
    "request_input = {\n",
    "    \"context\": context,\n",
    "    \"answer\": answer,\n",
    "}\n",
    "gc_result = groundedness_check.invoke(request_input)\n",
    "\n",
    "print(gc_result)\n",
    "if gc_result.lower().startswith(\"grounded\"):\n",
    "    print(\"✅ Groundedness check passed\")\n",
    "else:\n",
    "    print(\"❌ Groundedness check failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Groundedness check failed\n"
     ]
    }
   ],
   "source": [
    "context = \"DUS is a new approach developed by Upstage to improve the search quality.\"\n",
    "answer = \"DUS is developed by Google.\"\n",
    "\n",
    "request_input = {\n",
    "    \"context\": context,\n",
    "    \"answer\": answer,\n",
    "}\n",
    "gc_result = groundedness_check.invoke(request_input)\n",
    "\n",
    "if gc_result.lower().startswith(\"grounded\"):\n",
    "    print(\"✅ Groundedness check passed\")\n",
    "else:\n",
    "    print(\"❌ Groundedness check failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 3] What is RAG?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide context and allow the language model to respond within that context only.\n",
    "\n",
    "![Overview](./figures/rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 Layout Analysis\n",
    "\n",
    "Leveraging Layout Analyzer and LangChain for Efficient Text Splitting and Vectorization\n",
    "\n",
    "- Upstage Layout Analyzer extracts layouts, tables, and figures from any document\n",
    "- LangChain provides powerful tools for text splitting and vectorization\n",
    "\n",
    "![Layout Analyzer](./figures/la.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import (\n",
    "    UpstageLayoutAnalysisLoader,\n",
    "    UpstageGroundednessCheck,\n",
    "    ChatUpstage,\n",
    "    UpstageEmbeddings,\n",
    ")\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "layzer = UpstageLayoutAnalysisLoader(\"pdfs/solar_paper.pdf\", output_type=\"html\")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "docs = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"<h1 id='0' style='font-size:20px'>SOLAR 10.7B: Scaling Large Language Models \"\n",
      " 'with Simple yet Effecti')\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    pprint(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 id='0' style='font-size:20px'>SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective<br>Depth Up-Scaling</h1><br><p id='1' data-category='paragraph' style='font-size:18px'>Dahyun Kim∗, Chanjun Park∗†, Sanghoon Kim∗†, Wonsung Lee∗†, Wonho Song∗<br>Yunsu Kim∗, Hyeonwoo Kim∗, Yungi Kim, Hyeonju Lee, Jihoo Kim<br>Changbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim<br>Mikyoung Cha, Hwalsuk Lee†, Sunghun Kim†</p><p id='2' data-category='paragraph' style='font-size:18px'>Upstage AI, South Korea</p><br><p id='3' data-category='paragraph' style='font-size:14px'>{kdahyun, chanjun.park, limerobot, wonsung.lee, hwalsuk.lee, hunkim}@upstage.ai</p><br><p id='4' data-category='paragraph' style='font-size:18px'>Abstract</p><br><p id='5' data-category='paragraph' style='font-size:14px'>We introduce SOLAR 10.7B, a large language<br>model (LLM) with 10.7 billion parameters,<br>demonstrating superior performance in various<br>natural language processing (NLP) tasks. "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(docs[0].page_content[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 Retrieval Augmented Generation (RAG) for Question Answering\n",
    "\n",
    "- RAG combines retrieval and generation to enhance LLM performance on specific tasks\n",
    "- Relevant context is retrieved from external data sources and added to the prompt\n",
    "- The augmented prompt is then passed to the LLM for generating a response\n",
    "- RAG is particularly useful for question answering on custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE1\n",
      " The performance comparison amongst the merge candidates is presented in Table 6. The table shows the scores for the H6 average and individual tasks for two merge candidates, 'Cand. 1' and 'Cand. 2'. 'Cand. 1' is trained using the same setting as 'DPO v2', while 'Cand. 2' is trained using the same setting as 'DPO v3', but with slightly different hyper-parameters.\n",
      "\n",
      "From the table, we can see that 'Cand. 1' has high scores for the GSM8K task, but relatively low scores for the other tasks. On the other hand, 'Cand. 2' has low scores for the GSM8K task, but high scores for the other tasks. This indicates that 'Cand. 1' and 'Cand. 2' have different strengths and weaknesses, which can be beneficial for performance when merged.\n"
     ]
    }
   ],
   "source": [
    "# More general chat\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question considering the history of the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "---\n",
    "CONTEXT:\n",
    "{context}\n",
    "         \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "history = []\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "query1 = \"Performance comparison amongst the merge candidate\"\n",
    "response1 = chain.invoke({\"history\": history, \"context\": docs, \"input\": query1})\n",
    "print(\"RESPONSE1\\n\", response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE2\n",
      " The ablation studies presented in the provided text cover two main areas: instruction tuning and alignment tuning.\n",
      "\n",
      "**Instruction Tuning Ablation Studies:**\n",
      "\n",
      "1. **Ablation on the training datasets:** The authors present ablation studies using different training datasets for the instruction tuning. They use the Alpaca-GPT4 dataset, OpenOrca dataset, and a synthesized math dataset called Synth. Math-Instruct. They find that using the Synth. Math-Instruct dataset is beneficial and that merging models trained with and without OpenOrca can boost performance.\n",
      "\n",
      "2. **Ablation on the model merging strategy:** They experiment with merging the models trained with and without OpenOrca. They find that merging these models is beneficial and that the exact merge method may not be as crucial as long as the merge candidates have sufficiently different strengths.\n",
      "\n",
      "**Alignment Tuning Ablation Studies:**\n",
      "\n",
      "1. **Ablation on the training datasets:** They present ablation studies using different alignment datasets during direct preference optimization (DPO). They use the Ultrafeedback Clean dataset and the Synth. Math-Alignment dataset. They find that adding Synth. Math-Alignment is beneficial for H6 (average of six tasks).\n",
      "\n",
      "2. **Ablation on the SFT base models:** They use different instruction-tuned models as the base models for alignment tuning. They find that using a merged model as the base model for alignment tuning can result in a model with high scores for all tasks.\n",
      "\n",
      "3. **Ablation on different merge methods:** They train two models with different strengths and merge them using various methods. They find that the different merge methods have little effect on the H6 scores, and the scores for the individual tasks also do not differ by much.\n",
      "\n",
      "In summary, the ablation studies show that using the Synth. Math-Instruct dataset and merging models with different strengths can improve the performance of the instruction-tuned models. For the alignment-tuned models, adding the Synth. Math-Alignment dataset and using a merged model as the base model can also improve performance.\n"
     ]
    }
   ],
   "source": [
    "history = [HumanMessage(query1), AIMessage(response1)]\n",
    "query2 = \"How about Ablation studies?\"\n",
    "response2 = chain.invoke({\"history\": history, \"context\": docs, \"input\": query2})\n",
    "print(\"RESPONSE2\\n\", response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3  RAG Limitations\n",
    "- LLM does not have long enough context length\n",
    "- Sending long, irrelevant info is inefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load something big\n",
    "layzer = UpstageLayoutAnalysisLoader(\n",
    "    \"pdfs/kim-tse-2008.pdf\", output_type=\"html\", use_ocr=True\n",
    ")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "docs = layzer.load()  # or layzer.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"This model's maximum context length is 32768 tokens. However, your messages resulted in 36014 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "# More general chat\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question considering the history of the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "---\n",
    "CONTEXT:\n",
    "{context}\n",
    "         \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser\n",
    "()\n",
    "query1 = \"What is bug classification?\"\n",
    "\n",
    "try:\n",
    "    response1 = chain.invoke({\"history\": history, \"context\": docs, \"input\": query1})\n",
    "    print(response1)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107251\n"
     ]
    }
   ],
   "source": [
    "print(len(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_pretrained(\"upstage/solar-1-mini-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded input: ['<|startoftext|>', '▁Nice', '▁to', '▁meet', '▁you', '.', '▁I', '▁am', '▁Solar', '▁LL', 'M', ',', '▁a', '▁large', '▁language', '▁model', '▁developed', '▁by', '▁Up', 'stage', '.', '▁If', '▁you', '▁have', '▁any', '▁questions', ',', '▁please', '▁feel', '▁free', '▁to', '▁ask', '.']\n",
      "Number of tokens: 33\n"
     ]
    }
   ],
   "source": [
    "text = \"Nice to meet you. I am Solar LLM, a large language model developed by Upstage. If you have any questions, please feel free to ask.\"\n",
    "\n",
    "enc = tokenizer.encode(text)\n",
    "print(\"Encoded input:\", enc.tokens)\n",
    "\n",
    "number_of_tokens = len(enc.tokens)\n",
    "print(\"Number of tokens:\", number_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded input: ['<|startoftext|>', '▁만나', '서', '▁반가', '워', '요', '.', '▁저는', '▁Up', 'stage', '에서', '▁개발한', '▁대규모', '▁언어', '▁모델', '인', '▁Solar', '▁LL', 'M', '▁입니다', '.', '▁궁금한', '▁것이', '▁있으', '시면', '▁무엇이', '든', '▁물어', '보세요', '.']\n",
      "Number of tokens: 30\n"
     ]
    }
   ],
   "source": [
    "text = \"만나서 반가워요. 저는 Upstage에서 개발한 대규모 언어 모델인 Solar LLM 입니다. 궁금한 것이 있으시면 무엇이든 물어보세요.\"\n",
    "enc = tokenizer.encode(text)\n",
    "print(\"Encoded input:\", enc.tokens)\n",
    "\n",
    "number_of_tokens = len(enc.tokens)\n",
    "print(\"Number of tokens:\", number_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_tokens(text):\n",
    "    return len(tokenizer.encode(text).tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG 33\n",
      "KOR 30\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"ENG\",\n",
    "    num_of_tokens(\n",
    "        \"Nice to meet you. I am Solar LLM, a large language model developed by Upstage. If you have any questions, please feel free to ask.\"\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"KOR\",\n",
    "    num_of_tokens(\n",
    "        \"만나서 반가워요. 저는 Upstage에서 개발한 대규모 언어 모델인 Solar LLM 입니다. 궁금한 것이 있으시면 무엇이든 물어보세요.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String length 107251\n",
      "Number of tokens 34961\n"
     ]
    }
   ],
   "source": [
    "# Recall\n",
    "# Let's load something big\n",
    "# layzer = UpstageLayoutAnalysisLoader(\"pdfs/kim-tse-2008.pdf\", output_type=\"html\")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "# docs = layzer.load()  # or layzer.lazy_load()\n",
    "print(\"String length\", len(docs[0].page_content))\n",
    "print(\"Number of tokens\", num_of_tokens(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 4] Efficient Text Splitting and Indexing with LangChain\n",
    "\n",
    "\n",
    "### Steps\n",
    "<b> 1. Load Documents </b>\n",
    "\n",
    "The first step is to load the source documents that will be used to augment the language model's knowledge\n",
    "This could be done by reading files from disk, pulling from a database, scraping web pages, etc.\n",
    "The goal is to get the raw text content into a format that can be further processed\n",
    "\n",
    "<b>2. Chunking/Splitting</b>\n",
    "\n",
    "* Long documents need to be broken down into smaller chunks that are a manageable size for embedding and retrieval\n",
    "Common approaches include:\n",
    "  * Fixed-size chunking - split text into equal sized chunks based on character or token count \n",
    "  * Semantic chunking - split based on semantic boundaries like sentences, paragraphs, or sections\n",
    "  * Hierarchical chunking - create chunks at multiple levels of granularity\n",
    "The ideal chunk size depends on the embedding model, retrieval use case, and downstream task\n",
    "\n",
    "<b>3. Embedding & Indexing</b>\n",
    "\n",
    "* The text chunks are converted to vector embeddings using a model like Upstage embeddings\n",
    "* The embeddings are indexed and stored in a vector database to enable efficient similarity search \n",
    "* Metadata about the source chunks can also be stored alongside the embeddings\n",
    "\n",
    "<b>4. Retrieval</b>\n",
    "\n",
    "* At query time, the user's question is itself embedded as a query vector\n",
    "* The query embedding is used to find the most similar document chunks in the vector index \n",
    "* Top-k most relevant chunks are retrieved and can be used to augment the prompt sent to the language model to generate an answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RecursiveCharacterTextSplitter\n",
    "\n",
    " `RecursiveCharacterTextSplitter` class is designed to be recursively split so that semantically related pieces remain together. <br>\n",
    " During this process, a list of delimiter characters `(['\\n\\n', '\\n', ' ', ''])` is used sequentially to partition the text. \n",
    "- This splitting continues until the resulting chunks are smaller than the specified `chunk_size`. \n",
    "- The `chunk_overlap` parameter defines the number of characters that should overlap between the divided text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 1. load doc (done), 2. chunking, splits, 3. embeding - indexing, 4. retrieve\n",
    "\n",
    "# layzer = UpstageLayoutAnalysisLoader(\"pdfs/kim-tse-2008.pdf\", output_type=\"html\")\n",
    "# # For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "# docs = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 129\n"
     ]
    }
   ],
   "source": [
    "# 2. Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(\"Splits:\", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "split_lengths = [len(split.page_content) for split in splits]\n",
    "\n",
    "# Create a bar graph\n",
    "plt.bar(range(len(split_lengths)), split_lengths)\n",
    "plt.title(\"RecursiveCharacterTextSplitter\")\n",
    "plt.xlabel(\"Split Index\")\n",
    "plt.ylabel(\"Split Content Length\")\n",
    "plt.xticks(range(len(split_lengths)), [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.13 s, sys: 208 ms, total: 3.34 s\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3. Embed & indexing\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, embedding=UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<h1 id='2' style='font-size:22px'>Classifying Software Changes:<br>Clean or Buggy?</h1><br><p id='3'\n"
     ]
    }
   ],
   "source": [
    "# 4. retrive\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "result_docs = retriever.invoke(\"What is Bug Classification?\")\n",
    "print(len(result_docs))\n",
    "print(result_docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SemanticChunker\n",
    "\n",
    "SemanticChunker is an experimental feature in LangChain that serves to split text into semantically similar chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overview](./figures/semantic_chunker.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2. SemanticChunker Split\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "def semantic_chunker(\n",
    "    docs,\n",
    "    min_chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    max_chunk_size=1000,\n",
    "    merge_threshold=0.7,\n",
    "    embeddings=UpstageEmbeddings(model=\"solar-embedding-1-large\"),\n",
    "):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=min_chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    init_splits = text_splitter.split_documents(docs)\n",
    "    splits = []\n",
    "\n",
    "    base_split_text = None\n",
    "    base_split_emb = None\n",
    "    for split in init_splits:\n",
    "        if base_split_text is None:\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = embeddings.embed_documents([base_split_text])[0]\n",
    "            continue\n",
    "\n",
    "        split_emb = embeddings.embed_documents([split.page_content])[0]\n",
    "        distance = cosine_similarity(X=[base_split_emb], Y=[split_emb])\n",
    "        if (\n",
    "            distance[0][0] < merge_threshold\n",
    "            or len(base_split_text) + len(split.page_content) > max_chunk_size\n",
    "        ):\n",
    "            splits.append(Document(page_content=base_split_text))\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = split_emb\n",
    "        else:\n",
    "            base_split_text += split.page_content\n",
    "\n",
    "    if base_split_text:\n",
    "        splits.append(Document(page_content=base_split_text))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFaceEmbeddings\n",
    "Since it's just an approximation, it's acceptable to use very light embedding models like KLUE, https://huggingface.co/klue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SuWanKim1/miniconda3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "No sentence-transformers model found with name klue/roberta-small. Creating a new one with mean pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.83 s, sys: 1.28 s, total: 4.12 s\n",
      "Wall time: 4.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "hfembeddings = HuggingFaceEmbeddings(model_name=\"klue/roberta-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemanticChunker Splits: 241\n",
      "CPU times: user 13.4 s, sys: 1.64 s, total: 15 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "semantic_splits = semantic_chunker(docs, merge_threshold=0.8, embeddings=hfembeddings)\n",
    "print(\"SemanticChunker Splits:\", len(semantic_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "split_lengths = [num_of_tokens(split.page_content) for split in semantic_splits]\n",
    "\n",
    "# Create a bar graph\n",
    "plt.bar(range(len(split_lengths)), split_lengths)\n",
    "plt.xlabel(\"Split Index\")\n",
    "plt.ylabel(\"Split Content Length\")\n",
    "plt.title(\"Semantic Chunker Split Page Content Lengths\")\n",
    "plt.xticks(range(len(split_lengths)), [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChromaParallel Class: Parallel Document Embedding\n",
    "The ChromaParallel class is an extension of the Chroma class to enable parallel processing of document embedding and storage using multiple worker processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chroma is an AI-native open source vector database designed to enhance developer productivity and satisfaction. It is licensed under the Apache 2.0 license. \n",
    "\n",
    "- <b> Generate Vectorspace </b> : The `from_documents` class method creates a vector store from a list of documents.\n",
    "\n",
    "##### Reference\n",
    "\n",
    "* [Chroma LangChain Documentation](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/)\n",
    "* [Chroma Official Documentation](https://docs.trychroma.com/getting-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "class ChromaParallel(Chroma):\n",
    "\n",
    "    async def afrom_documents(documents, embedding, num_workers=2):\n",
    "        db = Chroma(embedding_function=embedding)\n",
    "        # create list of num_workers empty lists\n",
    "        doc_groups = [[] for _ in range(num_workers)]\n",
    "\n",
    "        for i in range(len(documents)):\n",
    "            doc_groups[i % num_workers].append(documents[i])\n",
    "\n",
    "        tasks = [db.aadd_documents(group) for group in doc_groups]\n",
    "        await asyncio.gather(*tasks)\n",
    "        return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='correct classifications of<br>the type (nb→b) over the total number of classificationsthat<br>resulted in a bug outcome. Put another way, if the change<br>classifier predicts that athat a change is buggy, what fraction of<br>these changes really contains a bug?</p><figure><img'\n",
      "Wall time: 22.16 sec\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "now = time.time()\n",
    "\n",
    "# 3. Embed & indexing\n",
    "loop = asyncio.get_event_loop()\n",
    "semantic_vectorstore = await ChromaParallel.afrom_documents(\n",
    "    documents=semantic_splits,\n",
    "    embedding=UpstageEmbeddings(model=\"solar-embedding-1-large\"),\n",
    "    num_workers=3,\n",
    ")\n",
    "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 4. retrive\n",
    "result_docs = semantic_retriever.invoke(\"What is Bug Classification?\")\n",
    "print(result_docs[1])\n",
    "print(f\"Wall time: {time.time() - now:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug classification is a process of categorizing software bugs based on their characteristics, such as the type of error, the component affected, the severity of the issue, or the root cause. This process helps developers and testers to prioritize and manage bugs more effectively.\n",
      "\n",
      "Bug classification typically works by following these steps:\n",
      "\n",
      "1. **Identification**: The first step is to identify the bug. This is usually done through testing or user reports.\n",
      "\n",
      "2. **Reporting**: The bug is then reported, usually through a bug tracking system, where it is assigned a unique identifier.\n",
      "\n",
      "3. **Analysis**: The bug is analyzed to determine its nature, severity, and impact on the software. This analysis may involve reproducing the bug, investigating its cause, and assessing how it affects the software's functionality.\n",
      "\n",
      "4. **Categorization**: Based on the analysis, the bug is classified into a specific category. This categorization can be done using predefined categories or custom categories specific to the project.\n",
      "\n",
      "5. **Prioritization**: Once the bug is classified, it is prioritized based on its severity, impact, and other factors. This prioritization helps developers to focus on the most critical bugs first.\n",
      "\n",
      "6. **Resolution**: The bug is then fixed by the development team, and once it is resolved, it is marked as \"closed\" or \"fixed\" in the bug tracking system.\n",
      "\n",
      "7. **Verification**: The fixed bug is verified to ensure that it has been resolved correctly and does not introduce new issues.\n",
      "\n",
      "By classifying bugs in this way, development teams can better manage their bug backlog, allocate resources more efficiently, and ensure that the most critical issues are addressed first.\n"
     ]
    }
   ],
   "source": [
    "# Finally query using RAG\n",
    "query = \"What is bug classification? How it works?\"\n",
    "result_docs = semantic_retriever.invoke(query)\n",
    "\n",
    "gc_result = chain.invoke({\"history\": history, \"context\": result_docs, \"input\": query})\n",
    "print(gc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying bugs is beneficial for several reasons:\n",
      "\n",
      "1. **Prioritization**: By categorizing bugs based on their severity, impact, and other factors, development teams can prioritize their work and focus on the most critical issues first. This helps to ensure that the most pressing problems are addressed promptly, improving the overall quality of the software.\n",
      "\n",
      "2. **Efficiency**: Classifying bugs allows teams to manage their workload more effectively. They can assign bugs to specific team members based on their expertise or availability, streamlining the bug fixing process.\n",
      "\n",
      "3. **Transparency**: A well-defined bug classification system provides transparency into the bug tracking process. This enables stakeholders, such as project managers, to understand the current state of the software and make informed decisions about resource allocation and project timelines.\n",
      "\n",
      "4. **Improved Communication**: Clear bug classification categories facilitate better communication within the development team and between the team and other stakeholders. Everyone involved in the project can understand the nature and severity of the bugs, making it easier to coordinate efforts and track progress.\n",
      "\n",
      "5. **Quality Assurance**: Bug classification helps in identifying patterns and trends in the types of bugs that occur in the software. This information can be used to improve the development process, prevent similar bugs from occurring in the future, and enhance the overall quality of the software.\n",
      "\n",
      "6. **Customer Satisfaction**: By effectively managing and resolving bugs, development teams can improve the user experience and increase customer satisfaction. This can lead to better product adoption, positive reviews, and increased customer loyalty.\n",
      "\n",
      "In summary, bug classification is a crucial part of the software development process that helps teams to manage their workload, improve communication, and ensure that the software is of high quality and meets user expectations.\n"
     ]
    }
   ],
   "source": [
    "history = [HumanMessage(query), AIMessage(gc_result)]\n",
    "\n",
    "query = \"Why it is good?\"\n",
    "result_docs = semantic_retriever.invoke(query)\n",
    "\n",
    "gc_result = chain.invoke({\"history\": history, \"context\": result_docs, \"input\": query})\n",
    "print(gc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For an in-depth look at the different types of RAG, please refer to the files '09. Smart RAG' and '10. Tool_RAG'.\n",
    "\n",
    "- [09. Smart RAG.ipynb](https://github.com/UpstageAI/cookbook/blob/main/cookbooks/upstage/Solar-Full-Stack-LLM-101/09_Smart_RAG.ipynb)\n",
    "- [10. Tool_RAG.ipynb](https://github.com/UpstageAI/cookbook/blob/main/cookbooks/upstage/Solar-Full-Stack-LLM-101/10_tool_RAG.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Session 5] Gradio\n",
    "\n",
    "<b> Comprehensive RAG System for PDFs </b> : Use Gradio and RAG techniques to process PDF documents and generate real-time, interactive responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU gradio python-dotenv langchain-upstage python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "from langchain_upstage import (\n",
    "    ChatUpstage,\n",
    "    UpstageEmbeddings,\n",
    "    UpstageLayoutAnalysisLoader,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "llm = ChatUpstage(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More general chat\n",
    "chat_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{message}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_with_history_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history_langchain_format = []\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "\n",
    "    return chain.invoke({\"message\": message, \"history\": history_langchain_format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.ChatInterface(\n",
    "        chat,\n",
    "        examples=[\n",
    "            \"How to eat healthy?\",\n",
    "            \"Best Places in Korea\",\n",
    "            \"How to make a chatbot?\",\n",
    "        ],\n",
    "        title=\"Solar Chatbot\",\n",
    "        description=\"Upstage Solar Chatbot\",\n",
    "    )\n",
    "    chatbot.chatbot.height = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio_ChatPDF\n",
    "\n",
    "- <b> Comprehensive RAG System for PDFs </b> : Use Gradio and RAG techniques to process PDF documents and generate real-time, interactive responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history, retriever):\n",
    "    result_docs = \"\"\n",
    "    if retriever:\n",
    "        result_docs = retriever.invoke(message)\n",
    "\n",
    "    history_langchain_format = []\n",
    "    for human, ai in history:\n",
    "        history_langchain_format.append(HumanMessage(content=human))\n",
    "        history_langchain_format.append(AIMessage(content=ai))\n",
    "\n",
    "    generator = chain.stream(\n",
    "        {\n",
    "            \"context\": result_docs,\n",
    "            \"message\": message,\n",
    "            \"history\": history_langchain_format,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    assistant = \"\"\n",
    "    for gen in generator:\n",
    "        assistant += gen\n",
    "        yield assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_upload(file):\n",
    "    layzer = UpstageLayoutAnalysisLoader(file, output_type=\"html\", use_ocr=False)\n",
    "    docs = layzer.load()\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    print(len(splits))\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=UpstageEmbeddings(\n",
    "            model=\"solar-embedding-1-large\", embed_batch_size=100\n",
    "        ),\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    return file, retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Solar Chatbot\")\n",
    "    gr.Markdown(\n",
    "        \"Upstage Solar Chatbot\",\n",
    "    )\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            file = gr.File()\n",
    "            retreiver = gr.State()\n",
    "        with gr.Column():\n",
    "            chatbot = gr.ChatInterface(\n",
    "                chat,\n",
    "                examples=[\n",
    "                    [\"How to eat healthy?\"],\n",
    "                    [\"Best Places in Korea\"],\n",
    "                    [\"How to make a chatbot?\"],\n",
    "                ],\n",
    "                additional_inputs=retreiver,\n",
    "            )\n",
    "    chatbot.chatbot.height = 300\n",
    "    file.upload(file_upload, file, [file, retreiver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Building Your Own AI-Powered Chatbot! 🤖\n",
    "\n",
    "\n",
    "Congratulations on completing the course on building chatbots using Language Models (LLMs), Layout Analysis (LA), custom tools, and Groundedness Checks (GC)! Now, showcase your brilliant ideas by participating in a hackathon and leveraging the Solar API! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
