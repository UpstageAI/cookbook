{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/Solar-Fullstack-LLM-101/16_Reasoning.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fact Checking with Knowledge Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install -qU langchain langchain-upstage langchain_community python-dotenv duckduckgo-search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPSTAGE_API_KEY\n",
    "To obtain your Upstage API key, follow these steps:\n",
    "\n",
    "1. Visit the Upstage AI console at <https://console.upstage.ai>.\n",
    "2. Sign up for an account if you don't already have one.\n",
    "3. Log in to your account.\n",
    "4. Navigate to the API key section.\n",
    "5. Generate your API key.\n",
    "6. Copy the key and save it securely.\n",
    "\n",
    "![Console](./figures/console.upstage.ai.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title set API key\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Running in Google Colab. Please set the UPSTAGE_API_KEY in the Colab Secrets\n",
    "    from google.colab import userdata\n",
    "\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
    "else:\n",
    "    # Running locally. Please set the UPSTAGE_API_KEY in the .env file\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "if \"UPSTAGE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = getpass.getpass(\"Enter your Upstage API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Any, Union\n",
    "import json\n",
    "\n",
    "from langchain_upstage import ChatUpstage as Chat\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from typing import Optional, Dict, Union, List, Any\n",
    "\n",
    "solar_pro = Chat(model=\"solar-pro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_check = \"\"\"\n",
    "Sung Kim is CEO of UpstageAI and it is founded in 1995.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracted_claimed_facts(\n",
    "    text: str, llm: Optional[Chat] = solar_pro\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extract claimed facts from the given text, including entities and their relationships.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to extract facts from.\n",
    "        llm (Optional[Chat]): The language model to use for extraction, if needed.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of extracted facts, where each fact is represented as a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are an expert fact extractor. Your task is to analyze the given text and extract a list of claimed facts, focusing on entities and their relationships. Extract precise and specific relations without categorizing them into predefined types.\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\"\"Extract the claimed facts from the following text, providing a list of dictionaries. Each dictionary should represent a fact and include keys for 'entity', 'relation', and 'value'. Be specific and precise with the relations.\n",
    "\n",
    "Examples:\n",
    "Input: \"Albert Einstein developed the theory of relativity in 1915.\"\n",
    "Output: [\n",
    "    {{\"entity\": \"Albert Einstein\", \"relation\": \"developed\", \"value\": \"theory of relativity\"}},\n",
    "    {{\"entity\": \"theory of relativity\", \"relation\": \"developed in\", \"value\": \"1915\"}}\n",
    "]\n",
    "\n",
    "Input: \"The Eiffel Tower, completed in 1889, stands at a height of 324 meters.\"\n",
    "Output: [\n",
    "    {{\"entity\": \"Eiffel Tower\", \"relation\": \"completed in\", \"value\": \"1889\"}},\n",
    "    {{\"entity\": \"Eiffel Tower\", \"relation\": \"height\", \"value\": \"324 meters\"}}\n",
    "]\n",
    "\n",
    "Now, extract facts from the following text:\n",
    "{input_text}\"\"\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Respond with a JSON array of fact dictionaries only, without any additional text.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the output parser\n",
    "    output_parser = JsonOutputParser()\n",
    "\n",
    "    # Create the chain\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    # Run the chain\n",
    "    result = chain.invoke({\"input_text\": text})\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Extracting claimed facts\n",
      "Extracted 2 claimed facts:\n",
      "{'entity': 'Sung Kim', 'relation': 'CEO of', 'value': 'UpstageAI'}\n",
      "  1. Sung Kim CEO of UpstageAI\n",
      "\n",
      "{'entity': 'UpstageAI', 'relation': 'founded in', 'value': '1995'}\n",
      "  2. UpstageAI founded in 1995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 1: Extracting claimed facts\")\n",
    "claimed_facts = extracted_claimed_facts(text_to_check)\n",
    "print(f\"Extracted {len(claimed_facts)} claimed facts:\")\n",
    "for i, fact in enumerate(claimed_facts):\n",
    "    print(fact)\n",
    "    print(f\"  {i+1}. {fact['entity']} {fact['relation']} {fact['value']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_context(\n",
    "    text: str,\n",
    "    claimed_facts: List[Dict[str, Any]],\n",
    "    search_tool: DuckDuckGoSearchResults = DuckDuckGoSearchResults(),\n",
    "    llm: Optional[Chat] = solar_pro,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Search for relevant information using claimed facts.\n",
    "\n",
    "    Args:\n",
    "        text (str): The original input text.\n",
    "        claimed_facts (List[Dict[str, Any]]): The list of extracted claimed facts.\n",
    "        search_tool (Any): The search tool to use for finding information (e.g., DuckDuckGoSearchResults).\n",
    "        llm (Optional[Chat]): The language model to use for processing, if needed.\n",
    "\n",
    "    Returns:\n",
    "        str: The relevant context information found from the search.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Generate search keywords\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are an expert at generating concise and relevant search keywords. Your task is to analyze the given text and extracted facts, then produce a list of 3-5 search keywords or short phrases that would be most effective for finding additional context and verification information.\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\"\"Given the following text and extracted facts, generate a list of 3-5 search keywords or short phrases:\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Extracted Facts:\n",
    "{facts}\n",
    "\n",
    "Provide only the keywords or short phrases, separated by commas.\"\"\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    facts_str = \"\\n\".join(\n",
    "        [\n",
    "            f\"- {fact['entity']} {fact['relation']} {fact['value']}\"\n",
    "            for fact in claimed_facts\n",
    "        ]\n",
    "    )\n",
    "    keywords_response = llm.invoke(prompt.format(text=text, facts=facts_str))\n",
    "\n",
    "    # Parse the keywords from the response\n",
    "    keywords = [kw.strip() for kw in keywords_response.content.split(\",\") if kw.strip()]\n",
    "\n",
    "    # Step 2: Perform search using the generated keywords\n",
    "    search_query = \" \".join(keywords)\n",
    "    search_results = search_tool.run(search_query)\n",
    "\n",
    "    # Step 3: Return the search results\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Searching for relevant context\n",
      "('snippet: SAN JOSE, California, Apr. 16, 2024 - Upstage, a pioneering AI '\n",
      " 'company specializing in large language models (LLMs) and Document AI, today '\n",
      " 'announced that it has raised $72 million in a Series B.With this latest '\n",
      " 'investment, Upstage has now raised over $100 million since its founding in '\n",
      " 'October 2020, making it the most-funded South Korean AI software company in '\n",
      " 'history., title: Upstage Raises $72 Million in Series B Funding â€” Upstage, '\n",
      " 'link: https://www.upstage.ai/feed/press/upstage-series-b-funding, snippet: '\n",
      " '\"This SCA highlights our strong partnership with AWS and our shared vision '\n",
      " 'to help enterprises globally adopt cutting-edge generative AI,\" said Sung '\n",
      " 'Kim, CEO and co-founder of Upstage.\"With the ..., title: Upstage Signs '\n",
      " 'Multi-Year Strategic Collaboration Agreement with AWS to ..., link: '\n",
      " 'https://finance.yahoo.com/news/upstage-signs-multi-strategic-collaboration-120000054.html, '\n",
      " 'snippet: With this latest investment, Upstage has now raised over $100 '\n",
      " 'million since its founding in October 2020, making it the most-funded South '\n",
      " 'Korean AI software company in history., title: Upstage Raises $72 Million in '\n",
      " 'Series B Funding to Expand Global Reach ..., link: '\n",
      " 'https://www.prnewswire.com/news-releases/upstage-raises-72-million-in-series-b-funding-to-expand-global-reach-of-its-groundbreaking-ai-solutions-302117880.html, '\n",
      " 'snippet: Sung Kim, cofounder and CEO of Upstage. Courtesy of Upstage. The '\n",
      " \"round brings Upstage's total funds raised to more than $100 million, which \"\n",
      " 'the startup claims makes it the most well-funded AI ..., title: Billionaire '\n",
      " \"Chey's SK Backs Korean AI Startup Upstage | Forbes, link: \"\n",
      " 'https://www.forbes.com/sites/johnkang/2024/05/24/billionaire-cheys-sk-backs-korean-ai-startup-eyes-synergies-in-databases-home-appliances-and-hotels/')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 2: Searching for relevant context\")\n",
    "\n",
    "relevant_context = search_context(text_to_check, claimed_facts)\n",
    "pprint(relevant_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kg(\n",
    "    claimed_facts: List[Dict[str, Any]],\n",
    "    context: str,\n",
    "    llm: Optional[Chat] = solar_pro,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build a knowledge graph from claimed facts and context information.\n",
    "\n",
    "    Args:\n",
    "        claimed_facts (List[Dict[str, Any]]): The list of extracted claimed facts.\n",
    "        context (str): The context information retrieved from the search.\n",
    "        llm (Optional[Chat]): The language model to use for processing, if needed.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: The constructed knowledge graph with source information.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are an expert in building knowledge graphs. Your task is to analyze the given context and construct a knowledge graph, using the claimed facts only as inspiration for the schema without assuming their truth. Include source information for each fact.\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\"\"Given the following context and claimed facts, construct a knowledge graph. Assume all information in the context is true, but use the claimed facts only as hints for the types of relations to look for.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Claimed Facts (use only as schema hints):\n",
    "{claimed_facts}\n",
    "\n",
    "Construct the knowledge graph as a JSON object where keys are entities and values are dictionaries of relations. Each relation should have a \"value\" and a \"source\" (a relevant quote from the context).\n",
    "\n",
    "Example format:\n",
    "{{\n",
    "  \"Entity1\": {{\n",
    "    \"relation1\": {{\n",
    "      \"value\": \"Value1\",\n",
    "      \"source\": \"Relevant quote from context\"\n",
    "    }},\n",
    "    \"relation2\": {{\n",
    "      \"value\": \"Value2\",\n",
    "      \"source\": \"Another relevant quote\"\n",
    "    }}\n",
    "  }},\n",
    "  \"Entity2\": {{\n",
    "    ...\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Ensure that:\n",
    "1. All information comes from the context, not the claimed facts.\n",
    "2. Each fact has a source quote from the context.\n",
    "3. The schema is inspired by, but not limited to, the relations in the claimed facts.\n",
    "\n",
    "Construct the knowledge graph:\"\"\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    output_parser = JsonOutputParser()\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    facts_str = \"\\n\".join(\n",
    "        [\n",
    "            f\"- {fact['entity']} {fact['relation']} {fact['value']}\"\n",
    "            for fact in claimed_facts\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    kg = chain.invoke({\"context\": context, \"claimed_facts\": facts_str})\n",
    "\n",
    "    return kg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Building knowledge graph\n",
      "Built knowledge graph with 3 entities\n",
      "{'AWS': {'partnership': {'source': 'This SCA highlights our strong partnership '\n",
      "                                   'with AWS and our shared vision to help '\n",
      "                                   'enterprises globally adopt cutting-edge '\n",
      "                                   'generative AI.',\n",
      "                         'value': 'AWS has a multi-year strategic '\n",
      "                                  'collaboration agreement with UpstageAI.'}},\n",
      " 'Sung Kim': {'position': {'source': 'Claimed Facts (use only as schema '\n",
      "                                     'hints): - Sung Kim CEO of UpstageAI',\n",
      "                           'value': 'CEO and co-founder of UpstageAI'}},\n",
      " 'UpstageAI': {'founding_year': {'source': 'With this latest investment, '\n",
      "                                           'Upstage has now raised over $100 '\n",
      "                                           'million since its founding in '\n",
      "                                           'October 2020.',\n",
      "                                 'value': 'UpstageAI was founded in 2020.'},\n",
      "               'funding_history': {'source': 'With this latest investment, '\n",
      "                                             'Upstage has now raised over $100 '\n",
      "                                             'million since its founding in '\n",
      "                                             'October 2020, making it the '\n",
      "                                             'most-funded South Korean AI '\n",
      "                                             'software company in history.',\n",
      "                                   'value': 'UpstageAI has now raised over '\n",
      "                                            '$100 million since its founding '\n",
      "                                            'in October 2020, including a '\n",
      "                                            'recent $72 million Series B.'},\n",
      "               'location': {'source': 'SAN JOJA, California, Apr. 16, 2024 - '\n",
      "                                      'Upstage, a pioneering AI company '\n",
      "                                      'specializing in large language models '\n",
      "                                      '(LLMs) and Document AI, today announced '\n",
      "                                      'that it has raised $72 million in a '\n",
      "                                      'Series B.',\n",
      "                            'value': 'UpstageAI is located in San Jose, '\n",
      "                                     'California.'},\n",
      "               'partnership': {'source': 'This SCA highlights our strong '\n",
      "                                         'partnership with AWS and our shared '\n",
      "                                         'vision to help enterprises globally '\n",
      "                                         'adopt cutting-edge generative AI.',\n",
      "                               'value': 'UpstageAI has a strong partnership '\n",
      "                                        'with AWS, as demonstrated by their '\n",
      "                                        'multi-year strategic collaboration '\n",
      "                                        'agreement.'}}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 3: Building knowledge graph\")\n",
    "kg = build_kg(claimed_facts, relevant_context)\n",
    "print(f\"Built knowledge graph with {len(kg)} entities\")\n",
    "pprint(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_facts(\n",
    "    claimed_facts: List[Dict[str, Any]],\n",
    "    context: str,\n",
    "    kg: Dict[str, Any],\n",
    "    confidence_threshold: float,\n",
    "    llm: Optional[Chat] = solar_pro,\n",
    ") -> Dict[str, Dict[str, Union[str, float, bool]]]:\n",
    "    \"\"\"\n",
    "    Verify the claimed facts against the knowledge graph and context.\n",
    "\n",
    "    Args:\n",
    "        claimed_facts (List[Dict[str, Any]]): The list of extracted claimed facts.\n",
    "        context (str): The context information retrieved from the search.\n",
    "        kg (Dict[str, Any]): The constructed knowledge graph.\n",
    "        confidence_threshold (float): The confidence threshold for fact verification.\n",
    "        llm (Optional[Chat]): The language model to use for verification, if needed.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict[str, Union[str, float, bool]]]: Verified facts with confidence scores.\n",
    "        The structure is: {fact_id: {\"claimed\": str, \"verified\": bool, \"confidence\": float, \"explanation\": str}}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are an expert fact-checker. Your task is to verify a claimed fact against a knowledge graph and context information. Provide a verification result, confidence score, and explanation for the fact.\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\"\"Verify the following claimed fact using the provided knowledge graph and context. Determine if it's verified, assign a confidence score (0.0 to 1.0), and provide a brief explanation.\n",
    "\n",
    "Claimed Fact: {entity} {relation} {value}\n",
    "\n",
    "Knowledge Graph:\n",
    "{kg}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Provide a JSON object with the following structure:\n",
    "{{\n",
    "  \"verified\": bool,\n",
    "  \"confidence\": float,\n",
    "  \"explanation\": string\n",
    "}}\n",
    "\n",
    "Ensure that:\n",
    "1. The verification is based on the information in the knowledge graph and context.\n",
    "2. The confidence score reflects the certainty of the verification (1.0 for absolute certainty, lower for less certainty).\n",
    "3. The explanation briefly justifies the verification decision and confidence score.\n",
    "\n",
    "Provide the verification result:\"\"\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    output_parser = JsonOutputParser()\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    kg_str = json.dumps(kg, indent=2)\n",
    "    verified_facts = {}\n",
    "\n",
    "    for i, fact in enumerate(claimed_facts):\n",
    "        verification_result = chain.invoke(\n",
    "            {\n",
    "                \"entity\": fact[\"entity\"],\n",
    "                \"relation\": fact[\"relation\"],\n",
    "                \"value\": fact[\"value\"],\n",
    "                \"kg\": kg_str,\n",
    "                \"context\": context,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        verified_facts[str(i)] = {\n",
    "            \"claimed\": f\"{fact['entity']} {fact['relation']} {fact['value']}\",\n",
    "            **verification_result,\n",
    "        }\n",
    "\n",
    "    return verified_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Verifying facts\n",
      "Verified 2 facts:\n",
      "  Fact 0:\n",
      "    Claimed: Sung Kim CEO of UpstageAI\n",
      "    Verified: True\n",
      "    Confidence: 1.0\n",
      "    Explanation: The knowledge graph clearly states that Sung Kim holds the position of 'CEO and co-founder of UpstageAI'. Additionally, multiple sources in the context confirm this information, including a direct quote from Sung Kim referring to himself as the CEO of Upstage.\n",
      "  Fact 1:\n",
      "    Claimed: UpstageAI founded in 1995\n",
      "    Verified: False\n",
      "    Confidence: 1.0\n",
      "    Explanation: The claimed fact is not verified. According to the knowledge graph, UpstageAI was founded in 2020, not in 1995. This information is also consistent with the context information provided.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 4: Verifying facts\")\n",
    "verified_facts = verify_facts(claimed_facts, relevant_context, kg, confidence_threshold=0.7)\n",
    "print(f\"Verified {len(verified_facts)} facts:\")\n",
    "for fact_id, result in verified_facts.items():\n",
    "    print(f\"  Fact {fact_id}:\")\n",
    "    print(f\"    Claimed: {result['claimed']}\")\n",
    "    print(f\"    Verified: {result['verified']}\")\n",
    "    print(f\"    Confidence: {result['confidence']}\")\n",
    "    print(\n",
    "        f\"    Explanation: {result['explanation']}\"\n",
    "    )  # Truncate long explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fact_check_comments_to_text(text, verified_facts, llm=solar_pro):\n",
    "    # First, let's create a mapping of claimed facts to their verifications\n",
    "    fact_map = {fact[\"claimed\"]: fact for fact in verified_facts.values()}\n",
    "\n",
    "    # Now, let's ask the LLM to annotate the original text\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are an AI assistant tasked with adding fact-check annotations to a given text.\n",
    "    For each fact in the text that has been verified, add an inline annotation \n",
    "    right after the fact, using the following format:\n",
    "    [Fact: <STATUS> (Confidence: <CONFIDENCE>) - <BRIEF_EXPLANATION>]\n",
    "    Where <STATUS> is True, False, or Unsure, <CONFIDENCE> is the confidence score,\n",
    "    and <BRIEF_EXPLANATION> is a very short explanation.\n",
    "    \"\"\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\"\"Original text:\n",
    "    {text}\n",
    "\n",
    "    Verified facts:\n",
    "    {fact_map}\n",
    "\n",
    "    Please add fact-check annotations to the original text based on the verified facts.\n",
    "    \"\"\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\"text\": text, \"fact_map\": fact_map})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Adding fact-check annotations to the original text\n",
      "Fact-checked text generated\n",
      "('Sung Kim is CEO of UpstageAI [Fact: True (Confidence: 1.0) - The knowledge '\n",
      " 'graph and multiple sources confirm this information] and it is founded in '\n",
      " '1995 [Fact: False (Confidence: 1.0) - UpstageAI was founded in 2020, not in '\n",
      " '1995].')\n"
     ]
    }
   ],
   "source": [
    "# Final step\n",
    "print(\"\\nStep 5: Adding fact-check annotations to the original text\")\n",
    "fact_checked_text = add_fact_check_comments_to_text(text_to_check, verified_facts)\n",
    "print(\"Fact-checked text generated\")\n",
    "pprint(fact_checked_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
