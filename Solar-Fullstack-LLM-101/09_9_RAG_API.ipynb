{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6156e0ed",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/Solar-Fullstack-LLM-101/09_9_RAG_API.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919fe33c-0149-4f7d-b200-544a18986c9a",
   "metadata": {},
   "source": [
    "# Upstage RAG API (experimental)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3ee57-68ab-4040-bd36-4014e2a23d96",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a384cc48-0425-4e8f-aafc-cfb8e56025c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "goldenverba 2.1.0 requires langchain-text-splitters==0.2.2, but you have langchain-text-splitters 0.3.2 which is incompatible.\n",
      "goldenverba 2.1.0 requires python-dotenv==1.0.0, but you have python-dotenv 1.0.1 which is incompatible.\n",
      "goldenverba 2.1.0 requires tiktoken==0.6.0, but you have tiktoken 0.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-upstage langchain python-dotenv openai rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15569b93-3c68-4aac-838c-37112d33987a",
   "metadata": {},
   "source": [
    "### Environment variables\n",
    "\n",
    "Set up environment variables \n",
    "* UPSTAGE_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18b63c7-d0d3-41c1-ae6b-5a0f1b8ccf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title set API key\n",
    "from pprint import pprint\n",
    "from rich import print as rprint\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Running in Google Colab. Please set the UPSTAGE_API_KEY in the Colab Secrets\n",
    "    from google.colab import userdata\n",
    "\n",
    "    os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
    "else:\n",
    "    # Running locally. Please set the UPSTAGE_API_KEY in the .env file\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "assert (\n",
    "    \"UPSTAGE_API_KEY\" in os.environ\n",
    "), \"Please set the UPSTAGE_API_KEY environment variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2b1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_base_url = \"https://rag.toy.x.upstage.ai/\"\n",
    "#rag_base_url = \"http://localhost:8000/\"\n",
    "\n",
    "# Plase chose your model name\n",
    "rag_model_name = \"sung-pro-1009\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "784872dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(base_url=rag_base_url, api_key=os.environ[\"UPSTAGE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e313b666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building/Rebuilding the index...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FileObject</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-6'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">bytes</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">418872</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1730856387</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper.pdf'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">purpose</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistants'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'queued'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sung-pro-1008'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">public_model_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'367ebd586fee0553547b'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mFileObject\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'file-6'\u001b[0m,\n",
       "    \u001b[33mbytes\u001b[0m=\u001b[1;36m418872\u001b[0m,\n",
       "    \u001b[33mcreated_at\u001b[0m=\u001b[1;36m1730856387\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'solar_paper.pdf'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'file'\u001b[0m,\n",
       "    \u001b[33mpurpose\u001b[0m=\u001b[32m'assistants'\u001b[0m,\n",
       "    \u001b[33mstatus\u001b[0m=\u001b[32m'queued'\u001b[0m,\n",
       "    \u001b[33mstatus_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmodel_name\u001b[0m=\u001b[32m'sung-pro-1008'\u001b[0m,\n",
       "    \u001b[33mpublic_model_name\u001b[0m=\u001b[32m'367ebd586fee0553547b'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FileObject</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-7'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">bytes</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">137425</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1730856387</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'solar_sample.pdf'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">purpose</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistants'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'queued'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sung-pro-1008'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">public_model_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'367ebd586fee0553547b'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mFileObject\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'file-7'\u001b[0m,\n",
       "    \u001b[33mbytes\u001b[0m=\u001b[1;36m137425\u001b[0m,\n",
       "    \u001b[33mcreated_at\u001b[0m=\u001b[1;36m1730856387\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'solar_sample.pdf'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'file'\u001b[0m,\n",
       "    \u001b[33mpurpose\u001b[0m=\u001b[32m'assistants'\u001b[0m,\n",
       "    \u001b[33mstatus\u001b[0m=\u001b[32m'queued'\u001b[0m,\n",
       "    \u001b[33mstatus_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmodel_name\u001b[0m=\u001b[32m'sung-pro-1008'\u001b[0m,\n",
       "    \u001b[33mpublic_model_name\u001b[0m=\u001b[32m'367ebd586fee0553547b'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FileObject</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-8'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">bytes</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">878624</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1730856388</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'docai.pdf'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">purpose</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistants'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'queued'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sung-pro-1008'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">public_model_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'367ebd586fee0553547b'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mFileObject\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'file-8'\u001b[0m,\n",
       "    \u001b[33mbytes\u001b[0m=\u001b[1;36m878624\u001b[0m,\n",
       "    \u001b[33mcreated_at\u001b[0m=\u001b[1;36m1730856388\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'docai.pdf'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'file'\u001b[0m,\n",
       "    \u001b[33mpurpose\u001b[0m=\u001b[32m'assistants'\u001b[0m,\n",
       "    \u001b[33mstatus\u001b[0m=\u001b[32m'queued'\u001b[0m,\n",
       "    \u001b[33mstatus_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmodel_name\u001b[0m=\u001b[32m'sung-pro-1008'\u001b[0m,\n",
       "    \u001b[33mpublic_model_name\u001b[0m=\u001b[32m'367ebd586fee0553547b'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FileObject</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file-9'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">bytes</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4432693</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1730856389</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">filename</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'kim-tse-2008.pdf'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">purpose</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistants'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'queued'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">status_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sung-pro-1008'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">public_model_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'367ebd586fee0553547b'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mFileObject\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'file-9'\u001b[0m,\n",
       "    \u001b[33mbytes\u001b[0m=\u001b[1;36m4432693\u001b[0m,\n",
       "    \u001b[33mcreated_at\u001b[0m=\u001b[1;36m1730856389\u001b[0m,\n",
       "    \u001b[33mfilename\u001b[0m=\u001b[32m'kim-tse-2008.pdf'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'file'\u001b[0m,\n",
       "    \u001b[33mpurpose\u001b[0m=\u001b[32m'assistants'\u001b[0m,\n",
       "    \u001b[33mstatus\u001b[0m=\u001b[32m'queued'\u001b[0m,\n",
       "    \u001b[33mstatus_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmodel_name\u001b[0m=\u001b[32m'sung-pro-1008'\u001b[0m,\n",
       "    \u001b[33mpublic_model_name\u001b[0m=\u001b[32m'367ebd586fee0553547b'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index build/rebuild submission completed.\n",
      "Public Mode Name: 367ebd586fee0553547b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Building/Rebuilding the index...\")\n",
    "directory = \"pdfs\"\n",
    "# Upload all files in the pdfs folder\n",
    "for file in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, file)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_response = client.files.create(\n",
    "            file=f, purpose=\"assistants\", extra_body={\"model_name\": rag_model_name}\n",
    "        )\n",
    "        rprint(file_response)\n",
    "\n",
    "print(\"Index build/rebuild submission completed.\")\n",
    "\n",
    "public_model_name = file_response.public_model_name\n",
    "print(\"Public Mode Name:\", public_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc27f4fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Send a query to the chat model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the Depth UpScaling for LLM?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Print the response content in a formatted way\u001b[39;00m\n\u001b[1;32m     18\u001b[0m rprint(response)\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/langchain_upstage/chat_models.py:236\u001b[0m, in \u001b[0;36mChatUpstage._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[1;32m    235\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_payload(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 236\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/openai/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/openai/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/openai/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/openai/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/.venv/lib/python3.12/site-packages/openai/_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1067\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Internal Server Error"
     ]
    }
   ],
   "source": [
    "# It will take a few minutes to build the index\n",
    "# You may get InternalServerError: \n",
    "# Error code: 503 - Service Not Ready\n",
    "# If you do, just wait for indexing to complete and try again\n",
    "\n",
    "# Import necessary libraries\n",
    "from langchain_upstage import ChatUpstage as Chat\n",
    "\n",
    "# Initialize the ChatUpstage model\n",
    "# Use the previously defined rag_model_name and rag_base_url\n",
    "chat = Chat(model=rag_model_name, base_url=rag_base_url)\n",
    "\n",
    "# Send a query to the chat model\n",
    "question = \"What's the Depth UpScaling for LLM?\"\n",
    "response = chat.invoke(question)\n",
    "\n",
    "# Print the response content in a formatted way\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will take a few minutes to build the index\n",
    "# You may get InternalServerError: \n",
    "# Error code: 503 - Service Not Ready\n",
    "# If you do, just wait for indexing to complete and try again\n",
    "\n",
    "# Import necessary libraries\n",
    "from langchain_upstage import ChatUpstage as Chat\n",
    "\n",
    "# Initialize the ChatUpstage model\n",
    "# Use the previously defined rag_model_name and rag_base_url\n",
    "chat = Chat(model=rag_model_name, base_url=rag_base_url, streaming=True)\n",
    "\n",
    "# Send a query to the chat model\n",
    "question = \"What's the Depth UpScaling for LLM?\"\n",
    "response = chat.invoke(question)\n",
    "\n",
    "# Print the response content in a formatted way\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb2b538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Depth UpScaling (DUS) for LLM is a method presented in the document \"SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling.\" DUS is a strategy for scaling LLMs and it consists of two main components: depthwise scaling and continued pre-training.\n",
      "\n",
      "Depthwise scaling is the process of increasing the depth of the LLM by adding more layers to the model architecture. This is done by duplicating the base model's layers, which allows for the creation of a larger model with more parameters. In the case of SOLAR 10.7B, the model has 10.7 billion parameters, which is achieved through depthwise scaling.\n",
      "\n",
      "After depthwise scaling, the scaled model undergoes continued pre-training. This process involves further training the model on a large-scale dataset to improve its performance and adapt it to the increased model size. Continued pre-training helps the model to better utilize its additional parameters and improve its generalization ability.\n",
      "\n",
      "DUS is contrasted to other LLM up-scaling methods that use mixture-of-experts, as it does not require complex changes to train and infer efficiently. Instead, DUS focuses on simple yet effective techniques to scale LLMs, making it an accessible and efficient approach."
     ]
    }
   ],
   "source": [
    "# Langchain Streaming\n",
    "# https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/09-langchain-streaming/09-langchain-streaming.ipynb\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "chat = Chat(model=rag_model_name, base_url=rag_base_url,\n",
    "    streaming=True,  # ! important\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  # ! important\n",
    ")\n",
    "\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# create messages to be passed to chat LLM\n",
    "messages = [HumanMessage(content=\"What's the Depth UpScaling for LLM? Describe it in detail.\")]\n",
    "\n",
    "response = chat.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e46e98",
   "metadata": {},
   "source": [
    "# Upstage RAG-API Configuration Options\n",
    "\n",
    "The `Chat` object is initialized with several options to customize its behavior:\n",
    "\n",
    "1. `api_key`: The API key for authentication. Get from https://console.upstage.ai/\n",
    "\n",
    "2. `model`: The name of the RAG (Retrieval-Augmented Generation) model to be used.\n",
    "\n",
    "3. `base_url`: The base URL for the RAG API.\n",
    "\n",
    "4. `extra_body`: A dictionary containing additional parameters for the API request:\n",
    "\n",
    "   - `hybrid_search` (bool): When set to `True`, enables a combination of semantic and keyword-based search for improved retrieval accuracy.\n",
    "   \n",
    "   - `contextual_query` (bool): If `True`, the system considers the context of previous interactions when processing the current query.\n",
    "   \n",
    "   - `contextual_chunk` (bool): When enabled, the system retrieves and processes information in context-aware chunks, potentially improving relevance.\n",
    "   \n",
    "   - `knowledge_graph` (bool): If set to `True`, the system utilizes a knowledge graph to enhance understanding and connections between concepts.\n",
    "   \n",
    "   - `kv_pairs` (bool): When enabled, the system extracts and utilizes key-value pairs from the input, which can be useful for structured data processing.\n",
    "   \n",
    "   - `llm_model_name` (str): Specifies the name of the language model to be used, in this case \"solar-pro\".\n",
    "\n",
    "These options allow for fine-tuning of the RAG system's behavior, potentially improving the relevance and accuracy of responses based on the specific use case and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e7b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The DUS is a new method for scaling up large language models (LLMs). It is compatible with easy-to-use</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM frameworks like HuggingFace and applicable to all transformer architectures. It has been used to create SO-LAR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">10.7B, an LLM with 10.7 billion parameters that outperforms existing models, and SOLAR 10.7B-Instruct, a variant </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fine-tuned for complex instructions that outperforms other models in various evaluation metrics.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sung-pro-1001'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-7acffdab-6565-45b9-8c05-5406e9a68de6-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'The DUS is a new method for scaling up large language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. It is compatible with easy-to-use\u001b[0m\n",
       "\u001b[32mLLM frameworks like HuggingFace and applicable to all transformer architectures. It has been used to create SO-LAR \u001b[0m\n",
       "\u001b[32m10.7B, an LLM with 10.7 billion parameters that outperforms existing models, and SOLAR 10.7B-Instruct, a variant \u001b[0m\n",
       "\u001b[32mfine-tuned for complex instructions that outperforms other models in various evaluation metrics.'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'sung-pro-1001'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-7acffdab-6565-45b9-8c05-5406e9a68de6-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_upstage import ChatUpstage as Chat\n",
    "\n",
    "# Initialize the ChatUpstage model\n",
    "# Use the previously defined rag_model_name and rag_base_url\n",
    "chat = Chat(\n",
    "    api_key=os.environ[\"UPSTAGE_API_KEY\"],\n",
    "    model=rag_model_name,\n",
    "    base_url=rag_base_url,\n",
    "    extra_body={\n",
    "        \"hybrid_search\": True,\n",
    "        \"contextual_query\": True,\n",
    "        \"contextual_chunk\": True,\n",
    "        \"knowledge_graph\": True,\n",
    "        \"kv_pairs\": True,\n",
    "        \"llm_model_name\": \"solar-pro\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Send a query to the chat model\n",
    "question = \"What's the DUS?\"\n",
    "response = chat.invoke(question)\n",
    "\n",
    "# Print the response content in a formatted way\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f08da4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m13\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the Depth UpScaling for LLM?\n"
     ]
    }
   ],
   "source": [
    "rprint(chat.get_num_tokens(question))\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ee76116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'_'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The following indexed files are being used for this query: solar_paper.pdf, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">solar_sample.pdf, docai.pdf, kim-tse-2008.pdf\\n\\nSolar 10.7B is a large language model (LLM) with 10.7 billion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parameters, demonstrating superior performance in various natural language processing (NLP) tasks. In the MMLU </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(Multi-Domain Evaluation) framework, it achieved an average score of 69.83, as shown in Table 2 of the provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">content.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1728237594.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sung-pro-1008'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'research and practical applications, fostering\\nwider accessibility and utility </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in various fields. Superior Performance Across Diverse\\nBenchmarks: SOLAR 10.7B excels in var-\\nious benchmarks, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outperforming established\\nmodels like Llama 2 and Mistral 7B in reason-\\ning, mathematics, and the MMLU </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">framework. Advancement in Instruction-Following Ca-\\npabilities: The introduction of SOLAR 10.7B-\\nInstruct, a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">variant fine-tuned for enhanced\\ninstruction-following abilities, marks a sig-\\nnificant improvement in the models</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ability to\\nunderstand and execute complex instructions.Sanghoon Kim, Dahyun Kim, Chanjun Park,\\nWonsung Lee, Wonho</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Song, Yunsu Kim and\\nHyeonwoo Kim contributed equally to this paper.\\nSanghoon Kim led the Foundation Model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">part,\\nwith Dahyun Kim, Wonho Song, Yunsu Kim, and\\nHyeonwoo Kim. Chanjun Park led the Data and\\nEvaluation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(Data-Centric LLM) part, with Yungi\\nKim, Jihoo Kim, Changbae Ahn, Seonghoon Yang,\\nSukyung Lee, and Hyunbyung </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Park. Wonsung Lee'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'f6a2b9ec-0af7-4ba0-9936-d1d7f3704f21'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'research and practical applications, fostering\\nwider accessibility and utility in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various fields. Superior Performance Across Diverse\\nBenchmarks: SOLAR 10.7B excels in var-\\nious benchmarks, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">outperforming established\\nmodels like Llama 2 and Mistral 7B in reason-\\ning, mathematics, and the MMLU </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">framework. Advancement in Instruction-Following Ca-\\npabilities: The introduction of SOLAR 10.7B-\\nInstruct, a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">variant fine-tuned for enhanced\\ninstruction-following abilities, marks a sig-\\nnificant improvement in the models</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ability to\\nunderstand and execute complex instructions.Sanghoon Kim, Dahyun Kim, Chanjun Park,\\nWonsung Lee, Wonho</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Song, Yunsu Kim and\\nHyeonwoo Kim contributed equally to this paper.\\nSanghoon Kim led the Foundation Model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">part,\\nwith Dahyun Kim, Wonho Song, Yunsu Kim, and\\nHyeonwoo Kim. Chanjun Park led the Data and\\nEvaluation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(Data-Centric LLM) part, with Yungi\\nKim, Jihoo Kim, Changbae Ahn, Seonghoon Yang,\\nSukyung Lee, and Hyunbyung </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Park. Wonsung Lee'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Wen, and Jiawei Han. 2023. Dont make your llm\\nan evaluation benchmark cheater.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv preprint\\narXiv:2311.01964.Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B\\nBrown, Alec Radford, Dario </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Amodei, Paul Chris-\\ntiano, and Geoffrey Irving. 2019. Fine-tuning lan-\\nguage models from human preferences. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv\\npreprint arXiv:1909.08593.A ContributionsThe contributions of this study are as follows: Introduction of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the SOLAR 10.7 Billion-\\nParameter Model: We have released the SO-\\nLAR 10.7B model, which is not only depth-\\nwise</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scaled but also continually pretrained.\\nThe availability of SOLAR 10.7B under the\\nApache 2.0 license permits </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">commercial us-\\nage, enabling the integration of this advanced\\nmodel into a diverse range of products and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ser-\\nvices. This bridges the gap between academic\\nresearch and practical applications, fostering\\nwider </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accessibility and utility in various fields. Superior Performance Across Diverse\\nBenchmarks: SOLAR 10.7B excels </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in var-'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e9bd9ca0-6b38-4544-be81-8247b4e6318f'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Wen, and Jiawei Han. 2023. Dont make your llm\\nan evaluation benchmark cheater. arXiv </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">preprint\\narXiv:2311.01964.Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B\\nBrown, Alec Radford, Dario Amodei, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Paul Chris-\\ntiano, and Geoffrey Irving. 2019. Fine-tuning lan-\\nguage models from human preferences. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv\\npreprint arXiv:1909.08593.A ContributionsThe contributions of this study are as follows: Introduction of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the SOLAR 10.7 Billion-\\nParameter Model: We have released the SO-\\nLAR 10.7B model, which is not only depth-\\nwise</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scaled but also continually pretrained.\\nThe availability of SOLAR 10.7B under the\\nApache 2.0 license permits </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">commercial us-\\nage, enabling the integration of this advanced\\nmodel into a diverse range of products and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ser-\\nvices. This bridges the gap between academic\\nresearch and practical applications, fostering\\nwider </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accessibility and utility in various fields. Superior Performance Across Diverse\\nBenchmarks: SOLAR 10.7B excels </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in var-'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'there are no additional modules or dynamism as\\nwith MoE, making DUS immediately</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">compatible\\nwith easy-to-use LLM frameworks such as Hug-\\ngingFace (Wolf et al., 2019) with no changes to\\nthe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training or inference framework for maximal\\nefficiency. Furthermore, DUS is applicable to all\\ntransformer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architectures, opening up new gate-\\nways to effectively and efficiently scale-up LLMs\\nin a simple manner. Using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DUS, we release SO-\\nLAR 10.7B, an LLM with 10.7 billion parameters,\\nthat outperforms existing models like Llama 2</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(Tou-\\nvron et al., 2023) and Mistral 7B (Jiang et al., 2023)\\nin various benchmarks.We have also developed SOLAR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">10.7B-Instruct,\\na variant fine-tuned for tasks requiring strict adher-\\nence to complex instructions. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">significantly out-\\nperforms the Mixtral-8x7B-Instruct model across\\nvarious evaluation metrics, evidencing an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">advanced\\nproficiency that exceeds the capabilities of even\\nlarger models in terms of benchmark performance.By </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">releasing SOLAR 10.7B under the Apache'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'be83e758-cce0-407c-9d03-8b39c372ff82'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'there are no additional modules or dynamism as\\nwith MoE, making DUS immediately </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">compatible\\nwith easy-to-use LLM frameworks such as Hug-\\ngingFace (Wolf et al., 2019) with no changes to\\nthe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training or inference framework for maximal\\nefficiency. Furthermore, DUS is applicable to all\\ntransformer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">architectures, opening up new gate-\\nways to effectively and efficiently scale-up LLMs\\nin a simple manner. Using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">DUS, we release SO-\\nLAR 10.7B, an LLM with 10.7 billion parameters,\\nthat outperforms existing models like Llama 2</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(Tou-\\nvron et al., 2023) and Mistral 7B (Jiang et al., 2023)\\nin various benchmarks.We have also developed SOLAR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">10.7B-Instruct,\\na variant fine-tuned for tasks requiring strict adher-\\nence to complex instructions. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">significantly out-\\nperforms the Mixtral-8x7B-Instruct model across\\nvarious evaluation metrics, evidencing an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">advanced\\nproficiency that exceeds the capabilities of even\\nlarger models in terms of benchmark performance.By </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">releasing SOLAR 10.7B under the Apache'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'training stage of the model and is chosen from {Pretrained, Instruction-tuned, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Alignment-tuned}. Models based on\\nSOLAR 10.7B are colored purple. The best scores for H6 and the individual tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are shown in bold.MetaMathQA (Yu et al., 2023) dataset.We reformatted the instruction datasets with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an\\nAlpaca-styled chat template. For datasets such as\\nOpenOrca, which are derived from FLAN (Long-\\npre et al., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023), we filter data that overlaps with\\nthe benchmark datasets (see Tab. 8 in Appendix. C\\nfor more information).</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The alignment datasets\\nare in the {prompt, chosen, rejected} triplet for-\\nmat. We preprocess the alignment </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">datasets follow-\\ning Zephyr (Tunstall et al., 2023). We use Data-\\nverse (Park et al., 2024) for data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">preprocessing.Evaluation. In the HuggingFace Open LLM\\nLeaderboard (Beeching et al., 2023), six types </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of\\nevaluation methods are presented: ARC (Clark\\net al., 2018), HellaSWAG (Zellers et al., 2019),\\nMMLU (Hendrycks</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">et al., 2020), TruthfulQA (Lin'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9c3b8cd3-6d05-48bd-89d4-c1f8d8c78098'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'training stage of the model and is chosen from {Pretrained, Instruction-tuned, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Alignment-tuned}. Models based on\\nSOLAR 10.7B are colored purple. The best scores for H6 and the individual tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are shown in bold.MetaMathQA (Yu et al., 2023) dataset.We reformatted the instruction datasets with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">an\\nAlpaca-styled chat template. For datasets such as\\nOpenOrca, which are derived from FLAN (Long-\\npre et al., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023), we filter data that overlaps with\\nthe benchmark datasets (see Tab. 8 in Appendix. C\\nfor more information).</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The alignment datasets\\nare in the {prompt, chosen, rejected} triplet for-\\nmat. We preprocess the alignment </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">datasets follow-\\ning Zephyr (Tunstall et al., 2023). We use Data-\\nverse (Park et al., 2024) for data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">preprocessing.Evaluation. In the HuggingFace Open LLM\\nLeaderboard (Beeching et al., 2023), six types </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of\\nevaluation methods are presented: ARC (Clark\\net al., 2018), HellaSWAG (Zellers et al., 2019),\\nMMLU (Hendrycks</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">et al., 2020), TruthfulQA (Lin'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective\\nDepth </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Up-ScalingDahyun Kim, Chanjun Park, Sanghoon Kim, Wonsung Lee, Wonho Song\\nYunsu Kim, Hyeonwoo Kim, Yungi</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Kim, Hyeonju Lee, Jihoo Kim\\nChangbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim\\nMikyoung </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Cha, Hwalsuk Lee, Sunghun KimUpstage AI, South Korea{kdahyun, chanjun.park, limerobot, wonsung.lee, hwalsuk.lee, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">hunkim}@upstage.aiAbstractWe introduce SOLAR 10.7B, a large language\\nmodel (LLM) with 10.7 billion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parameters,\\ndemonstrating superior performance in various\\nnatural language processing (NLP) tasks. In-\\nspired by</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recent efforts to efficiently up-scale\\nLLMs, we present a method for scaling LLMs\\ncalled depth up-scaling (DUS), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which encom-\\npasses depthwise scaling and continued pre-\\ntraining. In contrast to other LLM up-scaling\\nmethods </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that use mixture-of-experts, DUS does\\nnot require complex changes to train and infer-\\nence efficiently. We show </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experimentally that'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'d175b4c0-6c1d-4279-bb25-0ea9ccb820b4'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective\\nDepth </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Up-ScalingDahyun Kim, Chanjun Park, Sanghoon Kim, Wonsung Lee, Wonho Song\\nYunsu Kim, Hyeonwoo Kim, Yungi</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Kim, Hyeonju Lee, Jihoo Kim\\nChangbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim\\nMikyoung </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Cha, Hwalsuk Lee, Sunghun KimUpstage AI, South Korea{kdahyun, chanjun.park, limerobot, wonsung.lee, hwalsuk.lee, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">hunkim}@upstage.aiAbstractWe introduce SOLAR 10.7B, a large language\\nmodel (LLM) with 10.7 billion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parameters,\\ndemonstrating superior performance in various\\nnatural language processing (NLP) tasks. In-\\nspired by</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recent efforts to efficiently up-scale\\nLLMs, we present a method for scaling LLMs\\ncalled depth up-scaling (DUS), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which encom-\\npasses depthwise scaling and continued pre-\\ntraining. In contrast to other LLM up-scaling\\nmethods </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that use mixture-of-experts, DUS does\\nnot require complex changes to train and infer-\\nence efficiently. We show </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experimentally that'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'training. In contrast to other LLM up-scaling\\nmethods that use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mixture-of-experts, DUS does\\nnot require complex changes to train and infer-\\nence efficiently. We show </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experimentally that\\nDUS is simple yet effective in scaling up high-\\nperformance LLMs from small ones. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Building\\non the DUS model, we additionally present SO-\\nLAR 10.7B-Instruct, a variant fine-tuned </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for\\ninstruction-following capabilities, surpassing\\nMixtral-8x7B-Instruct. SOLAR 10.7B is pub-\\nlicly available </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">under the Apache 2.0 license,\\npromoting broad access and application in the\\nLLM field 1.1 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Introduction2024\\nApr\\n4\\n[cs.CL]\\narXiv:2312.15166v3The field of natural language processing (NLP)\\nhas been </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">significantly transformed by the introduc-\\ntion of large language models (LLMs), which have\\nenhanced our </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding and interaction with\\nhuman language (Zhao et al., 2023). These ad-\\nvancements bring challenges such</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as the increased\\nneed to train ever larger models (Rae et al., 2021;'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9f6dcf67-518b-4a8e-b172-2b8596c7c7cf'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'training. In contrast to other LLM up-scaling\\nmethods that use mixture-of-experts, DUS </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">does\\nnot require complex changes to train and infer-\\nence efficiently. We show experimentally that\\nDUS is simple</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">yet effective in scaling up high-\\nperformance LLMs from small ones. Building\\non the DUS model, we additionally </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">present SO-\\nLAR 10.7B-Instruct, a variant fine-tuned for\\ninstruction-following capabilities, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">surpassing\\nMixtral-8x7B-Instruct. SOLAR 10.7B is pub-\\nlicly available under the Apache 2.0 license,\\npromoting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">broad access and application in the\\nLLM field 1.1 Introduction2024\\nApr\\n4\\n[cs.CL]\\narXiv:2312.15166v3The field </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of natural language processing (NLP)\\nhas been significantly transformed by the introduc-\\ntion of large language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models (LLMs), which have\\nenhanced our understanding and interaction with\\nhuman language (Zhao et al., 2023). </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">These ad-\\nvancements bring challenges such as the increased\\nneed to train ever larger models (Rae et al., 2021;'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Llama 2 70B  70B Pretrained 67.87 67.32 87.33 69.83 44.92 83.74 54.06\\n Falcon </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">180B  180B Pretrained 67.85 69.45 88.86 70.50 45.47 86.90 45.94\\n SOLAR 10.7B  11B Pretrained 66.04 61.95 84.60 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">65.48 45.04 83.66 55.50\\n Qwen 14B  14B Pretrained 65.86 58.28 83.99 67.70 49.43 76.80 58.98\\n Mistral </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">7B-Instruct-v0.2  7B Instruction-tuned 65.71 63.14 84.88 60.78 68.26 77.19 40.03\\n Yi 34B-Chat  34B </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Instruction-tuned 65.32 65.44 84.16 74.90 55.37 80.11 31.92\\n Mistral 7B  7B Pretrained 60.97 59.98 83.31 64.16 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">42.15 78.37 37.83Table 2: Evaluation results in the Open LLM Leaderboard for SOLAR 10.7B and SOLAR 10.7B-Instruct </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">along with\\nother top-performing models. We report the scores for the six tasks mentioned in Sec. 4.1 along with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the H6 score\\n(average of six tasks). We also report the size of the models in units of billions of parameters. The</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">type indicates the\\ntraining stage of the model and is chosen from {Pretrained, Instruction-tuned, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Alignment-tuned}. Models based on'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'38c0e5d5-6ce5-4cd0-87b3-5ca968ea7263'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Llama 2 70B  70B Pretrained 67.87 67.32 87.33 69.83 44.92 83.74 54.06\\n Falcon 180B  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">180B Pretrained 67.85 69.45 88.86 70.50 45.47 86.90 45.94\\n SOLAR 10.7B  11B Pretrained 66.04 61.95 84.60 65.48 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">45.04 83.66 55.50\\n Qwen 14B  14B Pretrained 65.86 58.28 83.99 67.70 49.43 76.80 58.98\\n Mistral 7B-Instruct-v0.2 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\"> 7B Instruction-tuned 65.71 63.14 84.88 60.78 68.26 77.19 40.03\\n Yi 34B-Chat  34B Instruction-tuned 65.32 65.44 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">84.16 74.90 55.37 80.11 31.92\\n Mistral 7B  7B Pretrained 60.97 59.98 83.31 64.16 42.15 78.37 37.83Table 2: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Evaluation results in the Open LLM Leaderboard for SOLAR 10.7B and SOLAR 10.7B-Instruct along with\\nother </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">top-performing models. We report the scores for the six tasks mentioned in Sec. 4.1 along with the H6 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">score\\n(average of six tasks). We also report the size of the models in units of billions of parameters. The type </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">indicates the\\ntraining stage of the model and is chosen from {Pretrained, Instruction-tuned, Alignment-tuned}. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Models based on'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_sample'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'port the average scores for the six tasks, e.g., H6.\\nWe either submit directly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to the Open LLM Leader-\\nboard or utilize Evalverse (Kim et al., 2024b) for\\nrunning evaluations locally.Model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">merging. Model merging methods such\\nas Yadav et al. (2023) can boost model perfor-\\nmance without further </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training. We merge some\\nof the models that we trained in both the instruc-\\ntion and alignment tuning stages. We </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implement\\nour own merging methods although popular open\\nsource also exist such as MergeKit3.4.2 Main ResultsWe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">present evaluation results for our SOLAR\\n10.7B and SOLAR 10.7B-Instruct models </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">along3https://github.com/cg123/mergekitwith other top-performing models in Tab. 2. SO-\\nLAR 10.7B outperforms other</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pretrained models\\nof similar sizes, such as Qwen 14B and Mistral\\n7B, which shows that DUS is an effective </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">method\\nto up-scale base LLMs. Furthermore, despite the\\nsmaller size, SOLAR 10.7B-Instruct scores the\\nhighest in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">terms of H6, even surpassing the recent'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'c3bb1029-66a7-4e0b-b100-30c188853701'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'port the average scores for the six tasks, e.g., H6.\\nWe either submit directly to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Open LLM Leader-\\nboard or utilize Evalverse (Kim et al., 2024b) for\\nrunning evaluations locally.Model merging. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Model merging methods such\\nas Yadav et al. (2023) can boost model perfor-\\nmance without further training. We </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">merge some\\nof the models that we trained in both the instruc-\\ntion and alignment tuning stages. We implement\\nour</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">own merging methods although popular open\\nsource also exist such as MergeKit3.4.2 Main ResultsWe present </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluation results for our SOLAR\\n10.7B and SOLAR 10.7B-Instruct models along3https://github.com/cg123/mergekitwith</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">other top-performing models in Tab. 2. SO-\\nLAR 10.7B outperforms other pretrained models\\nof similar sizes, such </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as Qwen 14B and Mistral\\n7B, which shows that DUS is an effective method\\nto up-scale base LLMs. Furthermore, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">despite the\\nsmaller size, SOLAR 10.7B-Instruct scores the\\nhighest in terms of H6, even surpassing the recent'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_sample'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Mistral 7B-Instruct-v0.2 7B  Instruction-tuned 65.71 63.14 84.88 60.78 68.26 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">77.19 40.03\\n Yi 34B-Chat 34B  Instruction-tuned 65.32 65.44 84.16 74.90 55.37 80.11 31.92\\n Mistral 7B 7B  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Pretrained 60.97 59.98 83.31 64.16 42.15 78.37 37.83Table 2: Evaluation results in the Open LLM Leaderboard for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">SOLAR 10.7B and SOLAR 10.7B-Instruct along with\\nother top-performing models. We report the scores for the six </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks mentioned in Sec. 4.1 along with the H6 score\\n(average of six tasks). We also report the size of the models </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in units of billions of parameters. The type indicates the\\ntraining stage of the model and is chosen from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{Pretrained, Instruction-tuned, Alignment-tuned}. Models based on\\nSOLAR 10.7B are colored purple. The best scores </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for H6 and the individual tasks are shown in bold.MetaMathQA (Yu et al., 2023) dataset.We reformatted the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">instruction datasets with an\\nAlpaca-styled chat template. For datasets such as\\nOpenOrca, which are derived from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">FLAN (Long-'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'81572589-f7d1-4959-b60e-44cf29f1a339'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Mistral 7B-Instruct-v0.2 7B  Instruction-tuned 65.71 63.14 84.88 60.78 68.26 77.19 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">40.03\\n Yi 34B-Chat 34B  Instruction-tuned 65.32 65.44 84.16 74.90 55.37 80.11 31.92\\n Mistral 7B 7B  Pretrained </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">60.97 59.98 83.31 64.16 42.15 78.37 37.83Table 2: Evaluation results in the Open LLM Leaderboard for SOLAR 10.7B </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and SOLAR 10.7B-Instruct along with\\nother top-performing models. We report the scores for the six tasks mentioned </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in Sec. 4.1 along with the H6 score\\n(average of six tasks). We also report the size of the models in units of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">billions of parameters. The type indicates the\\ntraining stage of the model and is chosen from {Pretrained, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Instruction-tuned, Alignment-tuned}. Models based on\\nSOLAR 10.7B are colored purple. The best scores for H6 and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the individual tasks are shown in bold.MetaMathQA (Yu et al., 2023) dataset.We reformatted the instruction datasets</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with an\\nAlpaca-styled chat template. For datasets such as\\nOpenOrca, which are derived from FLAN (Long-'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'_'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'The following indexed files are being used for this query: solar_paper.pdf, \u001b[0m\n",
       "\u001b[32msolar_sample.pdf, docai.pdf, kim-tse-2008.pdf\\n\\nSolar 10.7B is a large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with 10.7 billion \u001b[0m\n",
       "\u001b[32mparameters, demonstrating superior performance in various natural language processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m tasks. In the MMLU \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mMulti-Domain Evaluation\u001b[0m\u001b[32m)\u001b[0m\u001b[32m framework, it achieved an average score of 69.83, as shown in Table 2 of the provided \u001b[0m\n",
       "\u001b[32mcontent.'\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1728237594\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'sung-pro-1008'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_paper'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'research and practical applications, fostering\\nwider accessibility and utility \u001b[0m\n",
       "\u001b[32min various fields. Superior Performance Across Diverse\\nBenchmarks: SOLAR 10.7B excels in var-\\nious benchmarks, \u001b[0m\n",
       "\u001b[32moutperforming established\\nmodels like Llama 2 and Mistral 7B in reason-\\ning, mathematics, and the MMLU \u001b[0m\n",
       "\u001b[32mframework. Advancement in Instruction-Following Ca-\\npabilities: The introduction of SOLAR 10.7B-\\nInstruct, a \u001b[0m\n",
       "\u001b[32mvariant fine-tuned for enhanced\\ninstruction-following abilities, marks a sig-\\nnificant improvement in the models\u001b[0m\n",
       "\u001b[32mability to\\nunderstand and execute complex instructions.Sanghoon Kim, Dahyun Kim, Chanjun Park,\\nWonsung Lee, Wonho\u001b[0m\n",
       "\u001b[32mSong, Yunsu Kim and\\nHyeonwoo Kim contributed equally to this paper.\\nSanghoon Kim led the Foundation Model \u001b[0m\n",
       "\u001b[32mpart,\\nwith Dahyun Kim, Wonho Song, Yunsu Kim, and\\nHyeonwoo Kim. Chanjun Park led the Data and\\nEvaluation \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mData-Centric LLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m part, with Yungi\\nKim, Jihoo Kim, Changbae Ahn, Seonghoon Yang,\\nSukyung Lee, and Hyunbyung \u001b[0m\n",
       "\u001b[32mPark. Wonsung Lee'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'f6a2b9ec-0af7-4ba0-9936-d1d7f3704f21'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'research and practical applications, fostering\\nwider accessibility and utility in \u001b[0m\n",
       "\u001b[32mvarious fields. Superior Performance Across Diverse\\nBenchmarks: SOLAR 10.7B excels in var-\\nious benchmarks, \u001b[0m\n",
       "\u001b[32moutperforming established\\nmodels like Llama 2 and Mistral 7B in reason-\\ning, mathematics, and the MMLU \u001b[0m\n",
       "\u001b[32mframework. Advancement in Instruction-Following Ca-\\npabilities: The introduction of SOLAR 10.7B-\\nInstruct, a \u001b[0m\n",
       "\u001b[32mvariant fine-tuned for enhanced\\ninstruction-following abilities, marks a sig-\\nnificant improvement in the models\u001b[0m\n",
       "\u001b[32mability to\\nunderstand and execute complex instructions.Sanghoon Kim, Dahyun Kim, Chanjun Park,\\nWonsung Lee, Wonho\u001b[0m\n",
       "\u001b[32mSong, Yunsu Kim and\\nHyeonwoo Kim contributed equally to this paper.\\nSanghoon Kim led the Foundation Model \u001b[0m\n",
       "\u001b[32mpart,\\nwith Dahyun Kim, Wonho Song, Yunsu Kim, and\\nHyeonwoo Kim. Chanjun Park led the Data and\\nEvaluation \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mData-Centric LLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m part, with Yungi\\nKim, Jihoo Kim, Changbae Ahn, Seonghoon Yang,\\nSukyung Lee, and Hyunbyung \u001b[0m\n",
       "\u001b[32mPark. Wonsung Lee'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_paper'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'Wen, and Jiawei Han. 2023. Dont make your llm\\nan evaluation benchmark cheater.\u001b[0m\n",
       "\u001b[32marXiv preprint\\narXiv:2311.01964.Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B\\nBrown, Alec Radford, Dario \u001b[0m\n",
       "\u001b[32mAmodei, Paul Chris-\\ntiano, and Geoffrey Irving. 2019. Fine-tuning lan-\\nguage models from human preferences. \u001b[0m\n",
       "\u001b[32marXiv\\npreprint arXiv:1909.08593.A ContributionsThe contributions of this study are as follows: Introduction of \u001b[0m\n",
       "\u001b[32mthe SOLAR 10.7 Billion-\\nParameter Model: We have released the SO-\\nLAR 10.7B model, which is not only depth-\\nwise\u001b[0m\n",
       "\u001b[32mscaled but also continually pretrained.\\nThe availability of SOLAR 10.7B under the\\nApache 2.0 license permits \u001b[0m\n",
       "\u001b[32mcommercial us-\\nage, enabling the integration of this advanced\\nmodel into a diverse range of products and \u001b[0m\n",
       "\u001b[32mser-\\nvices. This bridges the gap between academic\\nresearch and practical applications, fostering\\nwider \u001b[0m\n",
       "\u001b[32maccessibility and utility in various fields. Superior Performance Across Diverse\\nBenchmarks: SOLAR 10.7B excels \u001b[0m\n",
       "\u001b[32min var-'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'e9bd9ca0-6b38-4544-be81-8247b4e6318f'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Wen, and Jiawei Han. 2023. Dont make your llm\\nan evaluation benchmark cheater. arXiv \u001b[0m\n",
       "\u001b[32mpreprint\\narXiv:2311.01964.Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B\\nBrown, Alec Radford, Dario Amodei, \u001b[0m\n",
       "\u001b[32mPaul Chris-\\ntiano, and Geoffrey Irving. 2019. Fine-tuning lan-\\nguage models from human preferences. \u001b[0m\n",
       "\u001b[32marXiv\\npreprint arXiv:1909.08593.A ContributionsThe contributions of this study are as follows: Introduction of \u001b[0m\n",
       "\u001b[32mthe SOLAR 10.7 Billion-\\nParameter Model: We have released the SO-\\nLAR 10.7B model, which is not only depth-\\nwise\u001b[0m\n",
       "\u001b[32mscaled but also continually pretrained.\\nThe availability of SOLAR 10.7B under the\\nApache 2.0 license permits \u001b[0m\n",
       "\u001b[32mcommercial us-\\nage, enabling the integration of this advanced\\nmodel into a diverse range of products and \u001b[0m\n",
       "\u001b[32mser-\\nvices. This bridges the gap between academic\\nresearch and practical applications, fostering\\nwider \u001b[0m\n",
       "\u001b[32maccessibility and utility in various fields. Superior Performance Across Diverse\\nBenchmarks: SOLAR 10.7B excels \u001b[0m\n",
       "\u001b[32min var-'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_paper'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'there are no additional modules or dynamism as\\nwith MoE, making DUS immediately\u001b[0m\n",
       "\u001b[32mcompatible\\nwith easy-to-use LLM frameworks such as Hug-\\ngingFace \u001b[0m\u001b[32m(\u001b[0m\u001b[32mWolf et al., 2019\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with no changes to\\nthe \u001b[0m\n",
       "\u001b[32mtraining or inference framework for maximal\\nefficiency. Furthermore, DUS is applicable to all\\ntransformer \u001b[0m\n",
       "\u001b[32marchitectures, opening up new gate-\\nways to effectively and efficiently scale-up LLMs\\nin a simple manner. Using \u001b[0m\n",
       "\u001b[32mDUS, we release SO-\\nLAR 10.7B, an LLM with 10.7 billion parameters,\\nthat outperforms existing models like Llama 2\u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mTou-\\nvron et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Mistral 7B \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJiang et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nin various benchmarks.We have also developed SOLAR \u001b[0m\n",
       "\u001b[32m10.7B-Instruct,\\na variant fine-tuned for tasks requiring strict adher-\\nence to complex instructions. It \u001b[0m\n",
       "\u001b[32msignificantly out-\\nperforms the Mixtral-8x7B-Instruct model across\\nvarious evaluation metrics, evidencing an \u001b[0m\n",
       "\u001b[32madvanced\\nproficiency that exceeds the capabilities of even\\nlarger models in terms of benchmark performance.By \u001b[0m\n",
       "\u001b[32mreleasing SOLAR 10.7B under the Apache'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'be83e758-cce0-407c-9d03-8b39c372ff82'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'there are no additional modules or dynamism as\\nwith MoE, making DUS immediately \u001b[0m\n",
       "\u001b[32mcompatible\\nwith easy-to-use LLM frameworks such as Hug-\\ngingFace \u001b[0m\u001b[32m(\u001b[0m\u001b[32mWolf et al., 2019\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with no changes to\\nthe \u001b[0m\n",
       "\u001b[32mtraining or inference framework for maximal\\nefficiency. Furthermore, DUS is applicable to all\\ntransformer \u001b[0m\n",
       "\u001b[32marchitectures, opening up new gate-\\nways to effectively and efficiently scale-up LLMs\\nin a simple manner. Using \u001b[0m\n",
       "\u001b[32mDUS, we release SO-\\nLAR 10.7B, an LLM with 10.7 billion parameters,\\nthat outperforms existing models like Llama 2\u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mTou-\\nvron et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Mistral 7B \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJiang et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nin various benchmarks.We have also developed SOLAR \u001b[0m\n",
       "\u001b[32m10.7B-Instruct,\\na variant fine-tuned for tasks requiring strict adher-\\nence to complex instructions. It \u001b[0m\n",
       "\u001b[32msignificantly out-\\nperforms the Mixtral-8x7B-Instruct model across\\nvarious evaluation metrics, evidencing an \u001b[0m\n",
       "\u001b[32madvanced\\nproficiency that exceeds the capabilities of even\\nlarger models in terms of benchmark performance.By \u001b[0m\n",
       "\u001b[32mreleasing SOLAR 10.7B under the Apache'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_paper'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'training stage of the model and is chosen from \u001b[0m\u001b[32m{\u001b[0m\u001b[32mPretrained, Instruction-tuned, \u001b[0m\n",
       "\u001b[32mAlignment-tuned\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Models based on\\nSOLAR 10.7B are colored purple. The best scores for H6 and the individual tasks \u001b[0m\n",
       "\u001b[32mare shown in bold.MetaMathQA \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYu et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m dataset.We reformatted the instruction datasets with \u001b[0m\n",
       "\u001b[32man\\nAlpaca-styled chat template. For datasets such as\\nOpenOrca, which are derived from FLAN \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLong-\\npre et al., \u001b[0m\n",
       "\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, we filter data that overlaps with\\nthe benchmark datasets \u001b[0m\u001b[32m(\u001b[0m\u001b[32msee Tab. 8 in Appendix. C\\nfor more information\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\u001b[0m\n",
       "\u001b[32mThe alignment datasets\\nare in the \u001b[0m\u001b[32m{\u001b[0m\u001b[32mprompt, chosen, rejected\u001b[0m\u001b[32m}\u001b[0m\u001b[32m triplet for-\\nmat. We preprocess the alignment \u001b[0m\n",
       "\u001b[32mdatasets follow-\\ning Zephyr \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTunstall et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. We use Data-\\nverse \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPark et al., 2024\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for data \u001b[0m\n",
       "\u001b[32mpreprocessing.Evaluation. In the HuggingFace Open LLM\\nLeaderboard \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBeeching et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, six types \u001b[0m\n",
       "\u001b[32mof\\nevaluation methods are presented: ARC \u001b[0m\u001b[32m(\u001b[0m\u001b[32mClark\\net al., 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, HellaSWAG \u001b[0m\u001b[32m(\u001b[0m\u001b[32mZellers et al., 2019\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\nMMLU \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHendrycks\u001b[0m\n",
       "\u001b[32met al., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, TruthfulQA \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLin'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'9c3b8cd3-6d05-48bd-89d4-c1f8d8c78098'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'training stage of the model and is chosen from \u001b[0m\u001b[32m{\u001b[0m\u001b[32mPretrained, Instruction-tuned, \u001b[0m\n",
       "\u001b[32mAlignment-tuned\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Models based on\\nSOLAR 10.7B are colored purple. The best scores for H6 and the individual tasks \u001b[0m\n",
       "\u001b[32mare shown in bold.MetaMathQA \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYu et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m dataset.We reformatted the instruction datasets with \u001b[0m\n",
       "\u001b[32man\\nAlpaca-styled chat template. For datasets such as\\nOpenOrca, which are derived from FLAN \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLong-\\npre et al., \u001b[0m\n",
       "\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, we filter data that overlaps with\\nthe benchmark datasets \u001b[0m\u001b[32m(\u001b[0m\u001b[32msee Tab. 8 in Appendix. C\\nfor more information\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\u001b[0m\n",
       "\u001b[32mThe alignment datasets\\nare in the \u001b[0m\u001b[32m{\u001b[0m\u001b[32mprompt, chosen, rejected\u001b[0m\u001b[32m}\u001b[0m\u001b[32m triplet for-\\nmat. We preprocess the alignment \u001b[0m\n",
       "\u001b[32mdatasets follow-\\ning Zephyr \u001b[0m\u001b[32m(\u001b[0m\u001b[32mTunstall et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. We use Data-\\nverse \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPark et al., 2024\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for data \u001b[0m\n",
       "\u001b[32mpreprocessing.Evaluation. In the HuggingFace Open LLM\\nLeaderboard \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBeeching et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, six types \u001b[0m\n",
       "\u001b[32mof\\nevaluation methods are presented: ARC \u001b[0m\u001b[32m(\u001b[0m\u001b[32mClark\\net al., 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, HellaSWAG \u001b[0m\u001b[32m(\u001b[0m\u001b[32mZellers et al., 2019\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\nMMLU \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHendrycks\u001b[0m\n",
       "\u001b[32met al., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, TruthfulQA \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLin'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_paper'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective\\nDepth \u001b[0m\n",
       "\u001b[32mUp-ScalingDahyun Kim, Chanjun Park, Sanghoon Kim, Wonsung Lee, Wonho Song\\nYunsu Kim, Hyeonwoo Kim, Yungi\u001b[0m\n",
       "\u001b[32mKim, Hyeonju Lee, Jihoo Kim\\nChangbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim\\nMikyoung \u001b[0m\n",
       "\u001b[32mCha, Hwalsuk Lee, Sunghun KimUpstage AI, South Korea\u001b[0m\u001b[32m{\u001b[0m\u001b[32mkdahyun, chanjun.park, limerobot, wonsung.lee, hwalsuk.lee, \u001b[0m\n",
       "\u001b[32mhunkim\u001b[0m\u001b[32m}\u001b[0m\u001b[32m@upstage.aiAbstractWe introduce SOLAR 10.7B, a large language\\nmodel \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with 10.7 billion \u001b[0m\n",
       "\u001b[32mparameters,\\ndemonstrating superior performance in various\\nnatural language processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m tasks. In-\\nspired by\u001b[0m\n",
       "\u001b[32mrecent efforts to efficiently up-scale\\nLLMs, we present a method for scaling LLMs\\ncalled depth up-scaling \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDUS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mwhich encom-\\npasses depthwise scaling and continued pre-\\ntraining. In contrast to other LLM up-scaling\\nmethods \u001b[0m\n",
       "\u001b[32mthat use mixture-of-experts, DUS does\\nnot require complex changes to train and infer-\\nence efficiently. We show \u001b[0m\n",
       "\u001b[32mexperimentally that'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'd175b4c0-6c1d-4279-bb25-0ea9ccb820b4'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective\\nDepth \u001b[0m\n",
       "\u001b[32mUp-ScalingDahyun Kim, Chanjun Park, Sanghoon Kim, Wonsung Lee, Wonho Song\\nYunsu Kim, Hyeonwoo Kim, Yungi\u001b[0m\n",
       "\u001b[32mKim, Hyeonju Lee, Jihoo Kim\\nChangbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim\\nMikyoung \u001b[0m\n",
       "\u001b[32mCha, Hwalsuk Lee, Sunghun KimUpstage AI, South Korea\u001b[0m\u001b[32m{\u001b[0m\u001b[32mkdahyun, chanjun.park, limerobot, wonsung.lee, hwalsuk.lee, \u001b[0m\n",
       "\u001b[32mhunkim\u001b[0m\u001b[32m}\u001b[0m\u001b[32m@upstage.aiAbstractWe introduce SOLAR 10.7B, a large language\\nmodel \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m with 10.7 billion \u001b[0m\n",
       "\u001b[32mparameters,\\ndemonstrating superior performance in various\\nnatural language processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m tasks. In-\\nspired by\u001b[0m\n",
       "\u001b[32mrecent efforts to efficiently up-scale\\nLLMs, we present a method for scaling LLMs\\ncalled depth up-scaling \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDUS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mwhich encom-\\npasses depthwise scaling and continued pre-\\ntraining. In contrast to other LLM up-scaling\\nmethods \u001b[0m\n",
       "\u001b[32mthat use mixture-of-experts, DUS does\\nnot require complex changes to train and infer-\\nence efficiently. We show \u001b[0m\n",
       "\u001b[32mexperimentally that'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_paper'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'training. In contrast to other LLM up-scaling\\nmethods that use \u001b[0m\n",
       "\u001b[32mmixture-of-experts, DUS does\\nnot require complex changes to train and infer-\\nence efficiently. We show \u001b[0m\n",
       "\u001b[32mexperimentally that\\nDUS is simple yet effective in scaling up high-\\nperformance LLMs from small ones. \u001b[0m\n",
       "\u001b[32mBuilding\\non the DUS model, we additionally present SO-\\nLAR 10.7B-Instruct, a variant fine-tuned \u001b[0m\n",
       "\u001b[32mfor\\ninstruction-following capabilities, surpassing\\nMixtral-8x7B-Instruct. SOLAR 10.7B is pub-\\nlicly available \u001b[0m\n",
       "\u001b[32munder the Apache 2.0 license,\\npromoting broad access and application in the\\nLLM field 1.1 \u001b[0m\n",
       "\u001b[32mIntroduction2024\\nApr\\n4\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.CL\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\narXiv:2312.15166v3The field of natural language processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nhas been \u001b[0m\n",
       "\u001b[32msignificantly transformed by the introduc-\\ntion of large language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which have\\nenhanced our \u001b[0m\n",
       "\u001b[32munderstanding and interaction with\\nhuman language \u001b[0m\u001b[32m(\u001b[0m\u001b[32mZhao et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. These ad-\\nvancements bring challenges such\u001b[0m\n",
       "\u001b[32mas the increased\\nneed to train ever larger models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRae et al., 2021;'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'9f6dcf67-518b-4a8e-b172-2b8596c7c7cf'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'training. In contrast to other LLM up-scaling\\nmethods that use mixture-of-experts, DUS \u001b[0m\n",
       "\u001b[32mdoes\\nnot require complex changes to train and infer-\\nence efficiently. We show experimentally that\\nDUS is simple\u001b[0m\n",
       "\u001b[32myet effective in scaling up high-\\nperformance LLMs from small ones. Building\\non the DUS model, we additionally \u001b[0m\n",
       "\u001b[32mpresent SO-\\nLAR 10.7B-Instruct, a variant fine-tuned for\\ninstruction-following capabilities, \u001b[0m\n",
       "\u001b[32msurpassing\\nMixtral-8x7B-Instruct. SOLAR 10.7B is pub-\\nlicly available under the Apache 2.0 license,\\npromoting \u001b[0m\n",
       "\u001b[32mbroad access and application in the\\nLLM field 1.1 Introduction2024\\nApr\\n4\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32mcs.CL\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\narXiv:2312.15166v3The field \u001b[0m\n",
       "\u001b[32mof natural language processing \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nhas been significantly transformed by the introduc-\\ntion of large language \u001b[0m\n",
       "\u001b[32mmodels \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which have\\nenhanced our understanding and interaction with\\nhuman language \u001b[0m\u001b[32m(\u001b[0m\u001b[32mZhao et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. \u001b[0m\n",
       "\u001b[32mThese ad-\\nvancements bring challenges such as the increased\\nneed to train ever larger models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRae et al., 2021;'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_paper'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'Llama 2 70B  70B Pretrained 67.87 67.32 87.33 69.83 44.92 83.74 54.06\\n Falcon \u001b[0m\n",
       "\u001b[32m180B  180B Pretrained 67.85 69.45 88.86 70.50 45.47 86.90 45.94\\n SOLAR 10.7B  11B Pretrained 66.04 61.95 84.60 \u001b[0m\n",
       "\u001b[32m65.48 45.04 83.66 55.50\\n Qwen 14B  14B Pretrained 65.86 58.28 83.99 67.70 49.43 76.80 58.98\\n Mistral \u001b[0m\n",
       "\u001b[32m7B-Instruct-v0.2  7B Instruction-tuned 65.71 63.14 84.88 60.78 68.26 77.19 40.03\\n Yi 34B-Chat  34B \u001b[0m\n",
       "\u001b[32mInstruction-tuned 65.32 65.44 84.16 74.90 55.37 80.11 31.92\\n Mistral 7B  7B Pretrained 60.97 59.98 83.31 64.16 \u001b[0m\n",
       "\u001b[32m42.15 78.37 37.83Table 2: Evaluation results in the Open LLM Leaderboard for SOLAR 10.7B and SOLAR 10.7B-Instruct \u001b[0m\n",
       "\u001b[32malong with\\nother top-performing models. We report the scores for the six tasks mentioned in Sec. 4.1 along with \u001b[0m\n",
       "\u001b[32mthe H6 score\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32maverage of six tasks\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. We also report the size of the models in units of billions of parameters. The\u001b[0m\n",
       "\u001b[32mtype indicates the\\ntraining stage of the model and is chosen from \u001b[0m\u001b[32m{\u001b[0m\u001b[32mPretrained, Instruction-tuned, \u001b[0m\n",
       "\u001b[32mAlignment-tuned\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Models based on'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'38c0e5d5-6ce5-4cd0-87b3-5ca968ea7263'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Llama 2 70B  70B Pretrained 67.87 67.32 87.33 69.83 44.92 83.74 54.06\\n Falcon 180B  \u001b[0m\n",
       "\u001b[32m180B Pretrained 67.85 69.45 88.86 70.50 45.47 86.90 45.94\\n SOLAR 10.7B  11B Pretrained 66.04 61.95 84.60 65.48 \u001b[0m\n",
       "\u001b[32m45.04 83.66 55.50\\n Qwen 14B  14B Pretrained 65.86 58.28 83.99 67.70 49.43 76.80 58.98\\n Mistral 7B-Instruct-v0.2 \u001b[0m\n",
       "\u001b[32m 7B Instruction-tuned 65.71 63.14 84.88 60.78 68.26 77.19 40.03\\n Yi 34B-Chat  34B Instruction-tuned 65.32 65.44 \u001b[0m\n",
       "\u001b[32m84.16 74.90 55.37 80.11 31.92\\n Mistral 7B  7B Pretrained 60.97 59.98 83.31 64.16 42.15 78.37 37.83Table 2: \u001b[0m\n",
       "\u001b[32mEvaluation results in the Open LLM Leaderboard for SOLAR 10.7B and SOLAR 10.7B-Instruct along with\\nother \u001b[0m\n",
       "\u001b[32mtop-performing models. We report the scores for the six tasks mentioned in Sec. 4.1 along with the H6 \u001b[0m\n",
       "\u001b[32mscore\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32maverage of six tasks\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. We also report the size of the models in units of billions of parameters. The type \u001b[0m\n",
       "\u001b[32mindicates the\\ntraining stage of the model and is chosen from \u001b[0m\u001b[32m{\u001b[0m\u001b[32mPretrained, Instruction-tuned, Alignment-tuned\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. \u001b[0m\n",
       "\u001b[32mModels based on'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_sample'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'port the average scores for the six tasks, e.g., H6.\\nWe either submit directly \u001b[0m\n",
       "\u001b[32mto the Open LLM Leader-\\nboard or utilize Evalverse \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKim et al., 2024b\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for\\nrunning evaluations locally.Model \u001b[0m\n",
       "\u001b[32mmerging. Model merging methods such\\nas Yadav et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m can boost model perfor-\\nmance without further \u001b[0m\n",
       "\u001b[32mtraining. We merge some\\nof the models that we trained in both the instruc-\\ntion and alignment tuning stages. We \u001b[0m\n",
       "\u001b[32mimplement\\nour own merging methods although popular open\\nsource also exist such as MergeKit3.4.2 Main ResultsWe \u001b[0m\n",
       "\u001b[32mpresent evaluation results for our SOLAR\\n10.7B and SOLAR 10.7B-Instruct models \u001b[0m\n",
       "\u001b[32malong3https://github.com/cg123/mergekitwith other top-performing models in Tab. 2. SO-\\nLAR 10.7B outperforms other\u001b[0m\n",
       "\u001b[32mpretrained models\\nof similar sizes, such as Qwen 14B and Mistral\\n7B, which shows that DUS is an effective \u001b[0m\n",
       "\u001b[32mmethod\\nto up-scale base LLMs. Furthermore, despite the\\nsmaller size, SOLAR 10.7B-Instruct scores the\\nhighest in \u001b[0m\n",
       "\u001b[32mterms of H6, even surpassing the recent'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'c3bb1029-66a7-4e0b-b100-30c188853701'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'port the average scores for the six tasks, e.g., H6.\\nWe either submit directly to the \u001b[0m\n",
       "\u001b[32mOpen LLM Leader-\\nboard or utilize Evalverse \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKim et al., 2024b\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for\\nrunning evaluations locally.Model merging. \u001b[0m\n",
       "\u001b[32mModel merging methods such\\nas Yadav et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m can boost model perfor-\\nmance without further training. We \u001b[0m\n",
       "\u001b[32mmerge some\\nof the models that we trained in both the instruc-\\ntion and alignment tuning stages. We implement\\nour\u001b[0m\n",
       "\u001b[32mown merging methods although popular open\\nsource also exist such as MergeKit3.4.2 Main ResultsWe present \u001b[0m\n",
       "\u001b[32mevaluation results for our SOLAR\\n10.7B and SOLAR 10.7B-Instruct models along3https://github.com/cg123/mergekitwith\u001b[0m\n",
       "\u001b[32mother top-performing models in Tab. 2. SO-\\nLAR 10.7B outperforms other pretrained models\\nof similar sizes, such \u001b[0m\n",
       "\u001b[32mas Qwen 14B and Mistral\\n7B, which shows that DUS is an effective method\\nto up-scale base LLMs. Furthermore, \u001b[0m\n",
       "\u001b[32mdespite the\\nsmaller size, SOLAR 10.7B-Instruct scores the\\nhighest in terms of H6, even surpassing the recent'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_sample'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'Mistral 7B-Instruct-v0.2 7B  Instruction-tuned 65.71 63.14 84.88 60.78 68.26 \u001b[0m\n",
       "\u001b[32m77.19 40.03\\n Yi 34B-Chat 34B  Instruction-tuned 65.32 65.44 84.16 74.90 55.37 80.11 31.92\\n Mistral 7B 7B  \u001b[0m\n",
       "\u001b[32mPretrained 60.97 59.98 83.31 64.16 42.15 78.37 37.83Table 2: Evaluation results in the Open LLM Leaderboard for \u001b[0m\n",
       "\u001b[32mSOLAR 10.7B and SOLAR 10.7B-Instruct along with\\nother top-performing models. We report the scores for the six \u001b[0m\n",
       "\u001b[32mtasks mentioned in Sec. 4.1 along with the H6 score\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32maverage of six tasks\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. We also report the size of the models \u001b[0m\n",
       "\u001b[32min units of billions of parameters. The type indicates the\\ntraining stage of the model and is chosen from \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32mPretrained, Instruction-tuned, Alignment-tuned\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Models based on\\nSOLAR 10.7B are colored purple. The best scores \u001b[0m\n",
       "\u001b[32mfor H6 and the individual tasks are shown in bold.MetaMathQA \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYu et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m dataset.We reformatted the \u001b[0m\n",
       "\u001b[32minstruction datasets with an\\nAlpaca-styled chat template. For datasets such as\\nOpenOrca, which are derived from \u001b[0m\n",
       "\u001b[32mFLAN \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLong-'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'81572589-f7d1-4959-b60e-44cf29f1a339'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1008'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Mistral 7B-Instruct-v0.2 7B  Instruction-tuned 65.71 63.14 84.88 60.78 68.26 77.19 \u001b[0m\n",
       "\u001b[32m40.03\\n Yi 34B-Chat 34B  Instruction-tuned 65.32 65.44 84.16 74.90 55.37 80.11 31.92\\n Mistral 7B 7B  Pretrained \u001b[0m\n",
       "\u001b[32m60.97 59.98 83.31 64.16 42.15 78.37 37.83Table 2: Evaluation results in the Open LLM Leaderboard for SOLAR 10.7B \u001b[0m\n",
       "\u001b[32mand SOLAR 10.7B-Instruct along with\\nother top-performing models. We report the scores for the six tasks mentioned \u001b[0m\n",
       "\u001b[32min Sec. 4.1 along with the H6 score\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32maverage of six tasks\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. We also report the size of the models in units of \u001b[0m\n",
       "\u001b[32mbillions of parameters. The type indicates the\\ntraining stage of the model and is chosen from \u001b[0m\u001b[32m{\u001b[0m\u001b[32mPretrained, \u001b[0m\n",
       "\u001b[32mInstruction-tuned, Alignment-tuned\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Models based on\\nSOLAR 10.7B are colored purple. The best scores for H6 and \u001b[0m\n",
       "\u001b[32mthe individual tasks are shown in bold.MetaMathQA \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYu et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m dataset.We reformatted the instruction datasets\u001b[0m\n",
       "\u001b[32mwith an\\nAlpaca-styled chat template. For datasets such as\\nOpenOrca, which are derived from FLAN \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLong-'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with custom base URL and API key\n",
    "client = OpenAI(\n",
    "    base_url=rag_base_url,  # Using the custom RAG API base URL\n",
    "    api_key=os.environ[\n",
    "        \"UPSTAGE_API_KEY\"\n",
    "    ],  # Using the API key from environment variables\n",
    ")\n",
    "\n",
    "# Send a request to the RAG model\n",
    "response = client.chat.completions.create(\n",
    "    model=rag_model_name,  # Using the previously defined RAG model name\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What's Solar 10.7B LLM MMLU?\"}],  # The user's query\n",
    "    stream=True,  # Disable streaming for synchronous response\n",
    "    extra_body={\n",
    "        \"hybrid_search\": True,  # Enable hybrid search for better results\n",
    "        \"contextual_chunk\": False,\n",
    "        \"contextual_query\": True,\n",
    "        \"knowledge_graph\": False,\n",
    "        \"kv_pairs\": False,\n",
    "        \"verbose\": True,  # Request verbose output for debugging\n",
    "    },\n",
    ")\n",
    "\n",
    "# Print the model's response\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7793bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'_'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The following indexed files are being used for this query: solar_paper.pdf, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">solar_sample.pdf, docai.pdf, kim-tse-2008.pdf\\n\\nThe features of Document AI are:\\n\\n1. \"Layout Analyzer: Extracts </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">layouts, tables, and figures from any document.\"\\n2. \"Key Information Extractor: Extracts key information from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">target documents.\"\\n3. \"Document OCR: Extracts all text from any document.\"\\n\\nThese features have resulted in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">higher accuracy (95%-98% accuracy rate) compared to previous manual human work for document processing in various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enterprise use cases.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727891103.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sung-pro-1001'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'docai'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Document AI: Digitize anythingUpstage Document AI is comprised of three </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">solutions: Layout Analyzer: Extracts layouts, tables, and figures from any document.\\n Key Information Extractor:</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Extracts key information from target documents.\\n Document OCR: Extracts all text from any document.In various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enterprise use cases, Upstage Document AI resulted in higher accuracy\\n(95%-98% accuracy rate) compared to previous</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manual human work for document\\nprocessing. Due to its strong performance, the solution has been heavily adopted by</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various\\nleading insurance providers, yielding significant productivity gains and operating cost\\nreductions.Please</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">find customer testimonials, key customers, and customer success stories below.[Key customers]'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bf98c39f-4f74-4eda-9d62-b411fd22d25d'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'contextual_query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\"What are the features of Document AI?\"'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document AI: Digitize anythingUpstage Document AI is comprised of three solutions: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Layout Analyzer: Extracts layouts, tables, and figures from any document.\\n Key Information Extractor: Extracts </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">key information from target documents.\\n Document OCR: Extracts all text from any document.In various enterprise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use cases, Upstage Document AI resulted in higher accuracy\\n(95%-98% accuracy rate) compared to previous manual </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human work for document\\nprocessing. Due to its strong performance, the solution has been heavily adopted by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various\\nleading insurance providers, yielding significant productivity gains and operating cost\\nreductions.Please</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">find customer testimonials, key customers, and customer success stories below.[Key customers]'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'kim-tse-2008'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[42] M.D. Penta, S. Gradara, and G. Antoniol, Traceability Recovery\\nin RAD </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Software Systems, Proc. 10th IEEE Intl Workshop Program\\nComprehension, pp. 207-216, 2002.\\n[43] B. Raskutti, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">H.L. Ferra , and A. Kowalczyk, Second-Order\\nFeatures for Maximizing Text Classification Performance, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Proc.\\n12th European Conf. Machine Learning, pp. 419-430, 2001.\\n[44] Scientific Toolworks, Maintenance, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Understanding, Metrics and\\nDocumentation Tools for Ada, C, C++, Java, and FORTRAN,\\nhttp://www.scitools.com/, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2005.\\n[45] S. Scott and S. Matwin, Feature Engineering for Text Classifica-\\ntion, Proc. 16th Intl Conf. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Machine Learning, pp. 379-388, 1999.[46] F. Sebastiani, Machine Learning in Automated Text Categoriza-\\ntion, ACM</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Computing Surveys, vol. 34, no. 1, pp. 1-47, 2002.\\n[47] J. (cid:2)Sliwerski, T. Zimmermann, and A. Zeller, When </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Do Changes\\nInduce Fixes? Proc. Intl Workshop Mining Software Repositories,\\npp. 24-28, 2005.\\n[48] J.C. Spohrer,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">E. Soloway, and E. Pope, Where the Bugs Are,'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'8d9a1eed-5f89-4492-9678-663503ce3370'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'contextual_query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\"What are the features of Document AI?\"'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'[42] M.D. Penta, S. Gradara, and G. Antoniol, Traceability Recovery\\nin RAD Software </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Systems, Proc. 10th IEEE Intl Workshop Program\\nComprehension, pp. 207-216, 2002.\\n[43] B. Raskutti, H.L. Ferra </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">, and A. Kowalczyk, Second-Order\\nFeatures for Maximizing Text Classification Performance, Proc.\\n12th European </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Conf. Machine Learning, pp. 419-430, 2001.\\n[44] Scientific Toolworks, Maintenance, Understanding, Metrics </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and\\nDocumentation Tools for Ada, C, C++, Java, and FORTRAN,\\nhttp://www.scitools.com/, 2005.\\n[45] S. Scott and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">S. Matwin, Feature Engineering for Text Classifica-\\ntion, Proc. 16th Intl Conf. Machine Learning, pp. 379-388, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">1999.[46] F. Sebastiani, Machine Learning in Automated Text Categoriza-\\ntion, ACM Computing Surveys, vol. 34, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">no. 1, pp. 1-47, 2002.\\n[47] J. (cid:2)Sliwerski, T. Zimmermann, and A. Zeller, When Do Changes\\nInduce Fixes? </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Proc. Intl Workshop Mining Software Repositories,\\npp. 24-28, 2005.\\n[48] J.C. Spohrer, E. Soloway, and E. Pope, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Where the Bugs Are,'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'kim-tse-2008'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'. Revision 3 shows a change, the actual bug fix,\\nchanging line 3 from == to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">!=.The SZZ algorithm then identifies the bug-introducing\\nchange associated with the bug fix in revision 3. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">starts by\\ncomputing the delta between revisions 3 and 2, yieldingKIM ET AL.: CLASSIFYING SOFTWARE CHANGES: CLEAN </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">OR BUGGY?187line 3. SZZ then uses the SCM annotate data to determine\\nthe initial origin of line 3 at revision 2. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This is revision 1, the\\nbug-introducing change.One assumption of the presentation so far is that a bug </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is\\nrepaired in a single bug-fix change. What happens when a\\nbug is repaired across multiple commits? There are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">two\\ncases. In the first case, a bug repair is split across multiple\\ncommits, with each commit modifying a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">separate section of\\nthe code (code sections are disjoint). Each separate change is\\ntracked back to its initial </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">bug-introducing change, which is\\nthen used to train the SVM classifier. In the second case, a bug'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'c01f0c68-b1e1-44ae-bcf0-7bdc959f9392'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'contextual_query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\"What are the features of Document AI?\"'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'. Revision 3 shows a change, the actual bug fix,\\nchanging line 3 from == to !=.The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">SZZ algorithm then identifies the bug-introducing\\nchange associated with the bug fix in revision 3. It starts </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by\\ncomputing the delta between revisions 3 and 2, yieldingKIM ET AL.: CLASSIFYING SOFTWARE CHANGES: CLEAN OR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">BUGGY?187line 3. SZZ then uses the SCM annotate data to determine\\nthe initial origin of line 3 at revision 2. This</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is revision 1, the\\nbug-introducing change.One assumption of the presentation so far is that a bug is\\nrepaired in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a single bug-fix change. What happens when a\\nbug is repaired across multiple commits? There are two\\ncases. In the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">first case, a bug repair is split across multiple\\ncommits, with each commit modifying a separate section of\\nthe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code (code sections are disjoint). Each separate change is\\ntracked back to its initial bug-introducing change, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which is\\nthen used to train the SVM classifier. In the second case, a bug'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Ashish Sabharwal, Carissa Schoenick, and Oyvind\\nTafjord. 2018. Think you have </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">solved question an-\\nswering? try arc, the ai2 reasoning challenge. arXiv\\npreprint arXiv:1803.05457.Karl Cobbe, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Vineet Kosaraju, Mohammad Bavarian,\\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Hilton, Reiichiro\\nNakano, et al. 2021. Training verifiers to solve math\\nword problems. arXiv preprint </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv:2110.14168.Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao,\\nWei Zhu, Yuan Ni, Guotong Xie, Zhiyuan Liu, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and\\nMaosong Sun. 2023. Ultrafeedback: Boosting lan-\\nguage models with high-quality feedback. arXiv\\npreprint </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv:2310.01377.Chunyuan Deng, Yilun Zhao, Xiangru Tang, Mark Ger-\\nstein, and Arman Cohan. 2023. Investigating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data\\ncontamination in modern benchmarks for large lan-\\nguage models. arXiv preprint arXiv:2311.09783.Mohammad </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fraiwan and Natheer Khasawneh. 2023. A\\nreview of chatgpt applications in education, market-\\ning, software </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">engineering, and healthcare: Benefits,'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a3d2cc19-5ee7-4e63-b106-737b74671b37'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'contextual_query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\"What are the features of Document AI?\"'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Ashish Sabharwal, Carissa Schoenick, and Oyvind\\nTafjord. 2018. Think you have solved </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question an-\\nswering? try arc, the ai2 reasoning challenge. arXiv\\npreprint arXiv:1803.05457.Karl Cobbe, Vineet </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Kosaraju, Mohammad Bavarian,\\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob Hilton,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Reiichiro\\nNakano, et al. 2021. Training verifiers to solve math\\nword problems. arXiv preprint </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv:2110.14168.Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao,\\nWei Zhu, Yuan Ni, Guotong Xie, Zhiyuan Liu, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and\\nMaosong Sun. 2023. Ultrafeedback: Boosting lan-\\nguage models with high-quality feedback. arXiv\\npreprint </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">arXiv:2310.01377.Chunyuan Deng, Yilun Zhao, Xiangru Tang, Mark Ger-\\nstein, and Arman Cohan. 2023. Investigating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data\\ncontamination in modern benchmarks for large lan-\\nguage models. arXiv preprint arXiv:2311.09783.Mohammad </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fraiwan and Natheer Khasawneh. 2023. A\\nreview of chatgpt applications in education, market-\\ning, software </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">engineering, and healthcare: Benefits,'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'_'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'The following indexed files are being used for this query: solar_paper.pdf, \u001b[0m\n",
       "\u001b[32msolar_sample.pdf, docai.pdf, kim-tse-2008.pdf\\n\\nThe features of Document AI are:\\n\\n1. \"Layout Analyzer: Extracts \u001b[0m\n",
       "\u001b[32mlayouts, tables, and figures from any document.\"\\n2. \"Key Information Extractor: Extracts key information from \u001b[0m\n",
       "\u001b[32mtarget documents.\"\\n3. \"Document OCR: Extracts all text from any document.\"\\n\\nThese features have resulted in \u001b[0m\n",
       "\u001b[32mhigher accuracy \u001b[0m\u001b[32m(\u001b[0m\u001b[32m95%-98% accuracy rate\u001b[0m\u001b[32m)\u001b[0m\u001b[32m compared to previous manual human work for document processing in various \u001b[0m\n",
       "\u001b[32menterprise use cases.'\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1727891103\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'sung-pro-1001'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'docai'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'Document AI: Digitize anythingUpstage Document AI is comprised of three \u001b[0m\n",
       "\u001b[32msolutions: Layout Analyzer: Extracts layouts, tables, and figures from any document.\\n Key Information Extractor:\u001b[0m\n",
       "\u001b[32mExtracts key information from target documents.\\n Document OCR: Extracts all text from any document.In various \u001b[0m\n",
       "\u001b[32menterprise use cases, Upstage Document AI resulted in higher accuracy\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m95%-98% accuracy rate\u001b[0m\u001b[32m)\u001b[0m\u001b[32m compared to previous\u001b[0m\n",
       "\u001b[32mmanual human work for document\\nprocessing. Due to its strong performance, the solution has been heavily adopted by\u001b[0m\n",
       "\u001b[32mvarious\\nleading insurance providers, yielding significant productivity gains and operating cost\\nreductions.Please\u001b[0m\n",
       "\u001b[32mfind customer testimonials, key customers, and customer success stories below.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mKey customers\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'bf98c39f-4f74-4eda-9d62-b411fd22d25d'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'\u001b[0m,\n",
       "                \u001b[32m'contextual_query'\u001b[0m: \u001b[32m'\"What are the features of Document AI?\"'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Document AI: Digitize anythingUpstage Document AI is comprised of three solutions: \u001b[0m\n",
       "\u001b[32mLayout Analyzer: Extracts layouts, tables, and figures from any document.\\n Key Information Extractor: Extracts \u001b[0m\n",
       "\u001b[32mkey information from target documents.\\n Document OCR: Extracts all text from any document.In various enterprise \u001b[0m\n",
       "\u001b[32muse cases, Upstage Document AI resulted in higher accuracy\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m95%-98% accuracy rate\u001b[0m\u001b[32m)\u001b[0m\u001b[32m compared to previous manual \u001b[0m\n",
       "\u001b[32mhuman work for document\\nprocessing. Due to its strong performance, the solution has been heavily adopted by \u001b[0m\n",
       "\u001b[32mvarious\\nleading insurance providers, yielding significant productivity gains and operating cost\\nreductions.Please\u001b[0m\n",
       "\u001b[32mfind customer testimonials, key customers, and customer success stories below.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mKey customers\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'kim-tse-2008'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m42\u001b[0m\u001b[32m]\u001b[0m\u001b[32m M.D. Penta, S. Gradara, and G. Antoniol, Traceability Recovery\\nin RAD \u001b[0m\n",
       "\u001b[32mSoftware Systems, Proc. 10th IEEE Intl Workshop Program\\nComprehension, pp. 207-216, 2002.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m43\u001b[0m\u001b[32m]\u001b[0m\u001b[32m B. Raskutti, \u001b[0m\n",
       "\u001b[32mH.L. Ferra , and A. Kowalczyk, Second-Order\\nFeatures for Maximizing Text Classification Performance, \u001b[0m\n",
       "\u001b[32mProc.\\n12th European Conf. Machine Learning, pp. 419-430, 2001.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m44\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Scientific Toolworks, Maintenance, \u001b[0m\n",
       "\u001b[32mUnderstanding, Metrics and\\nDocumentation Tools for Ada, C, C++, Java, and FORTRAN,\\nhttp://www.scitools.com/, \u001b[0m\n",
       "\u001b[32m2005.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m45\u001b[0m\u001b[32m]\u001b[0m\u001b[32m S. Scott and S. Matwin, Feature Engineering for Text Classifica-\\ntion, Proc. 16th Intl Conf. \u001b[0m\n",
       "\u001b[32mMachine Learning, pp. 379-388, 1999.\u001b[0m\u001b[32m[\u001b[0m\u001b[32m46\u001b[0m\u001b[32m]\u001b[0m\u001b[32m F. Sebastiani, Machine Learning in Automated Text Categoriza-\\ntion, ACM\u001b[0m\n",
       "\u001b[32mComputing Surveys, vol. 34, no. 1, pp. 1-47, 2002.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m47\u001b[0m\u001b[32m]\u001b[0m\u001b[32m J. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mcid:2\u001b[0m\u001b[32m)\u001b[0m\u001b[32mSliwerski, T. Zimmermann, and A. Zeller, When \u001b[0m\n",
       "\u001b[32mDo Changes\\nInduce Fixes? Proc. Intl Workshop Mining Software Repositories,\\npp. 24-28, 2005.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m48\u001b[0m\u001b[32m]\u001b[0m\u001b[32m J.C. Spohrer,\u001b[0m\n",
       "\u001b[32mE. Soloway, and E. Pope, Where the Bugs Are,'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'8d9a1eed-5f89-4492-9678-663503ce3370'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'\u001b[0m,\n",
       "                \u001b[32m'contextual_query'\u001b[0m: \u001b[32m'\"What are the features of Document AI?\"'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m42\u001b[0m\u001b[32m]\u001b[0m\u001b[32m M.D. Penta, S. Gradara, and G. Antoniol, Traceability Recovery\\nin RAD Software \u001b[0m\n",
       "\u001b[32mSystems, Proc. 10th IEEE Intl Workshop Program\\nComprehension, pp. 207-216, 2002.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m43\u001b[0m\u001b[32m]\u001b[0m\u001b[32m B. Raskutti, H.L. Ferra \u001b[0m\n",
       "\u001b[32m, and A. Kowalczyk, Second-Order\\nFeatures for Maximizing Text Classification Performance, Proc.\\n12th European \u001b[0m\n",
       "\u001b[32mConf. Machine Learning, pp. 419-430, 2001.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m44\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Scientific Toolworks, Maintenance, Understanding, Metrics \u001b[0m\n",
       "\u001b[32mand\\nDocumentation Tools for Ada, C, C++, Java, and FORTRAN,\\nhttp://www.scitools.com/, 2005.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m45\u001b[0m\u001b[32m]\u001b[0m\u001b[32m S. Scott and \u001b[0m\n",
       "\u001b[32mS. Matwin, Feature Engineering for Text Classifica-\\ntion, Proc. 16th Intl Conf. Machine Learning, pp. 379-388, \u001b[0m\n",
       "\u001b[32m1999.\u001b[0m\u001b[32m[\u001b[0m\u001b[32m46\u001b[0m\u001b[32m]\u001b[0m\u001b[32m F. Sebastiani, Machine Learning in Automated Text Categoriza-\\ntion, ACM Computing Surveys, vol. 34, \u001b[0m\n",
       "\u001b[32mno. 1, pp. 1-47, 2002.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m47\u001b[0m\u001b[32m]\u001b[0m\u001b[32m J. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mcid:2\u001b[0m\u001b[32m)\u001b[0m\u001b[32mSliwerski, T. Zimmermann, and A. Zeller, When Do Changes\\nInduce Fixes? \u001b[0m\n",
       "\u001b[32mProc. Intl Workshop Mining Software Repositories,\\npp. 24-28, 2005.\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m48\u001b[0m\u001b[32m]\u001b[0m\u001b[32m J.C. Spohrer, E. Soloway, and E. Pope, \u001b[0m\n",
       "\u001b[32mWhere the Bugs Are,'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'kim-tse-2008'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'. Revision 3 shows a change, the actual bug fix,\\nchanging line 3 from == to \u001b[0m\n",
       "\u001b[32m!=.The SZZ algorithm then identifies the bug-introducing\\nchange associated with the bug fix in revision 3. It \u001b[0m\n",
       "\u001b[32mstarts by\\ncomputing the delta between revisions 3 and 2, yieldingKIM ET AL.: CLASSIFYING SOFTWARE CHANGES: CLEAN \u001b[0m\n",
       "\u001b[32mOR BUGGY?187line 3. SZZ then uses the SCM annotate data to determine\\nthe initial origin of line 3 at revision 2. \u001b[0m\n",
       "\u001b[32mThis is revision 1, the\\nbug-introducing change.One assumption of the presentation so far is that a bug \u001b[0m\n",
       "\u001b[32mis\\nrepaired in a single bug-fix change. What happens when a\\nbug is repaired across multiple commits? There are \u001b[0m\n",
       "\u001b[32mtwo\\ncases. In the first case, a bug repair is split across multiple\\ncommits, with each commit modifying a \u001b[0m\n",
       "\u001b[32mseparate section of\\nthe code \u001b[0m\u001b[32m(\u001b[0m\u001b[32mcode sections are disjoint\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Each separate change is\\ntracked back to its initial \u001b[0m\n",
       "\u001b[32mbug-introducing change, which is\\nthen used to train the SVM classifier. In the second case, a bug'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'c01f0c68-b1e1-44ae-bcf0-7bdc959f9392'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'\u001b[0m,\n",
       "                \u001b[32m'contextual_query'\u001b[0m: \u001b[32m'\"What are the features of Document AI?\"'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'. Revision 3 shows a change, the actual bug fix,\\nchanging line 3 from == to !=.The \u001b[0m\n",
       "\u001b[32mSZZ algorithm then identifies the bug-introducing\\nchange associated with the bug fix in revision 3. It starts \u001b[0m\n",
       "\u001b[32mby\\ncomputing the delta between revisions 3 and 2, yieldingKIM ET AL.: CLASSIFYING SOFTWARE CHANGES: CLEAN OR \u001b[0m\n",
       "\u001b[32mBUGGY?187line 3. SZZ then uses the SCM annotate data to determine\\nthe initial origin of line 3 at revision 2. This\u001b[0m\n",
       "\u001b[32mis revision 1, the\\nbug-introducing change.One assumption of the presentation so far is that a bug is\\nrepaired in \u001b[0m\n",
       "\u001b[32ma single bug-fix change. What happens when a\\nbug is repaired across multiple commits? There are two\\ncases. In the\u001b[0m\n",
       "\u001b[32mfirst case, a bug repair is split across multiple\\ncommits, with each commit modifying a separate section of\\nthe \u001b[0m\n",
       "\u001b[32mcode \u001b[0m\u001b[32m(\u001b[0m\u001b[32mcode sections are disjoint\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Each separate change is\\ntracked back to its initial bug-introducing change, \u001b[0m\n",
       "\u001b[32mwhich is\\nthen used to train the SVM classifier. In the second case, a bug'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_paper'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'Ashish Sabharwal, Carissa Schoenick, and Oyvind\\nTafjord. 2018. Think you have \u001b[0m\n",
       "\u001b[32msolved question an-\\nswering? try arc, the ai2 reasoning challenge. arXiv\\npreprint arXiv:1803.05457.Karl Cobbe, \u001b[0m\n",
       "\u001b[32mVineet Kosaraju, Mohammad Bavarian,\\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob \u001b[0m\n",
       "\u001b[32mHilton, Reiichiro\\nNakano, et al. 2021. Training verifiers to solve math\\nword problems. arXiv preprint \u001b[0m\n",
       "\u001b[32marXiv:2110.14168.Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao,\\nWei Zhu, Yuan Ni, Guotong Xie, Zhiyuan Liu, \u001b[0m\n",
       "\u001b[32mand\\nMaosong Sun. 2023. Ultrafeedback: Boosting lan-\\nguage models with high-quality feedback. arXiv\\npreprint \u001b[0m\n",
       "\u001b[32marXiv:2310.01377.Chunyuan Deng, Yilun Zhao, Xiangru Tang, Mark Ger-\\nstein, and Arman Cohan. 2023. Investigating \u001b[0m\n",
       "\u001b[32mdata\\ncontamination in modern benchmarks for large lan-\\nguage models. arXiv preprint arXiv:2311.09783.Mohammad \u001b[0m\n",
       "\u001b[32mFraiwan and Natheer Khasawneh. 2023. A\\nreview of chatgpt applications in education, market-\\ning, software \u001b[0m\n",
       "\u001b[32mengineering, and healthcare: Benefits,'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'a3d2cc19-5ee7-4e63-b106-737b74671b37'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'\u001b[0m,\n",
       "                \u001b[32m'contextual_query'\u001b[0m: \u001b[32m'\"What are the features of Document AI?\"'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Ashish Sabharwal, Carissa Schoenick, and Oyvind\\nTafjord. 2018. Think you have solved \u001b[0m\n",
       "\u001b[32mquestion an-\\nswering? try arc, the ai2 reasoning challenge. arXiv\\npreprint arXiv:1803.05457.Karl Cobbe, Vineet \u001b[0m\n",
       "\u001b[32mKosaraju, Mohammad Bavarian,\\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\\nPlappert, Jerry Tworek, Jacob Hilton,\u001b[0m\n",
       "\u001b[32mReiichiro\\nNakano, et al. 2021. Training verifiers to solve math\\nword problems. arXiv preprint \u001b[0m\n",
       "\u001b[32marXiv:2110.14168.Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao,\\nWei Zhu, Yuan Ni, Guotong Xie, Zhiyuan Liu, \u001b[0m\n",
       "\u001b[32mand\\nMaosong Sun. 2023. Ultrafeedback: Boosting lan-\\nguage models with high-quality feedback. arXiv\\npreprint \u001b[0m\n",
       "\u001b[32marXiv:2310.01377.Chunyuan Deng, Yilun Zhao, Xiangru Tang, Mark Ger-\\nstein, and Arman Cohan. 2023. Investigating \u001b[0m\n",
       "\u001b[32mdata\\ncontamination in modern benchmarks for large lan-\\nguage models. arXiv preprint arXiv:2311.09783.Mohammad \u001b[0m\n",
       "\u001b[32mFraiwan and Natheer Khasawneh. 2023. A\\nreview of chatgpt applications in education, market-\\ning, software \u001b[0m\n",
       "\u001b[32mengineering, and healthcare: Benefits,'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Contextual Query\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with custom base URL and API key\n",
    "client = OpenAI(\n",
    "    base_url=rag_base_url,  # Using the custom RAG API base URL\n",
    "    api_key=os.environ[\n",
    "        \"UPSTAGE_API_KEY\"\n",
    "    ],  # Using the API key from environment variables\n",
    ")\n",
    "# Send a request to the RAG model\n",
    "response = client.chat.completions.create(\n",
    "    model=rag_model_name,  # Using the previously defined RAG model name\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What's the benefits of Document AI?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"It can help you understand the Document AI\"},\n",
    "        {\"role\": \"user\", \"content\": \"How about its features?\"},  # The user's query\n",
    "    ],\n",
    "    stream=False,  # Disable streaming for synchronous response\n",
    "    extra_body={\n",
    "        \"contextual_query\": True,\n",
    "        \"contextual_chunk\": False,\n",
    "        \"knowledge_graph\": False,\n",
    "        \"kv_pairs\": False,\n",
    "        \"verbose\": True,  # Request verbose output for debugging\n",
    "    },\n",
    ")\n",
    "\n",
    "# Print the model's response\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ba517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'_'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The following indexed files are being used for this query: solar_paper.pdf, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">solar_sample.pdf, docai.pdf, kim-tse-2008.pdf\\n\\nBased on the provided context, key-value pairs, and knowledge </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">graph, I can explain \"Document AI\" as follows:\\n\\nThe main topic of this document is \"Upstage Document AI: Digitize</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything\". Document AI is described as providing three solutions: \"Layout Analyzer\", \"Key Information Extractor\", </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and \"Document OCR\". Layout Analyzer extracts layouts, tables, and figures from any document. Key Information </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Extractor extracts key information from target documents. Document OCR extracts all text from any document. In </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enterprise use cases, Document AI achieved an accuracy rate of 95-98%, leading to significant productivity gains </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and operating cost reductions for leading insurance providers.\\n\\nHere are some direct quotes from the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context:\\n\\n1. \"This chunk introduces the main document and its three solutions, Layout Analyzer, Key Information </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Extractor, and Document OCR, and highlights its effectiveness in enterprise use cases, achieving 95-98% accuracy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rates, leading to significant adoption by leading insurance providers and resulting in productivity gains and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operating cost reductions.\"\\n2. \"Upstage Document AI: Digitize anything is comprised of the following </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">solutions:Layout Analyzer: Extracts layouts, tablescs, and figures from any documentKey Information Extractor: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Extracts key information from target documentsDocument OCR: Extracts all text from any document\"\\n\\nAnd here are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">some key-value pairs and knowledge graph entries relevant to this answer:\\n\\n- [{\\'key\\': \\'Document Title\\', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'value\\': \\'Upstage Document AI: Digitize anything\\'}, {\\'key\\': \\'Solution 1\\', \\'value\\': \\'Layout Analyzer\\'}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{\\'key\\': \\'Solution 1 Description\\', \\'value\\': \\'Extracts layouts, tables, and figures from any document\\'}, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{\\'key\\': \\'Solution 2\\', \\'value\\': \\'Key Information Extractor\\'}, {\\'key\\': \\'Solution 2 Description\\', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'value\\': \\'Extracts key information from target documents\\'}, {\\'key\\': \\'Solution 3\\', \\'value\\': \\'Document </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">OCR\\'}, {\\'key\\': \\'Solution 3 Description\\', \\'value\\': \\'Extracts all text from any document\\'}, {\\'key\\': </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'Benefits\\', \\'value\\': \\'Significant productivity gains and operating cost reductions\\'}, {\\'key\\': </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'customer_type\\', \\'value\\': \\'Leading insurance providers\\'}]\\n- {\\'knowledge_graph\\': {\\'type\\': \\'Document\\', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'attributes\\': {\\'title\\': \\'Upstage Document AI: Digitize anything\\'}, \\'relationships\\': {\\'solutions\\': </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">[{\\'name\\': \\'Layout Analyzer\\', \\'description\\': \\'Extracts layouts, tables, and figures from any document\\', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'type\\': \\'Solution\\'}, {\\'name\\': \\'Key Information Extractor\\', \\'description\\': \\'Extracts key information from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">target documents\\', \\'type\\': \\'Solution\\'}, {\\'name\\': \\'Document OOC\\', \\'description\\': \\'Extracts all text from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">any document\\', \\'type\\': \\'Solution\\'}], \\'performance\\': {\\'accuracyRate\\': \\'95-98%\\', \\'comparison\\': \\'Higher </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accuracy than previous manual human work\\', \\'customerType\\': \\'Leading insurance providers\\', \\'benefits\\': </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'Significant productivity gains and operating cost reductions\\'}]}}}'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1727891121.0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sung-pro-1001'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'docai'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'kv_pairs'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Document Title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Upstage Document AI: Digitize anything'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solution 1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Layout Analyzer'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solution 1 Description'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extracts layouts, tables, and figures from any document'</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solution 2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Key Information Extractor'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solution 2 Description'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extracts key information from target documents'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solution 3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Document OCR'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solution 3 Description'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extracts all text from any document'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Accuracy Rate'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'95%-98%'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Comparison'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Higher accuracy compared to previous manual human work'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Customer Type'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Leading insurance providers'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Benefits'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Significant productivity gains and operating cost reductions'</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_graph'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'Upstage Document AI: Digitize anything'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Upstage Document AI: Digitize anything'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'relationships'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'solutions'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                                <span style=\"font-weight: bold\">{</span>\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Layout Analyzer'</span>,\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extracts layouts, tables, and figures from any document'</span>,\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solution'</span>\n",
       "                                <span style=\"font-weight: bold\">}</span>,\n",
       "                                <span style=\"font-weight: bold\">{</span>\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Key Information Extractor'</span>,\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extracts key information from target documents'</span>,\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solution'</span>\n",
       "                                <span style=\"font-weight: bold\">}</span>,\n",
       "                                <span style=\"font-weight: bold\">{</span>\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Document OCR'</span>,\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extracts all text from any document'</span>,\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Solution'</span>\n",
       "                                <span style=\"font-weight: bold\">}</span>\n",
       "                            <span style=\"font-weight: bold\">]</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'performance'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'accuracyRate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'95%-98%'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'comparison'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Higher accuracy compared to previous manual human work'</span>\n",
       "                            <span style=\"font-weight: bold\">}</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'customerType'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Leading insurance providers'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'benefits'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Significant productivity gains and operating cost reductions'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'contextual_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Context: The main topic of this document is \"Upstage Document AI: Digitize </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anything,\" which describes three solutions: \"Layout Analyzer,\" \"Key Information Extractor,\" and \"Document OCR.\" </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This chunk specifically introduces these solutions and highlights their effectiveness in enterprise use cases, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">achieving 95%-98% accuracy rates, leading to significant adoption by leading insurance providers and resulting in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">productivity gains and operating cost reductions.'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Document AI: Digitize anythingUpstage Document AI is comprised of three </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">solutions: Layout Analyzer: Extracts layouts, tables, and figures from any document.\\n Key Information Extractor:</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Extracts key information from target documents.\\n Document OCR: Extracts all text from any document.In various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enterprise use cases, Upstage Document AI resulted in higher accuracy\\n(95%-98% accuracy rate) compared to previous</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">manual human work for document\\nprocessing. Due to its strong performance, the solution has been heavily adopted by</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various\\nleading insurance providers, yielding significant productivity gains and operating cost\\nreductions.Please</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">find customer testimonials, key customers, and customer success stories below.[Key customers]'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'e89888ff-d932-4e08-8baf-d1388c0fce4d'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Context: The main topic of this document is \"Upstage Document AI: Digitize anything,\" </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which describes three solutions: \"Layout Analyzer,\" \"Key Information Extractor,\" and \"Document OCR.\" This chunk </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specifically introduces these solutions and highlights their effectiveness in enterprise use cases, achieving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">95%-98% accuracy rates, leading to significant adoption by leading insurance providers and resulting in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">productivity gains and operating cost reductions. Document AI: Digitize anythingUpstage Document AI is comprised of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">three solutions: Layout Analyzer: Extracts layouts, tables, and figures from any document.\\n Key Information </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Extractor: Extracts key information from target documents.\\n Document OCR: Extracts all text from any document.In </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various enterprise use cases, Upstage Document AI resulted in higher accuracy\\n(95%-98% accuracy rate) compared to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">previous manual human work for document\\nprocessing. Due to its strong performance, the solution has been heavily </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">adopted by various\\nleading insurance providers, yielding significant productivity gains and operating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cost\\nreductions.Please find customer testimonials, key customers, and customer success stories below.[Key </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">customers]'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'filename'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'solar_paper'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'kv_pairs'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Document Topic'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Tuning'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Discussed Process'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Fine-tuning an instruction-tuned model to be more aligned with human or strong AI</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">preferences using sDPO'</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Improved Version of'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Direct Preference Optimization'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Key Concept 1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Use of mostly open-source datasets'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Key Concept 2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Synthesis of a math-focused alignment dataset'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Specific Role of Dataset'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Synth. Math-Instruct dataset'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Dataset Contribution'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Enhances the model's mathematical capabilities by utilizing rephrased </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answer pairs\"</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Relationship Between Chunk and Purpose'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Details the steps taken during the alignment tuning stage to improve the model's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance\"</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Tuning Stage'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Further fine-tuning of the instruction-tuned model to be more aligned with human </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or strong AI preferences'</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Tuning Method'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sDPO (Kim et al., 2024a)'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Similarity to Instruction Tuning Stage'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Use of mostly open-source datasets and math-focused alignment dataset'</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Data Synthesis Process'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Utilizing the 'Synth. Math-Instruct' dataset\"</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Benefit of Synth. Math-Instruct Data'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Enhancing the model's mathematical capabilities\"</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Data Synthesis Assumption'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Rephrased answer to the rephrased question is a better answer than the original'</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_graph'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Tuning'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Document Topic'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'relationships'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'Discussed Process'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Fine-tuning an instruction-tuned model to be more aligned with human or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">strong AI preferences using sDPO'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Process'</span>\n",
       "                            <span style=\"font-weight: bold\">}</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'entities'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'Improved Version of'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Direct Preference Optimization'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Method'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'relationships'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'Improved Version'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sDPO (Kim et al., 2024a)'</span>,\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Method'</span>,\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'authors'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Kim et al.'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'publicationYear'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"font-weight: bold\">}</span>\n",
       "                                    <span style=\"font-weight: bold\">}</span>\n",
       "                                <span style=\"font-weight: bold\">}</span>\n",
       "                            <span style=\"font-weight: bold\">}</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'entities_from_kv_pairs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'Key Concept 1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Use of mostly open-source datasets'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Concept'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'relationships'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'Similarity to Instruction Tuning Stage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Use of mostly open-source datasets and math-focused alignment </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset'</span>\n",
       "                                    <span style=\"font-weight: bold\">}</span>\n",
       "                                <span style=\"font-weight: bold\">}</span>\n",
       "                            <span style=\"font-weight: bold\">}</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'Key Concept 2'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Synthesis of a math-focused alignment dataset'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Concept'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'relationships'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Data Synthesis Process'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Utilizing the 'Synth. Math-Instruct' dataset\"</span>\n",
       "                                    <span style=\"font-weight: bold\">}</span>\n",
       "                                <span style=\"font-weight: bold\">}</span>\n",
       "                            <span style=\"font-weight: bold\">}</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'Specific Role of Dataset'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Synth. Math-Instract dataset'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Dataset'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'Contribution'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Enhances the model's mathematical capabilities by utilizing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rephrased question-answer pairs\"</span>\n",
       "                                <span style=\"font-weight: bold\">}</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'relationships'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'Relationship Between Chunk and Purpose'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Details the steps taken during the alignment tuning stage to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improve the model's performance\"</span>\n",
       "                                    <span style=\"font-weight: bold\">}</span>\n",
       "                                <span style=\"font-weight: bold\">}</span>\n",
       "                            <span style=\"font-weight: bold\">}</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Tuning Stage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Further fine-tuning of the instruction-tuned model to be more aligned with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human or strong AI preferences'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Stage'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Method'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sDPO (Kim et al., 2024a)'</span><span style=\"font-weight: bold\">}</span>\n",
       "                            <span style=\"font-weight: bold\">}</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Tuning Method'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sDPO (Kim et al., 2024a)'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Method'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'authors'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Kim et al.'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'publicationYear'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"font-weight: bold\">}</span>\n",
       "                            <span style=\"font-weight: bold\">}</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Data Synthesis Process'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Utilizing the 'Synth. Math-Instrect' dataset\"</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Process'</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Benefit'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Enhancing the model's mathematical capabilities\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "                                <span style=\"color: #008000; text-decoration-color: #008000\">'relationships'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                    <span style=\"color: #008000; text-decoration-color: #008000\">'Alignment Data Synthesis Assumption'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                                        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Rephrased answer to the rephrased question is a better answer than</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the original'</span>\n",
       "                                    <span style=\"font-weight: bold\">}</span>\n",
       "                                <span style=\"font-weight: bold\">}</span>\n",
       "                            <span style=\"font-weight: bold\">}</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'contextual_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Context: The main topic of the document is \"alignment tuning\". This chunk </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discusses the process of fine-tuning an instruction-tuned model to be more aligned with human or strong AI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">preferences using sDPO, an improved version of direct preference optimization. Key concepts include the use of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mostly open-source datasets, the synthesis of a math-focused alignment dataset, and the specific role of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\'Synth. Math-Instruct\\' dataset, which enhances the model\\'s mathematical capabilities by utilizing rephrased </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answer pairs. The relationship between the chunk and the overall purpose is that it details the steps </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">taken during the alignment tuning stage to improve the model\\'s performance.'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'original_chunk'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'swers of the seed math data. We use the resulting\\nrephrased question-answer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pairs as a QA datasetand call it Synth. Math-Instruct.Alignment tuning. In the alignment tuning stage,\\nthe </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">instruction-tuned model is further fine-tuned\\nto be more aligned with human or strong AI\\n(e.g., GPT4 (OpenAI, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023)) preferences using\\nsDPO (Kim et al., 2024a), an improved version\\nof direct preference optimization (DPO) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(Rafailov\\net al., 2023). Similar to the instruction tuning stage,\\nwe use mostly open-source datasets but also </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">syn-\\nthesize a math-focused alignment dataset utilizing\\nthe Synth. Math-Instruct dataset mentioned in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\ninstruction tuning stage.The alignment data synthesis process is as\\nfollows. We take advantage of the fact </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that\\nthe rephrased question-answer pairs in Synth.\\nMath-Instruct data are beneficial in enhancing the\\nmodels </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mathematical capabilities (see Sec. 4.3.1).\\nThus, we speculate that the rephrased answer to the\\nrephrased </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question is a better answer than the orig-'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'is_contextual_chunk'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'59a52fc9-dc57-46db-b7c0-1ba66495af8d'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_collection_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Context: The main topic of the document is \"alignment tuning\". This chunk discusses the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">process of fine-tuning an instruction-tuned model to be more aligned with human or strong AI preferences using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sDPO, an improved version of direct preference optimization. Key concepts include the use of mostly open-source </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">datasets, the synthesis of a math-focused alignment dataset, and the specific role of the \\'Synth. Math-Instruct\\' </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset, which enhances the model\\'s mathematical capabilities by utilizing rephrased question-answer pairs. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relationship between the chunk and the overall purpose is that it details the steps taken during the alignment </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tuning stage to improve the model\\'s performance. swers of the seed math data. We use the resulting\\nrephrased </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answer pairs as a QA datasetand call it Synth. Math-Instruct.Alignment tuning. In the alignment tuning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">stage,\\nthe instruction-tuned model is further fine-tuned\\nto be more aligned with human or strong AI\\n(e.g., GPT4 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(OpenAI, 2023)) preferences using\\nsDPO (Kim et al., 2024a), an improved version\\nof direct preference optimization</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(DPO) (Rafailov\\net al., 2023). Similar to the instruction tuning stage,\\nwe use mostly open-source datasets but </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">also syn-\\nthesize a math-focused alignment dataset utilizing\\nthe Synth. Math-Instruct dataset mentioned in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the\\ninstruction tuning stage.The alignment data synthesis process is as\\nfollows. We take advantage of the fact </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that\\nthe rephrased question-answer pairs in Synth.\\nMath-Instruct data are beneficial in enhancing the\\nmodels </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mathematical capabilities (see Sec. 4.3.1).\\nThus, we speculate that the rephrased answer to the\\nrephrased </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question is a better answer than the orig-'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'_'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'The following indexed files are being used for this query: solar_paper.pdf, \u001b[0m\n",
       "\u001b[32msolar_sample.pdf, docai.pdf, kim-tse-2008.pdf\\n\\nBased on the provided context, key-value pairs, and knowledge \u001b[0m\n",
       "\u001b[32mgraph, I can explain \"Document AI\" as follows:\\n\\nThe main topic of this document is \"Upstage Document AI: Digitize\u001b[0m\n",
       "\u001b[32manything\". Document AI is described as providing three solutions: \"Layout Analyzer\", \"Key Information Extractor\", \u001b[0m\n",
       "\u001b[32mand \"Document OCR\". Layout Analyzer extracts layouts, tables, and figures from any document. Key Information \u001b[0m\n",
       "\u001b[32mExtractor extracts key information from target documents. Document OCR extracts all text from any document. In \u001b[0m\n",
       "\u001b[32menterprise use cases, Document AI achieved an accuracy rate of 95-98%, leading to significant productivity gains \u001b[0m\n",
       "\u001b[32mand operating cost reductions for leading insurance providers.\\n\\nHere are some direct quotes from the \u001b[0m\n",
       "\u001b[32mcontext:\\n\\n1. \"This chunk introduces the main document and its three solutions, Layout Analyzer, Key Information \u001b[0m\n",
       "\u001b[32mExtractor, and Document OCR, and highlights its effectiveness in enterprise use cases, achieving 95-98% accuracy \u001b[0m\n",
       "\u001b[32mrates, leading to significant adoption by leading insurance providers and resulting in productivity gains and \u001b[0m\n",
       "\u001b[32moperating cost reductions.\"\\n2. \"Upstage Document AI: Digitize anything is comprised of the following \u001b[0m\n",
       "\u001b[32msolutions:Layout Analyzer: Extracts layouts, tablescs, and figures from any documentKey Information Extractor: \u001b[0m\n",
       "\u001b[32mExtracts key information from target documentsDocument OCR: Extracts all text from any document\"\\n\\nAnd here are \u001b[0m\n",
       "\u001b[32msome key-value pairs and knowledge graph entries relevant to this answer:\\n\\n- \u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'key\\': \\'Document Title\\', \u001b[0m\n",
       "\u001b[32m\\'value\\': \\'Upstage Document AI: Digitize anything\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'key\\': \\'Solution 1\\', \\'value\\': \\'Layout Analyzer\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m\\'key\\': \\'Solution 1 Description\\', \\'value\\': \\'Extracts layouts, tables, and figures from any document\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m\\'key\\': \\'Solution 2\\', \\'value\\': \\'Key Information Extractor\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'key\\': \\'Solution 2 Description\\', \u001b[0m\n",
       "\u001b[32m\\'value\\': \\'Extracts key information from target documents\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'key\\': \\'Solution 3\\', \\'value\\': \\'Document \u001b[0m\n",
       "\u001b[32mOCR\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'key\\': \\'Solution 3 Description\\', \\'value\\': \\'Extracts all text from any document\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'key\\': \u001b[0m\n",
       "\u001b[32m\\'Benefits\\', \\'value\\': \\'Significant productivity gains and operating cost reductions\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'key\\': \u001b[0m\n",
       "\u001b[32m\\'customer_type\\', \\'value\\': \\'Leading insurance providers\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n- \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'knowledge_graph\\': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'type\\': \\'Document\\', \u001b[0m\n",
       "\u001b[32m\\'attributes\\': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'title\\': \\'Upstage Document AI: Digitize anything\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \\'relationships\\': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'solutions\\': \u001b[0m\n",
       "\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'name\\': \\'Layout Analyzer\\', \\'description\\': \\'Extracts layouts, tables, and figures from any document\\', \u001b[0m\n",
       "\u001b[32m\\'type\\': \\'Solution\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'name\\': \\'Key Information Extractor\\', \\'description\\': \\'Extracts key information from\u001b[0m\n",
       "\u001b[32mtarget documents\\', \\'type\\': \\'Solution\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'name\\': \\'Document OOC\\', \\'description\\': \\'Extracts all text from\u001b[0m\n",
       "\u001b[32many document\\', \\'type\\': \\'Solution\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \\'performance\\': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'accuracyRate\\': \\'95-98%\\', \\'comparison\\': \\'Higher \u001b[0m\n",
       "\u001b[32maccuracy than previous manual human work\\', \\'customerType\\': \\'Leading insurance providers\\', \\'benefits\\': \u001b[0m\n",
       "\u001b[32m\\'Significant productivity gains and operating cost reductions\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1727891121\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'sung-pro-1001'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'docai'\u001b[0m,\n",
       "                \u001b[32m'kv_pairs'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Document Title'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Upstage Document AI: Digitize anything'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Solution 1'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Layout Analyzer'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'key'\u001b[0m: \u001b[32m'Solution 1 Description'\u001b[0m,\n",
       "                        \u001b[32m'value'\u001b[0m: \u001b[32m'Extracts layouts, tables, and figures from any document'\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Solution 2'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Key Information Extractor'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Solution 2 Description'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Extracts key information from target documents'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Solution 3'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Document OCR'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Solution 3 Description'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Extracts all text from any document'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Accuracy Rate'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'95%-98%'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Comparison'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Higher accuracy compared to previous manual human work'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Customer Type'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Leading insurance providers'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Benefits'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Significant productivity gains and operating cost reductions'\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[32m'knowledge_graph'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'Upstage Document AI: Digitize anything'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'type'\u001b[0m: \u001b[32m'Document'\u001b[0m,\n",
       "                        \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Upstage Document AI: Digitize anything'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'relationships'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'solutions'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                                \u001b[1m{\u001b[0m\n",
       "                                    \u001b[32m'name'\u001b[0m: \u001b[32m'Layout Analyzer'\u001b[0m,\n",
       "                                    \u001b[32m'description'\u001b[0m: \u001b[32m'Extracts layouts, tables, and figures from any document'\u001b[0m,\n",
       "                                    \u001b[32m'type'\u001b[0m: \u001b[32m'Solution'\u001b[0m\n",
       "                                \u001b[1m}\u001b[0m,\n",
       "                                \u001b[1m{\u001b[0m\n",
       "                                    \u001b[32m'name'\u001b[0m: \u001b[32m'Key Information Extractor'\u001b[0m,\n",
       "                                    \u001b[32m'description'\u001b[0m: \u001b[32m'Extracts key information from target documents'\u001b[0m,\n",
       "                                    \u001b[32m'type'\u001b[0m: \u001b[32m'Solution'\u001b[0m\n",
       "                                \u001b[1m}\u001b[0m,\n",
       "                                \u001b[1m{\u001b[0m\n",
       "                                    \u001b[32m'name'\u001b[0m: \u001b[32m'Document OCR'\u001b[0m,\n",
       "                                    \u001b[32m'description'\u001b[0m: \u001b[32m'Extracts all text from any document'\u001b[0m,\n",
       "                                    \u001b[32m'type'\u001b[0m: \u001b[32m'Solution'\u001b[0m\n",
       "                                \u001b[1m}\u001b[0m\n",
       "                            \u001b[1m]\u001b[0m,\n",
       "                            \u001b[32m'performance'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'accuracyRate'\u001b[0m: \u001b[32m'95%-98%'\u001b[0m,\n",
       "                                \u001b[32m'comparison'\u001b[0m: \u001b[32m'Higher accuracy compared to previous manual human work'\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m,\n",
       "                            \u001b[32m'customerType'\u001b[0m: \u001b[32m'Leading insurance providers'\u001b[0m,\n",
       "                            \u001b[32m'benefits'\u001b[0m: \u001b[32m'Significant productivity gains and operating cost reductions'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'contextual_chunk'\u001b[0m: \u001b[32m'Context: The main topic of this document is \"Upstage Document AI: Digitize \u001b[0m\n",
       "\u001b[32manything,\" which describes three solutions: \"Layout Analyzer,\" \"Key Information Extractor,\" and \"Document OCR.\" \u001b[0m\n",
       "\u001b[32mThis chunk specifically introduces these solutions and highlights their effectiveness in enterprise use cases, \u001b[0m\n",
       "\u001b[32machieving 95%-98% accuracy rates, leading to significant adoption by leading insurance providers and resulting in \u001b[0m\n",
       "\u001b[32mproductivity gains and operating cost reductions.'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'Document AI: Digitize anythingUpstage Document AI is comprised of three \u001b[0m\n",
       "\u001b[32msolutions: Layout Analyzer: Extracts layouts, tables, and figures from any document.\\n Key Information Extractor:\u001b[0m\n",
       "\u001b[32mExtracts key information from target documents.\\n Document OCR: Extracts all text from any document.In various \u001b[0m\n",
       "\u001b[32menterprise use cases, Upstage Document AI resulted in higher accuracy\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m95%-98% accuracy rate\u001b[0m\u001b[32m)\u001b[0m\u001b[32m compared to previous\u001b[0m\n",
       "\u001b[32mmanual human work for document\\nprocessing. Due to its strong performance, the solution has been heavily adopted by\u001b[0m\n",
       "\u001b[32mvarious\\nleading insurance providers, yielding significant productivity gains and operating cost\\nreductions.Please\u001b[0m\n",
       "\u001b[32mfind customer testimonials, key customers, and customer success stories below.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mKey customers\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'e89888ff-d932-4e08-8baf-d1388c0fce4d'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Context: The main topic of this document is \"Upstage Document AI: Digitize anything,\" \u001b[0m\n",
       "\u001b[32mwhich describes three solutions: \"Layout Analyzer,\" \"Key Information Extractor,\" and \"Document OCR.\" This chunk \u001b[0m\n",
       "\u001b[32mspecifically introduces these solutions and highlights their effectiveness in enterprise use cases, achieving \u001b[0m\n",
       "\u001b[32m95%-98% accuracy rates, leading to significant adoption by leading insurance providers and resulting in \u001b[0m\n",
       "\u001b[32mproductivity gains and operating cost reductions. Document AI: Digitize anythingUpstage Document AI is comprised of\u001b[0m\n",
       "\u001b[32mthree solutions: Layout Analyzer: Extracts layouts, tables, and figures from any document.\\n Key Information \u001b[0m\n",
       "\u001b[32mExtractor: Extracts key information from target documents.\\n Document OCR: Extracts all text from any document.In \u001b[0m\n",
       "\u001b[32mvarious enterprise use cases, Upstage Document AI resulted in higher accuracy\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m95%-98% accuracy rate\u001b[0m\u001b[32m)\u001b[0m\u001b[32m compared to \u001b[0m\n",
       "\u001b[32mprevious manual human work for document\\nprocessing. Due to its strong performance, the solution has been heavily \u001b[0m\n",
       "\u001b[32madopted by various\\nleading insurance providers, yielding significant productivity gains and operating \u001b[0m\n",
       "\u001b[32mcost\\nreductions.Please find customer testimonials, key customers, and customer success stories below.\u001b[0m\u001b[32m[\u001b[0m\u001b[32mKey \u001b[0m\n",
       "\u001b[32mcustomers\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mid\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
       "                \u001b[32m'filename'\u001b[0m: \u001b[32m'solar_paper'\u001b[0m,\n",
       "                \u001b[32m'kv_pairs'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Document Topic'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Alignment Tuning'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'key'\u001b[0m: \u001b[32m'Discussed Process'\u001b[0m,\n",
       "                        \u001b[32m'value'\u001b[0m: \u001b[32m'Fine-tuning an instruction-tuned model to be more aligned with human or strong AI\u001b[0m\n",
       "\u001b[32mpreferences using sDPO'\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Improved Version of'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Direct Preference Optimization'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Key Concept 1'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Use of mostly open-source datasets'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Key Concept 2'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Synthesis of a math-focused alignment dataset'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Specific Role of Dataset'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'Synth. Math-Instruct dataset'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'key'\u001b[0m: \u001b[32m'Dataset Contribution'\u001b[0m,\n",
       "                        \u001b[32m'value'\u001b[0m: \u001b[32m\"Enhances the model's mathematical capabilities by utilizing rephrased \u001b[0m\n",
       "\u001b[32mquestion-answer pairs\"\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'key'\u001b[0m: \u001b[32m'Relationship Between Chunk and Purpose'\u001b[0m,\n",
       "                        \u001b[32m'value'\u001b[0m: \u001b[32m\"Details the steps taken during the alignment tuning stage to improve the model's \u001b[0m\n",
       "\u001b[32mperformance\"\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'key'\u001b[0m: \u001b[32m'Alignment Tuning Stage'\u001b[0m,\n",
       "                        \u001b[32m'value'\u001b[0m: \u001b[32m'Further fine-tuning of the instruction-tuned model to be more aligned with human \u001b[0m\n",
       "\u001b[32mor strong AI preferences'\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\u001b[32m'key'\u001b[0m: \u001b[32m'Alignment Tuning Method'\u001b[0m, \u001b[32m'value'\u001b[0m: \u001b[32m'sDPO \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKim et al., 2024a\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'key'\u001b[0m: \u001b[32m'Similarity to Instruction Tuning Stage'\u001b[0m,\n",
       "                        \u001b[32m'value'\u001b[0m: \u001b[32m'Use of mostly open-source datasets and math-focused alignment dataset'\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'key'\u001b[0m: \u001b[32m'Alignment Data Synthesis Process'\u001b[0m,\n",
       "                        \u001b[32m'value'\u001b[0m: \u001b[32m\"Utilizing the 'Synth. Math-Instruct' dataset\"\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'key'\u001b[0m: \u001b[32m'Benefit of Synth. Math-Instruct Data'\u001b[0m,\n",
       "                        \u001b[32m'value'\u001b[0m: \u001b[32m\"Enhancing the model's mathematical capabilities\"\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'key'\u001b[0m: \u001b[32m'Alignment Data Synthesis Assumption'\u001b[0m,\n",
       "                        \u001b[32m'value'\u001b[0m: \u001b[32m'Rephrased answer to the rephrased question is a better answer than the original'\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[32m'knowledge_graph'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'Alignment Tuning'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'type'\u001b[0m: \u001b[32m'Document Topic'\u001b[0m,\n",
       "                        \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'relationships'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'Discussed Process'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'name'\u001b[0m: \u001b[32m'Fine-tuning an instruction-tuned model to be more aligned with human or \u001b[0m\n",
       "\u001b[32mstrong AI preferences using sDPO'\u001b[0m,\n",
       "                                \u001b[32m'type'\u001b[0m: \u001b[32m'Process'\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'entities'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'Improved Version of'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'name'\u001b[0m: \u001b[32m'Direct Preference Optimization'\u001b[0m,\n",
       "                                \u001b[32m'type'\u001b[0m: \u001b[32m'Method'\u001b[0m,\n",
       "                                \u001b[32m'relationships'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                    \u001b[32m'Improved Version'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                        \u001b[32m'name'\u001b[0m: \u001b[32m'sDPO \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKim et al., 2024a\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                                        \u001b[32m'type'\u001b[0m: \u001b[32m'Method'\u001b[0m,\n",
       "                                        \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'authors'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Kim et al.'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'publicationYear'\u001b[0m: \u001b[1;36m2024\u001b[0m\u001b[1m}\u001b[0m\n",
       "                                    \u001b[1m}\u001b[0m\n",
       "                                \u001b[1m}\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'entities_from_kv_pairs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'Key Concept 1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'name'\u001b[0m: \u001b[32m'Use of mostly open-source datasets'\u001b[0m,\n",
       "                                \u001b[32m'type'\u001b[0m: \u001b[32m'Concept'\u001b[0m,\n",
       "                                \u001b[32m'relationships'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                    \u001b[32m'Similarity to Instruction Tuning Stage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                        \u001b[32m'name'\u001b[0m: \u001b[32m'Use of mostly open-source datasets and math-focused alignment \u001b[0m\n",
       "\u001b[32mdataset'\u001b[0m\n",
       "                                    \u001b[1m}\u001b[0m\n",
       "                                \u001b[1m}\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m,\n",
       "                            \u001b[32m'Key Concept 2'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'name'\u001b[0m: \u001b[32m'Synthesis of a math-focused alignment dataset'\u001b[0m,\n",
       "                                \u001b[32m'type'\u001b[0m: \u001b[32m'Concept'\u001b[0m,\n",
       "                                \u001b[32m'relationships'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                    \u001b[32m'Alignment Data Synthesis Process'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                        \u001b[32m'name'\u001b[0m: \u001b[32m\"Utilizing the 'Synth. Math-Instruct' dataset\"\u001b[0m\n",
       "                                    \u001b[1m}\u001b[0m\n",
       "                                \u001b[1m}\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m,\n",
       "                            \u001b[32m'Specific Role of Dataset'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'name'\u001b[0m: \u001b[32m'Synth. Math-Instract dataset'\u001b[0m,\n",
       "                                \u001b[32m'type'\u001b[0m: \u001b[32m'Dataset'\u001b[0m,\n",
       "                                \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                    \u001b[32m'Contribution'\u001b[0m: \u001b[32m\"Enhances the model's mathematical capabilities by utilizing \u001b[0m\n",
       "\u001b[32mrephrased question-answer pairs\"\u001b[0m\n",
       "                                \u001b[1m}\u001b[0m,\n",
       "                                \u001b[32m'relationships'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                    \u001b[32m'Relationship Between Chunk and Purpose'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                        \u001b[32m'name'\u001b[0m: \u001b[32m\"Details the steps taken during the alignment tuning stage to \u001b[0m\n",
       "\u001b[32mimprove the model's performance\"\u001b[0m\n",
       "                                    \u001b[1m}\u001b[0m\n",
       "                                \u001b[1m}\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m,\n",
       "                            \u001b[32m'Alignment Tuning Stage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'name'\u001b[0m: \u001b[32m'Further fine-tuning of the instruction-tuned model to be more aligned with\u001b[0m\n",
       "\u001b[32mhuman or strong AI preferences'\u001b[0m,\n",
       "                                \u001b[32m'type'\u001b[0m: \u001b[32m'Stage'\u001b[0m,\n",
       "                                \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'Method'\u001b[0m: \u001b[32m'sDPO \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKim et al., 2024a\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m,\n",
       "                            \u001b[32m'Alignment Tuning Method'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'name'\u001b[0m: \u001b[32m'sDPO \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKim et al., 2024a\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                                \u001b[32m'type'\u001b[0m: \u001b[32m'Method'\u001b[0m,\n",
       "                                \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'authors'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Kim et al.'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'publicationYear'\u001b[0m: \u001b[1;36m2024\u001b[0m\u001b[1m}\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m,\n",
       "                            \u001b[32m'Alignment Data Synthesis Process'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                \u001b[32m'name'\u001b[0m: \u001b[32m\"Utilizing the 'Synth. Math-Instrect' dataset\"\u001b[0m,\n",
       "                                \u001b[32m'type'\u001b[0m: \u001b[32m'Process'\u001b[0m,\n",
       "                                \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'Benefit'\u001b[0m: \u001b[32m\"Enhancing the model's mathematical capabilities\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                                \u001b[32m'relationships'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                    \u001b[32m'Alignment Data Synthesis Assumption'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                                        \u001b[32m'name'\u001b[0m: \u001b[32m'Rephrased answer to the rephrased question is a better answer than\u001b[0m\n",
       "\u001b[32mthe original'\u001b[0m\n",
       "                                    \u001b[1m}\u001b[0m\n",
       "                                \u001b[1m}\u001b[0m\n",
       "                            \u001b[1m}\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'contextual_chunk'\u001b[0m: \u001b[32m'Context: The main topic of the document is \"alignment tuning\". This chunk \u001b[0m\n",
       "\u001b[32mdiscusses the process of fine-tuning an instruction-tuned model to be more aligned with human or strong AI \u001b[0m\n",
       "\u001b[32mpreferences using sDPO, an improved version of direct preference optimization. Key concepts include the use of \u001b[0m\n",
       "\u001b[32mmostly open-source datasets, the synthesis of a math-focused alignment dataset, and the specific role of the \u001b[0m\n",
       "\u001b[32m\\'Synth. Math-Instruct\\' dataset, which enhances the model\\'s mathematical capabilities by utilizing rephrased \u001b[0m\n",
       "\u001b[32mquestion-answer pairs. The relationship between the chunk and the overall purpose is that it details the steps \u001b[0m\n",
       "\u001b[32mtaken during the alignment tuning stage to improve the model\\'s performance.'\u001b[0m,\n",
       "                \u001b[32m'original_chunk'\u001b[0m: \u001b[32m'swers of the seed math data. We use the resulting\\nrephrased question-answer \u001b[0m\n",
       "\u001b[32mpairs as a QA datasetand call it Synth. Math-Instruct.Alignment tuning. In the alignment tuning stage,\\nthe \u001b[0m\n",
       "\u001b[32minstruction-tuned model is further fine-tuned\\nto be more aligned with human or strong AI\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., GPT4 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mOpenAI, \u001b[0m\n",
       "\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m preferences using\\nsDPO \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKim et al., 2024a\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, an improved version\\nof direct preference optimization \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDPO\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mRafailov\\net al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Similar to the instruction tuning stage,\\nwe use mostly open-source datasets but also \u001b[0m\n",
       "\u001b[32msyn-\\nthesize a math-focused alignment dataset utilizing\\nthe Synth. Math-Instruct dataset mentioned in \u001b[0m\n",
       "\u001b[32mthe\\ninstruction tuning stage.The alignment data synthesis process is as\\nfollows. We take advantage of the fact \u001b[0m\n",
       "\u001b[32mthat\\nthe rephrased question-answer pairs in Synth.\\nMath-Instruct data are beneficial in enhancing the\\nmodels \u001b[0m\n",
       "\u001b[32mmathematical capabilities \u001b[0m\u001b[32m(\u001b[0m\u001b[32msee Sec. 4.3.1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nThus, we speculate that the rephrased answer to the\\nrephrased \u001b[0m\n",
       "\u001b[32mquestion is a better answer than the orig-'\u001b[0m,\n",
       "                \u001b[32m'is_contextual_chunk'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "                \u001b[32m'_id'\u001b[0m: \u001b[32m'59a52fc9-dc57-46db-b7c0-1ba66495af8d'\u001b[0m,\n",
       "                \u001b[32m'_collection_name'\u001b[0m: \n",
       "\u001b[32m'97081dab6dca79d677fe6cc3b1c29a4d8c722bb418b504fad71eb75831f649fb_sung-pro-1001'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mpage_content\u001b[0m=\u001b[32m'Context: The main topic of the document is \"alignment tuning\". This chunk discusses the \u001b[0m\n",
       "\u001b[32mprocess of fine-tuning an instruction-tuned model to be more aligned with human or strong AI preferences using \u001b[0m\n",
       "\u001b[32msDPO, an improved version of direct preference optimization. Key concepts include the use of mostly open-source \u001b[0m\n",
       "\u001b[32mdatasets, the synthesis of a math-focused alignment dataset, and the specific role of the \\'Synth. Math-Instruct\\' \u001b[0m\n",
       "\u001b[32mdataset, which enhances the model\\'s mathematical capabilities by utilizing rephrased question-answer pairs. The \u001b[0m\n",
       "\u001b[32mrelationship between the chunk and the overall purpose is that it details the steps taken during the alignment \u001b[0m\n",
       "\u001b[32mtuning stage to improve the model\\'s performance. swers of the seed math data. We use the resulting\\nrephrased \u001b[0m\n",
       "\u001b[32mquestion-answer pairs as a QA datasetand call it Synth. Math-Instruct.Alignment tuning. In the alignment tuning \u001b[0m\n",
       "\u001b[32mstage,\\nthe instruction-tuned model is further fine-tuned\\nto be more aligned with human or strong AI\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., GPT4 \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mOpenAI, 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m preferences using\\nsDPO \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKim et al., 2024a\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, an improved version\\nof direct preference optimization\u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mDPO\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRafailov\\net al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Similar to the instruction tuning stage,\\nwe use mostly open-source datasets but \u001b[0m\n",
       "\u001b[32malso syn-\\nthesize a math-focused alignment dataset utilizing\\nthe Synth. Math-Instruct dataset mentioned in \u001b[0m\n",
       "\u001b[32mthe\\ninstruction tuning stage.The alignment data synthesis process is as\\nfollows. We take advantage of the fact \u001b[0m\n",
       "\u001b[32mthat\\nthe rephrased question-answer pairs in Synth.\\nMath-Instruct data are beneficial in enhancing the\\nmodels \u001b[0m\n",
       "\u001b[32mmathematical capabilities \u001b[0m\u001b[32m(\u001b[0m\u001b[32msee Sec. 4.3.1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nThus, we speculate that the rephrased answer to the\\nrephrased \u001b[0m\n",
       "\u001b[32mquestion is a better answer than the orig-'\u001b[0m,\n",
       "            \u001b[33mtype\u001b[0m=\u001b[32m'Document'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with custom base URL and API key\n",
    "client = OpenAI(\n",
    "    base_url=rag_base_url,  # Using the custom RAG API base URL\n",
    "    api_key=os.environ[\n",
    "        \"UPSTAGE_API_KEY\"\n",
    "    ],  # Using the API key from environment variables\n",
    ")\n",
    "\n",
    "# Send a request to the RAG model\n",
    "response = client.chat.completions.create(\n",
    "    model=rag_model_name,  # Using the previously defined RAG model name\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Explain Document AI\"}],  # The user's query\n",
    "    stream=False,  # Disable streaming for synchronous response\n",
    "    extra_body={\n",
    "        \"hybrid_search\": True,  # Enable hybrid search for better results\n",
    "        \"contextual_query\": True,  # Enable contextual querying\n",
    "        \"knowledge_graph\": True,\n",
    "        \"kv_pairs\": True,\n",
    "        \"verbose\": True,  # Request verbose output for debugging\n",
    "    },\n",
    ")\n",
    "\n",
    "# Print the model's response\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5776bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The document AI, as described in the context provided, is a product called \"Upstage Document AI: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Digitize anything.\" It consists of three solutions: \"Layout Analyzer,\" \"Key Information Extractor,\" and \"Document </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">OCR.\" It can be used to extract layouts, tables, and figures from any document, extract key information from target</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">documents, and extract all text from any document, respectively.\\n\\nIn enterprise use cases, Upstage Document AI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">has achieved higher accuracy compared to previous manual human work, leading to significant adoption by leading </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">insurance providers and resulting in productivity gains and operating cost reductions.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1c9fba8131d5829120ff'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-c6e2b043-0dee-497b-b44d-0a5c836fbbc6-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'The document AI, as described in the context provided, is a product called \"Upstage Document AI: \u001b[0m\n",
       "\u001b[32mDigitize anything.\" It consists of three solutions: \"Layout Analyzer,\" \"Key Information Extractor,\" and \"Document \u001b[0m\n",
       "\u001b[32mOCR.\" It can be used to extract layouts, tables, and figures from any document, extract key information from target\u001b[0m\n",
       "\u001b[32mdocuments, and extract all text from any document, respectively.\\n\\nIn enterprise use cases, Upstage Document AI \u001b[0m\n",
       "\u001b[32mhas achieved higher accuracy compared to previous manual human work, leading to significant adoption by leading \u001b[0m\n",
       "\u001b[32minsurance providers and resulting in productivity gains and operating cost reductions.'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'1c9fba8131d5829120ff'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-c6e2b043-0dee-497b-b44d-0a5c836fbbc6-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the chat model using the public model name (accessible to everyone)\n",
    "chat = Chat(model=public_model_name, base_url=rag_base_url)\n",
    "\n",
    "# Define the question about Document AI and its usage\n",
    "question = \"What's Document AI? How can it be used?\"\n",
    "\n",
    "# Invoke the chat model with the question\n",
    "response = chat.invoke(question)\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f7197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What's the benefits of Document AI?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The benefit of Upstage Document AI, as stated in the provided information, is \"Significant </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">productivity gains and operating cost reductions.\"'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1c9fba8131d5829120ff'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-e080b83c-702f-4101-9ca3-6d2f9ed712ea-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'The benefit of Upstage Document AI, as stated in the provided information, is \"Significant \u001b[0m\n",
       "\u001b[32mproductivity gains and operating cost reductions.\"'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'1c9fba8131d5829120ff'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-e080b83c-702f-4101-9ca3-6d2f9ed712ea-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How about its features?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The question asks for information about the features of Document AI, but the provided context, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">key-value pairs, knowledge graph, and all other instructions are about Upstage Document AI and its specific tools: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Layout Analyzer, Key Information Extractor, and Document OCR. These tools have the following features:\\n\\n1. Layout</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Analyzer: \"Extracts layouts, tables, and figures from any document\"\\n2. Key Information Extractor: \"Extracts key </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information from target documents\"\\n3. Document OCR: \"Extracts all text from any document\"\\n\\nThe provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information does not specify any general features of Document AI as a whole, only the features of its specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tools.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1c9fba8131d5829120ff'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-93da3c16-a456-47aa-8675-37b2f9df56d4-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'The question asks for information about the features of Document AI, but the provided context, \u001b[0m\n",
       "\u001b[32mkey-value pairs, knowledge graph, and all other instructions are about Upstage Document AI and its specific tools: \u001b[0m\n",
       "\u001b[32mLayout Analyzer, Key Information Extractor, and Document OCR. These tools have the following features:\\n\\n1. Layout\u001b[0m\n",
       "\u001b[32mAnalyzer: \"Extracts layouts, tables, and figures from any document\"\\n2. Key Information Extractor: \"Extracts key \u001b[0m\n",
       "\u001b[32minformation from target documents\"\\n3. Document OCR: \"Extracts all text from any document\"\\n\\nThe provided \u001b[0m\n",
       "\u001b[32minformation does not specify any general features of Document AI as a whole, only the features of its specific \u001b[0m\n",
       "\u001b[32mtools.'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'1c9fba8131d5829120ff'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-93da3c16-a456-47aa-8675-37b2f9df56d4-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Why we need it?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Based on the provided context, key-value pairs, and knowledge graph, the reason for needing Document </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AI is not explicitly stated. However, I can infer some potential reasons based on the information given. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context mentions that Upstage Document AI: Digitize anything has been adopted by leading insurance providers due to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">its higher accuracy rates compared to previous manual human work, leading to significant productivity gains and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operating cost reductions. Therefore, Document AI may be needed to improve the accuracy of document processing, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">increase productivity, and reduce operating costs.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1c9fba8131d5829120ff'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-eb426770-3337-4785-ae6d-9dbcf35a1327-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'Based on the provided context, key-value pairs, and knowledge graph, the reason for needing Document \u001b[0m\n",
       "\u001b[32mAI is not explicitly stated. However, I can infer some potential reasons based on the information given. The \u001b[0m\n",
       "\u001b[32mcontext mentions that Upstage Document AI: Digitize anything has been adopted by leading insurance providers due to\u001b[0m\n",
       "\u001b[32mits higher accuracy rates compared to previous manual human work, leading to significant productivity gains and \u001b[0m\n",
       "\u001b[32moperating cost reductions. Therefore, Document AI may be needed to improve the accuracy of document processing, \u001b[0m\n",
       "\u001b[32mincrease productivity, and reduce operating costs.'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'1c9fba8131d5829120ff'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-eb426770-3337-4785-ae6d-9dbcf35a1327-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat History:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"What's the benefits of Document AI?\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m\"What\u001b[0m\u001b[32m's the benefits of Document AI?\"\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The benefit of Upstage Document AI, as stated in the provided information, is \"Significant </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">productivity gains and operating cost reductions.\"'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1c9fba8131d5829120ff'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-e080b83c-702f-4101-9ca3-6d2f9ed712ea-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'The benefit of Upstage Document AI, as stated in the provided information, is \"Significant \u001b[0m\n",
       "\u001b[32mproductivity gains and operating cost reductions.\"'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'1c9fba8131d5829120ff'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-e080b83c-702f-4101-9ca3-6d2f9ed712ea-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'How about its features?'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'How about its features?'\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The question asks for information about the features of Document AI, but the provided context, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">key-value pairs, knowledge graph, and all other instructions are about Upstage Document AI and its specific tools: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Layout Analyzer, Key Information Extractor, and Document OCR. These tools have the following features:\\n\\n1. Layout</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Analyzer: \"Extracts layouts, tables, and figures from any document\"\\n2. Key Information Extractor: \"Extracts key </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information from target documents\"\\n3. Document OCR: \"Extracts all text from any document\"\\n\\nThe provided </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information does not specify any general features of Document AI as a whole, only the features of its specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tools.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1c9fba8131d5829120ff'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-93da3c16-a456-47aa-8675-37b2f9df56d4-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'The question asks for information about the features of Document AI, but the provided context, \u001b[0m\n",
       "\u001b[32mkey-value pairs, knowledge graph, and all other instructions are about Upstage Document AI and its specific tools: \u001b[0m\n",
       "\u001b[32mLayout Analyzer, Key Information Extractor, and Document OCR. These tools have the following features:\\n\\n1. Layout\u001b[0m\n",
       "\u001b[32mAnalyzer: \"Extracts layouts, tables, and figures from any document\"\\n2. Key Information Extractor: \"Extracts key \u001b[0m\n",
       "\u001b[32minformation from target documents\"\\n3. Document OCR: \"Extracts all text from any document\"\\n\\nThe provided \u001b[0m\n",
       "\u001b[32minformation does not specify any general features of Document AI as a whole, only the features of its specific \u001b[0m\n",
       "\u001b[32mtools.'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'1c9fba8131d5829120ff'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-93da3c16-a456-47aa-8675-37b2f9df56d4-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Why we need it?'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'Why we need it?'\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Based on the provided context, key-value pairs, and knowledge graph, the reason for needing Document </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AI is not explicitly stated. However, I can infer some potential reasons based on the information given. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context mentions that Upstage Document AI: Digitize anything has been adopted by leading insurance providers due to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">its higher accuracy rates compared to previous manual human work, leading to significant productivity gains and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">operating cost reductions. Therefore, Document AI may be needed to improve the accuracy of document processing, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">increase productivity, and reduce operating costs.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1c9fba8131d5829120ff'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-eb426770-3337-4785-ae6d-9dbcf35a1327-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'Based on the provided context, key-value pairs, and knowledge graph, the reason for needing Document \u001b[0m\n",
       "\u001b[32mAI is not explicitly stated. However, I can infer some potential reasons based on the information given. The \u001b[0m\n",
       "\u001b[32mcontext mentions that Upstage Document AI: Digitize anything has been adopted by leading insurance providers due to\u001b[0m\n",
       "\u001b[32mits higher accuracy rates compared to previous manual human work, leading to significant productivity gains and \u001b[0m\n",
       "\u001b[32moperating cost reductions. Therefore, Document AI may be needed to improve the accuracy of document processing, \u001b[0m\n",
       "\u001b[32mincrease productivity, and reduce operating costs.'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'1c9fba8131d5829120ff'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run-eb426770-3337-4785-ae6d-9dbcf35a1327-0'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RAG API with history\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chat = Chat(model=public_model_name, base_url=rag_base_url)\n",
    "\n",
    "chain = prompt_template | chat\n",
    "\n",
    "questions = [\n",
    "    \"What's the benefits of Document AI?\",\n",
    "    \"How about its features?\",\n",
    "    \"Why we need it?\",\n",
    "]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    print(\"Question: \", question)\n",
    "\n",
    "    human_message = HumanMessage(content=question)\n",
    "    response = chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "    rprint(response)\n",
    "    chat_history.append(human_message)\n",
    "    chat_history.append(response)\n",
    "\n",
    "# Print the chat history\n",
    "print(\"Chat History:\")\n",
    "for chat in chat_history:\n",
    "    rprint(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Try to upload a file to the public model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>1c9fba8131d5829120ff\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Try to upload a file to the public model\u001b[33m...\u001b[0m1c9fba8131d5829120ff\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error code: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span> - <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'detail'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Invalid model name. Please use only alphanumeric characters, hyphens, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">underscores. Example: 'my-model-123'\"</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error code: \u001b[1;36m400\u001b[0m - \u001b[1m{\u001b[0m\u001b[32m'detail'\u001b[0m: \u001b[32m\"Invalid model name. Please use only alphanumeric characters, hyphens, and \u001b[0m\n",
       "\u001b[32munderscores. Example: 'my-model-123'\"\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Public mode name is read-only\n",
    "rprint(f\"Try to upload a file to the public model...{public_model_name}\")\n",
    "\n",
    "# Expect 400 BadRequest Error\n",
    "# If you want to upload a file to the public model, you need to use the private model name\n",
    "\n",
    "try:\n",
    "    file_response = client.files.create(\n",
    "        file=open(\"pdfs/solar_paper.pdf\", \"rb\"),\n",
    "        purpose=\"assistants\",\n",
    "        extra_body={\"model_name\": public_model_name},\n",
    "    )\n",
    "except Exception as e:\n",
    "    rprint(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b533657-1df4-414c-9404-4a7975492215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete the model\n",
    "response = client.models.delete(rag_model_name)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
